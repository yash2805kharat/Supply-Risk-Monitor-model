{"cells":[{"cell_type":"code","source":["!pip install xgboost\n!pip install xlrd==1.2.0\n!pip install eli5\n!pip install shap"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Installing libraries","showTitle":true,"inputWidgets":{},"nuid":"45a2d862-6f72-449d-a1fe-51397dd28269"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Requirement already satisfied: xgboost in /databricks/python3/lib/python3.8/site-packages (1.5.2)\r\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.8/site-packages (from xgboost) (1.20.1)\r\nRequirement already satisfied: scipy in /databricks/python3/lib/python3.8/site-packages (from xgboost) (1.6.2)\r\n<span class=\"ansi-yellow-fg\">WARNING: You are using pip version 21.0.1; however, version 22.0.4 is available.\r\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.</span>\r\nRequirement already satisfied: xlrd==1.2.0 in /databricks/python3/lib/python3.8/site-packages (1.2.0)\r\n<span class=\"ansi-yellow-fg\">WARNING: You are using pip version 21.0.1; however, version 22.0.4 is available.\r\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.</span>\r\nRequirement already satisfied: eli5 in /databricks/python3/lib/python3.8/site-packages (0.11.0)\r\nRequirement already satisfied: six in /databricks/python3/lib/python3.8/site-packages (from eli5) (1.15.0)\r\nRequirement already satisfied: attrs&gt;16.0.0 in /databricks/python3/lib/python3.8/site-packages (from eli5) (20.3.0)\r\nRequirement already satisfied: scipy in /databricks/python3/lib/python3.8/site-packages (from eli5) (1.6.2)\r\nRequirement already satisfied: graphviz in /databricks/python3/lib/python3.8/site-packages (from eli5) (0.19.1)\r\nRequirement already satisfied: tabulate&gt;=0.7.7 in /databricks/python3/lib/python3.8/site-packages (from eli5) (0.8.9)\r\nRequirement already satisfied: numpy&gt;=1.9.0 in /databricks/python3/lib/python3.8/site-packages (from eli5) (1.20.1)\r\nRequirement already satisfied: jinja2 in /databricks/python3/lib/python3.8/site-packages (from eli5) (2.11.3)\r\nRequirement already satisfied: scikit-learn&gt;=0.20 in /databricks/python3/lib/python3.8/site-packages (from eli5) (0.24.1)\r\nRequirement already satisfied: joblib&gt;=0.11 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn&gt;=0.20-&gt;eli5) (1.0.1)\r\nRequirement already satisfied: threadpoolctl&gt;=2.0.0 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn&gt;=0.20-&gt;eli5) (2.1.0)\r\nRequirement already satisfied: MarkupSafe&gt;=0.23 in /databricks/python3/lib/python3.8/site-packages (from jinja2-&gt;eli5) (2.0.1)\r\n<span class=\"ansi-yellow-fg\">WARNING: You are using pip version 21.0.1; however, version 22.0.4 is available.\r\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.</span>\r\nRequirement already satisfied: shap in /databricks/python3/lib/python3.8/site-packages (0.40.0)\r\nRequirement already satisfied: tqdm&gt;4.25.0 in /databricks/python3/lib/python3.8/site-packages (from shap) (4.63.1)\r\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.8/site-packages (from shap) (1.20.1)\r\nRequirement already satisfied: scipy in /databricks/python3/lib/python3.8/site-packages (from shap) (1.6.2)\r\nRequirement already satisfied: cloudpickle in /databricks/python3/lib/python3.8/site-packages (from shap) (2.0.0)\r\nRequirement already satisfied: packaging&gt;20.9 in /databricks/python3/lib/python3.8/site-packages (from shap) (21.3)\r\nRequirement already satisfied: slicer==0.0.7 in /databricks/python3/lib/python3.8/site-packages (from shap) (0.0.7)\r\nRequirement already satisfied: numba in /databricks/python3/lib/python3.8/site-packages (from shap) (0.55.1)\r\nRequirement already satisfied: pandas in /databricks/python3/lib/python3.8/site-packages (from shap) (1.2.4)\r\nRequirement already satisfied: scikit-learn in /databricks/python3/lib/python3.8/site-packages (from shap) (0.24.1)\r\nRequirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /databricks/python3/lib/python3.8/site-packages (from packaging&gt;20.9-&gt;shap) (2.4.7)\r\nRequirement already satisfied: llvmlite&lt;0.39,&gt;=0.38.0rc1 in /databricks/python3/lib/python3.8/site-packages (from numba-&gt;shap) (0.38.0)\r\nRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba-&gt;shap) (52.0.0)\r\nRequirement already satisfied: pytz&gt;=2017.3 in /databricks/python3/lib/python3.8/site-packages (from pandas-&gt;shap) (2020.5)\r\nRequirement already satisfied: python-dateutil&gt;=2.7.3 in /databricks/python3/lib/python3.8/site-packages (from pandas-&gt;shap) (2.8.1)\r\nRequirement already satisfied: six&gt;=1.5 in /databricks/python3/lib/python3.8/site-packages (from python-dateutil&gt;=2.7.3-&gt;pandas-&gt;shap) (1.15.0)\r\nRequirement already satisfied: joblib&gt;=0.11 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn-&gt;shap) (1.0.1)\r\nRequirement already satisfied: threadpoolctl&gt;=2.0.0 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn-&gt;shap) (2.1.0)\r\n<span class=\"ansi-yellow-fg\">WARNING: You are using pip version 21.0.1; however, version 22.0.4 is available.\r\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.</span>\r\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Requirement already satisfied: xgboost in /databricks/python3/lib/python3.8/site-packages (1.5.2)\r\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.8/site-packages (from xgboost) (1.20.1)\r\nRequirement already satisfied: scipy in /databricks/python3/lib/python3.8/site-packages (from xgboost) (1.6.2)\r\n<span class=\"ansi-yellow-fg\">WARNING: You are using pip version 21.0.1; however, version 22.0.4 is available.\r\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.</span>\r\nRequirement already satisfied: xlrd==1.2.0 in /databricks/python3/lib/python3.8/site-packages (1.2.0)\r\n<span class=\"ansi-yellow-fg\">WARNING: You are using pip version 21.0.1; however, version 22.0.4 is available.\r\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.</span>\r\nRequirement already satisfied: eli5 in /databricks/python3/lib/python3.8/site-packages (0.11.0)\r\nRequirement already satisfied: six in /databricks/python3/lib/python3.8/site-packages (from eli5) (1.15.0)\r\nRequirement already satisfied: attrs&gt;16.0.0 in /databricks/python3/lib/python3.8/site-packages (from eli5) (20.3.0)\r\nRequirement already satisfied: scipy in /databricks/python3/lib/python3.8/site-packages (from eli5) (1.6.2)\r\nRequirement already satisfied: graphviz in /databricks/python3/lib/python3.8/site-packages (from eli5) (0.19.1)\r\nRequirement already satisfied: tabulate&gt;=0.7.7 in /databricks/python3/lib/python3.8/site-packages (from eli5) (0.8.9)\r\nRequirement already satisfied: numpy&gt;=1.9.0 in /databricks/python3/lib/python3.8/site-packages (from eli5) (1.20.1)\r\nRequirement already satisfied: jinja2 in /databricks/python3/lib/python3.8/site-packages (from eli5) (2.11.3)\r\nRequirement already satisfied: scikit-learn&gt;=0.20 in /databricks/python3/lib/python3.8/site-packages (from eli5) (0.24.1)\r\nRequirement already satisfied: joblib&gt;=0.11 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn&gt;=0.20-&gt;eli5) (1.0.1)\r\nRequirement already satisfied: threadpoolctl&gt;=2.0.0 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn&gt;=0.20-&gt;eli5) (2.1.0)\r\nRequirement already satisfied: MarkupSafe&gt;=0.23 in /databricks/python3/lib/python3.8/site-packages (from jinja2-&gt;eli5) (2.0.1)\r\n<span class=\"ansi-yellow-fg\">WARNING: You are using pip version 21.0.1; however, version 22.0.4 is available.\r\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.</span>\r\nRequirement already satisfied: shap in /databricks/python3/lib/python3.8/site-packages (0.40.0)\r\nRequirement already satisfied: tqdm&gt;4.25.0 in /databricks/python3/lib/python3.8/site-packages (from shap) (4.63.1)\r\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.8/site-packages (from shap) (1.20.1)\r\nRequirement already satisfied: scipy in /databricks/python3/lib/python3.8/site-packages (from shap) (1.6.2)\r\nRequirement already satisfied: cloudpickle in /databricks/python3/lib/python3.8/site-packages (from shap) (2.0.0)\r\nRequirement already satisfied: packaging&gt;20.9 in /databricks/python3/lib/python3.8/site-packages (from shap) (21.3)\r\nRequirement already satisfied: slicer==0.0.7 in /databricks/python3/lib/python3.8/site-packages (from shap) (0.0.7)\r\nRequirement already satisfied: numba in /databricks/python3/lib/python3.8/site-packages (from shap) (0.55.1)\r\nRequirement already satisfied: pandas in /databricks/python3/lib/python3.8/site-packages (from shap) (1.2.4)\r\nRequirement already satisfied: scikit-learn in /databricks/python3/lib/python3.8/site-packages (from shap) (0.24.1)\r\nRequirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /databricks/python3/lib/python3.8/site-packages (from packaging&gt;20.9-&gt;shap) (2.4.7)\r\nRequirement already satisfied: llvmlite&lt;0.39,&gt;=0.38.0rc1 in /databricks/python3/lib/python3.8/site-packages (from numba-&gt;shap) (0.38.0)\r\nRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba-&gt;shap) (52.0.0)\r\nRequirement already satisfied: pytz&gt;=2017.3 in /databricks/python3/lib/python3.8/site-packages (from pandas-&gt;shap) (2020.5)\r\nRequirement already satisfied: python-dateutil&gt;=2.7.3 in /databricks/python3/lib/python3.8/site-packages (from pandas-&gt;shap) (2.8.1)\r\nRequirement already satisfied: six&gt;=1.5 in /databricks/python3/lib/python3.8/site-packages (from python-dateutil&gt;=2.7.3-&gt;pandas-&gt;shap) (1.15.0)\r\nRequirement already satisfied: joblib&gt;=0.11 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn-&gt;shap) (1.0.1)\r\nRequirement already satisfied: threadpoolctl&gt;=2.0.0 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn-&gt;shap) (2.1.0)\r\n<span class=\"ansi-yellow-fg\">WARNING: You are using pip version 21.0.1; however, version 22.0.4 is available.\r\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.</span>\r\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["import pandas as pd\nimport numpy as np\nimport datetime\nfrom datetime import datetime as dt\nfrom datetime import timedelta\nfrom sklearn.ensemble import RandomForestRegressor\nimport pickle\nimport xgboost\nimport os\nimport warnings\nimport math\nimport eli5\nimport shap\nfrom pandas.tseries.offsets import BDay\nwarnings.filterwarnings('ignore')\n\npd.set_option('display.max_rows', 1000)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Importing libraries","showTitle":true,"inputWidgets":{},"nuid":"8f69106e-38ab-4d63-8e8a-c77b45a9f245"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["run_date_phase_1 = '2022_02_25'\nrun_date_phase_2 = '2022_03_20'\nmaterial_best_models='material_best_model_vlookup_'+run_date_phase_2\n# reading best model lookup file\nmaterial_best_model = spark.read.table(material_best_models)\nmaterial_best_model = material_best_model.toPandas()\n\nsmi_raw_data='enter file path to SMI_data_bricks_raw_data_csv.xlsx'\n# reading SMI data\nsmi_1=pd.read_excel(smi_raw_data)\n\nrisk_raw_data='enter file path to Risk_Support_raw_data.xlsx'\n#reading financial data\nfin=pd.read_excel(risk_raw_data)\n\nfreq_raw_data='order_freq_19_01'\n#reading frequency data\nfreqc = spark.read.table(freq_raw_data)\nfreq=freqc.toPandas()\n\nlead_time_mod='model_data_vf_19_01'\n#reading historical data\nhistorical_data = spark.read.table(lead_time_mod)\nhistorical_data = historical_data.toPandas()\nhistorical_data = historical_data[historical_data['PO_Create_Date']!='1888-01-01']\nhistorical_data = historical_data[historical_data['Delivered_Quantity']!=0]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Importing files and tables","showTitle":true,"inputWidgets":{},"nuid":"fd6bda2a-e0b7-4672-9b5a-3c3f3289d48e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# updating values on model data \nfor vs_id, vs_reg in zip(historical_data['updated_VS_location'],historical_data['updated_VS_region']):\n  if (((vs_id=='madison') | (vs_id=='payette')) & (vs_reg=='id')):\n    historical_data.loc[(historical_data['updated_VS_location']==vs_id) & \n                        (historical_data['updated_VS_region']==vs_reg),'updated_VS_country']='us'\n  else:\n    pass\n\nhistorical_data.loc[historical_data['updated_VS_region']=='de','updated_VS_country']='de'\nhistorical_data.loc[historical_data['updated_VS_region']=='br','updated_VS_country']='br'\nhistorical_data.loc[historical_data['updated_VS_region']=='vn','updated_VS_country']='vt'\nhistorical_data.loc[historical_data['updated_VS_country']=='vt','updated_VS_region']='vt'"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7c2876ba-d70d-4283-9248-67034d55caaf"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Creating historical daily weather variables\ndaily_weather_historical_v1 = spark.read.table('weather_data_weekly')\ndaily_weather_historical_v1 = daily_weather_historical_v1.toPandas()\ndaily_weather_historical_v1.rename(columns={'name':'location'}, inplace=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Creating Variables to pass in the predict function","showTitle":true,"inputWidgets":{},"nuid":"5789b969-2b49-4767-8472-f063e7a30eeb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Function for creating PO+2W date, PO+4W date and PO+6W date\ndef po_delta_week_dates(po_create_date, vs_location, vs_region):\n  po_create_date_2W = pd.to_datetime(po_create_date)+timedelta(14)\n  po_create_date_2W = pd.to_datetime(po_create_date_2W).strftime('%Y-%m-%d')\n  po_create_date_4W = pd.to_datetime(po_create_date)+timedelta(28)\n  po_create_date_4W = pd.to_datetime(po_create_date_4W).strftime('%Y-%m-%d')\n  po_create_date_6W = pd.to_datetime(po_create_date)+timedelta(42)\n  po_create_date_6W = pd.to_datetime(po_create_date_6W).strftime('%Y-%m-%d')\n  location = vs_location+','+vs_region\n  return po_create_date_2W, po_create_date_4W, po_create_date_6W, location"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4f37aaf8-5035-478e-8cf6-74cf377c2a87"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Reading weather forecast data\ndaily_weather_15day_forecast = spark.read.table('weather_forecast_ves')\ndaily_weather_15day_forecast = daily_weather_15day_forecast.toPandas()\ndaily_weather_15day_forecast['datetime'] = pd.to_datetime(daily_weather_15day_forecast['datetime'])\ndaily_weather_15day_forecast['conditions']=daily_weather_15day_forecast['conditions'].astype(str)\ndaily_weather_15day_forecast['icon']=daily_weather_15day_forecast['icon'].astype(str)\ndaily_weather_15day_forecast['rainfall_mm']=[vals  if 'Rain' in datas else 0 for datas,vals in zip(daily_weather_15day_forecast['conditions'],daily_weather_15day_forecast['precip'])]\ndaily_weather_15day_forecast['Weeks']=pd.to_datetime(daily_weather_15day_forecast['datetime']).dt.week\ndaily_weather_15day_forecast['fog_count']=[1  if 'fog' in datas else 0 for datas in daily_weather_15day_forecast['icon']]\ndaily_weather_15day_forecast['rain_count']=[1  if 'rain' in datas else 0 for datas in daily_weather_15day_forecast['icon']]\ndaily_weather_15day_forecast['snow_count']=[1  if 'snow' in datas else 0 for datas in daily_weather_15day_forecast['icon']]\ndaily_weather_15day_forecast['Years']=pd.to_datetime(daily_weather_15day_forecast['datetime']).dt.year\ndaily_weather_15day_forecast_v1=pd.pivot_table(daily_weather_15day_forecast,values=['tempmax','tempmin','snowdepth','windspeed','rainfall_mm'],index=['location','Weeks'],aggfunc='mean').reset_index()\ndaily_weather_15day_forecast_v121=pd.pivot_table(daily_weather_15day_forecast,values=['fog_count','rain_count','snow_count'],index=['location','Weeks','Years'],aggfunc='sum').reset_index()\ndaily_weather_15day_forecast_v122=pd.pivot_table(daily_weather_15day_forecast_v121,values=['fog_count','rain_count','snow_count'],index=['location','Weeks'],aggfunc='mean').reset_index()\ndaily_weather_15day_forecast_v1=daily_weather_15day_forecast_v1.merge(daily_weather_15day_forecast_v122,on=['location','Weeks'],how='left')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d028b645-6004-4387-abcb-fca4960124ee"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Function for creating daily weather variables from historical weather, historical weekly weather average and weather forecast\ndef create_daily_weather_vars(po_date, vs_location, vs_region, mat_id):\n  historical_data['PO_Create_Date'] = pd.to_datetime(historical_data['PO_Create_Date'])\n  last_historical_date = max(historical_data[historical_data['Material_No.']==mat_id]['PO_Create_Date'])\n  lead_time_cutoff = historical_data[(historical_data['Material_No.']==mat_id) & \n                                     (historical_data['lead_time']>0)]['lead_time'].describe()[6]\n  po_date_2w, po_date_4w, po_date_6w, location = po_delta_week_dates(po_date, vs_location, vs_region)\n  \n  alldates=pd.date_range(start=po_date, end=po_date_6w)\n  tempdf1=pd.DataFrame(alldates,columns=['dates'])\n  tempdf1['location']=location\n  tempdf1['Weeks']=pd.to_datetime(tempdf1['dates']).dt.week\n  \n  daily_weather_historical_v11=daily_weather_historical_v1[(daily_weather_historical_v1['location']==location)].copy()\n  weather_raw_data_historical_v2=pd.merge(tempdf1,daily_weather_historical_v11,on=['location','Weeks'],how='left')\n  \n  daily_weather_15day_forecast_v11=daily_weather_15day_forecast_v1[(daily_weather_15day_forecast_v1['location']==location)].copy()\n  weather_raw_data_forecast_v2=pd.merge(tempdf1,daily_weather_15day_forecast_v11,on=['location','Weeks'],how='left')\n  \n  #Historical variables for typical weather data for 2, 4 and 6 weeks from PO Create Date\n  rainfall_mm_2w_hist=weather_raw_data_historical_v2[(weather_raw_data_historical_v2['dates']>=po_date) & \n                                                  (weather_raw_data_historical_v2['dates']<=po_date_2w)]['rainfall_mm'].max()\n  rainfall_mm_4w_hist=weather_raw_data_historical_v2[(weather_raw_data_historical_v2['dates']>=po_date) & \n                                                (weather_raw_data_historical_v2['dates']<=po_date_4w)]['rainfall_mm'].max()\n  rainfall_mm_6w_hist=weather_raw_data_historical_v2[(weather_raw_data_historical_v2['dates']>=po_date) & \n                                                (weather_raw_data_historical_v2['dates']<=po_date_6w)]['rainfall_mm'].max()\n  snowdepth_2w_hist=weather_raw_data_historical_v2[(weather_raw_data_historical_v2['dates']>=po_date) & \n                                              (weather_raw_data_historical_v2['dates']<=po_date_2w)]['snowdepth'].max()\n  snowdepth_4w_hist=weather_raw_data_historical_v2[(weather_raw_data_historical_v2['dates']>=po_date) & \n                                              (weather_raw_data_historical_v2['dates']<=po_date_4w)]['snowdepth'].max()\n  snowdepth_6w_hist=weather_raw_data_historical_v2[(weather_raw_data_historical_v2['dates']>=po_date) & \n                                              (weather_raw_data_historical_v2['dates']<=po_date_6w)]['snowdepth'].max()\n  tempmax_2w_hist=weather_raw_data_historical_v2[(weather_raw_data_historical_v2['dates']>=po_date) & \n                                            (weather_raw_data_historical_v2['dates']<=po_date_2w)]['tempmax'].max()\n  tempmax_4w_hist=weather_raw_data_historical_v2[(weather_raw_data_historical_v2['dates']>=po_date) & \n                                            (weather_raw_data_historical_v2['dates']<=po_date_4w)]['tempmax'].max()\n  tempmax_6w_hist=weather_raw_data_historical_v2[(weather_raw_data_historical_v2['dates']>=po_date) & \n                                            (weather_raw_data_historical_v2['dates']<=po_date_6w)]['tempmax'].max()\n  tempmin_2w_hist=weather_raw_data_historical_v2[(weather_raw_data_historical_v2['dates']>=po_date) & \n                                            (weather_raw_data_historical_v2['dates']<=po_date_2w)]['tempmin'].min()\n  tempmin_4w_hist=weather_raw_data_historical_v2[(weather_raw_data_historical_v2['dates']>=po_date) & \n                                            (weather_raw_data_historical_v2['dates']<=po_date_4w)]['tempmin'].min()\n  tempmin_6w_hist=weather_raw_data_historical_v2[(weather_raw_data_historical_v2['dates']>=po_date) & \n                                            (weather_raw_data_historical_v2['dates']<=po_date_6w)]['tempmin'].min()\n  windspeed_2w_hist=weather_raw_data_historical_v2[(weather_raw_data_historical_v2['dates']>=po_date) & \n                                              (weather_raw_data_historical_v2['dates']<=po_date_2w)]['windspeed'].max()\n  windspeed_4w_hist=weather_raw_data_historical_v2[(weather_raw_data_historical_v2['dates']>=po_date) & \n                                              (weather_raw_data_historical_v2['dates']<=po_date_4w)]['windspeed'].max()\n  windspeed_6w_hist=weather_raw_data_historical_v2[(weather_raw_data_historical_v2['dates']>=po_date) & \n                                              (weather_raw_data_historical_v2['dates']<=po_date_6w)]['windspeed'].max()\n\n  fogcount_2w_hist=weather_raw_data_historical_v2[(weather_raw_data_historical_v2['dates']>=po_date) & \n                                             (weather_raw_data_historical_v2['dates']<=po_date_2w)]['fog_count'].max()\n  fogcount_4w_hist=weather_raw_data_historical_v2[(weather_raw_data_historical_v2['dates']>=po_date) & \n                                             (weather_raw_data_historical_v2['dates']<=po_date_4w)]['fog_count'].max()\n  fogcount_6w_hist=weather_raw_data_historical_v2[(weather_raw_data_historical_v2['dates']>=po_date) & \n                                             (weather_raw_data_historical_v2['dates']<=po_date_6w)]['fog_count'].max()\n  snowcount_2w_hist=weather_raw_data_historical_v2[(weather_raw_data_historical_v2['dates']>=po_date) & \n                                              (weather_raw_data_historical_v2['dates']<=po_date_2w)]['snow_count'].max()\n  snowcount_4w_hist=weather_raw_data_historical_v2[(weather_raw_data_historical_v2['dates']>=po_date) & \n                                              (weather_raw_data_historical_v2['dates']<=po_date_4w)]['snow_count'].max()\n  snowcount_6w_hist=weather_raw_data_historical_v2[(weather_raw_data_historical_v2['dates']>=po_date) & \n                                              (weather_raw_data_historical_v2['dates']<=po_date_6w)]['snow_count'].max()\n  raincount_2w_hist=weather_raw_data_historical_v2[(weather_raw_data_historical_v2['dates']>=po_date) & \n                                              (weather_raw_data_historical_v2['dates']<=po_date_2w)]['rain_count'].max()\n  raincount_4w_hist=weather_raw_data_historical_v2[(weather_raw_data_historical_v2['dates']>=po_date) & \n                                              (weather_raw_data_historical_v2['dates']<=po_date_4w)]['rain_count'].max()\n  raincount_6w_hist=weather_raw_data_historical_v2[(weather_raw_data_historical_v2['dates']>=po_date) & \n                                              (weather_raw_data_historical_v2['dates']<=po_date_6w)]['rain_count'].max()\n  \n  #Forecast variables for typical weather data for 2, 4 and 6 weeks from PO Create Date\n  rainfall_mm_2w_fcst=weather_raw_data_forecast_v2[(weather_raw_data_forecast_v2['dates']>=po_date) & \n                                                (weather_raw_data_forecast_v2['dates']<=po_date_2w)]['rainfall_mm'].max()\n  rainfall_mm_4w_fcst=weather_raw_data_forecast_v2[(weather_raw_data_forecast_v2['dates']>=po_date) & \n                                              (weather_raw_data_forecast_v2['dates']<=po_date_4w)]['rainfall_mm'].max()\n  rainfall_mm_6w_fcst=weather_raw_data_forecast_v2[(weather_raw_data_forecast_v2['dates']>=po_date) & \n                                              (weather_raw_data_forecast_v2['dates']<=po_date_6w)]['rainfall_mm'].max()\n  snowdepth_2w_fcst=weather_raw_data_forecast_v2[(weather_raw_data_forecast_v2['dates']>=po_date) & \n                                            (weather_raw_data_forecast_v2['dates']<=po_date_2w)]['snowdepth'].max()\n  snowdepth_4w_fcst=weather_raw_data_forecast_v2[(weather_raw_data_forecast_v2['dates']>=po_date) & \n                                            (weather_raw_data_forecast_v2['dates']<=po_date_4w)]['snowdepth'].max()\n  snowdepth_6w_fcst=weather_raw_data_forecast_v2[(weather_raw_data_forecast_v2['dates']>=po_date) & \n                                            (weather_raw_data_forecast_v2['dates']<=po_date_6w)]['snowdepth'].max()\n  tempmax_2w_fcst=weather_raw_data_forecast_v2[(weather_raw_data_forecast_v2['dates']>=po_date) & \n                                          (weather_raw_data_forecast_v2['dates']<=po_date_2w)]['tempmax'].max()\n  tempmax_4w_fcst=weather_raw_data_forecast_v2[(weather_raw_data_forecast_v2['dates']>=po_date) & \n                                          (weather_raw_data_forecast_v2['dates']<=po_date_4w)]['tempmax'].max()\n  tempmax_6w_fcst=weather_raw_data_forecast_v2[(weather_raw_data_forecast_v2['dates']>=po_date) & \n                                          (weather_raw_data_forecast_v2['dates']<=po_date_6w)]['tempmax'].max()\n  tempmin_2w_fcst=weather_raw_data_forecast_v2[(weather_raw_data_forecast_v2['dates']>=po_date) & \n                                          (weather_raw_data_forecast_v2['dates']<=po_date_2w)]['tempmin'].min()\n  tempmin_4w_fcst=weather_raw_data_forecast_v2[(weather_raw_data_forecast_v2['dates']>=po_date) & \n                                          (weather_raw_data_forecast_v2['dates']<=po_date_4w)]['tempmin'].min()\n  tempmin_6w_fcst=weather_raw_data_forecast_v2[(weather_raw_data_forecast_v2['dates']>=po_date) & \n                                          (weather_raw_data_forecast_v2['dates']<=po_date_6w)]['tempmin'].min()\n  windspeed_2w_fcst=weather_raw_data_forecast_v2[(weather_raw_data_forecast_v2['dates']>=po_date) & \n                                            (weather_raw_data_forecast_v2['dates']<=po_date_2w)]['windspeed'].max()\n  windspeed_4w_fcst=weather_raw_data_forecast_v2[(weather_raw_data_forecast_v2['dates']>=po_date) & \n                                            (weather_raw_data_forecast_v2['dates']<=po_date_4w)]['windspeed'].max()\n  windspeed_6w_fcst=weather_raw_data_forecast_v2[(weather_raw_data_forecast_v2['dates']>=po_date) & \n                                            (weather_raw_data_forecast_v2['dates']<=po_date_6w)]['windspeed'].max()\n\n  fogcount_2w_fcst=weather_raw_data_forecast_v2[(weather_raw_data_forecast_v2['dates']>=po_date) & \n                                           (weather_raw_data_forecast_v2['dates']<=po_date_2w)]['fog_count'].max()\n  fogcount_4w_fcst=weather_raw_data_forecast_v2[(weather_raw_data_forecast_v2['dates']>=po_date) & \n                                           (weather_raw_data_forecast_v2['dates']<=po_date_4w)]['fog_count'].max()\n  fogcount_6w_fcst=weather_raw_data_forecast_v2[(weather_raw_data_forecast_v2['dates']>=po_date) & \n                                           (weather_raw_data_forecast_v2['dates']<=po_date_6w)]['fog_count'].max()\n  snowcount_2w_fcst=weather_raw_data_forecast_v2[(weather_raw_data_forecast_v2['dates']>=po_date) & \n                                            (weather_raw_data_forecast_v2['dates']<=po_date_2w)]['snow_count'].max()\n  snowcount_4w_fcst=weather_raw_data_forecast_v2[(weather_raw_data_forecast_v2['dates']>=po_date) & \n                                            (weather_raw_data_forecast_v2['dates']<=po_date_4w)]['snow_count'].max()\n  snowcount_6w_fcst=weather_raw_data_forecast_v2[(weather_raw_data_forecast_v2['dates']>=po_date) & \n                                            (weather_raw_data_forecast_v2['dates']<=po_date_6w)]['snow_count'].max()\n  raincount_2w_fcst=weather_raw_data_forecast_v2[(weather_raw_data_forecast_v2['dates']>=po_date) & \n                                            (weather_raw_data_forecast_v2['dates']<=po_date_2w)]['rain_count'].max()\n  raincount_4w_fcst=weather_raw_data_forecast_v2[(weather_raw_data_forecast_v2['dates']>=po_date) & \n                                            (weather_raw_data_forecast_v2['dates']<=po_date_4w)]['rain_count'].max()\n  raincount_6w_fcst=weather_raw_data_forecast_v2[(weather_raw_data_forecast_v2['dates']>=po_date) & \n                                            (weather_raw_data_forecast_v2['dates']<=po_date_6w)]['rain_count'].max()\n  \n  #By default setting the variables to historical average values\n  rainfall_mm_2w = rainfall_mm_2w_hist\n  rainfall_mm_4w = rainfall_mm_4w_hist\n  rainfall_mm_6w = rainfall_mm_6w_hist\n  snowdepth_2w = snowdepth_2w_hist\n  snowdepth_4w = snowdepth_4w_hist\n  snowdepth_6w = snowdepth_6w_hist\n  tempmax_2w = tempmax_2w_hist\n  tempmax_4w = tempmax_4w_hist\n  tempmax_6w = tempmax_6w_hist\n  tempmin_2w = tempmin_2w_hist\n  tempmin_4w = tempmin_4w_hist\n  tempmin_6w = tempmin_6w_hist\n  windspeed_2w = windspeed_2w_hist\n  windspeed_4w = windspeed_4w_hist\n  windspeed_6w = windspeed_6w_hist\n  fogcount_2w = fogcount_2w_hist\n  fogcount_4w = fogcount_4w_hist\n  fogcount_6w = fogcount_6w_hist\n  snowcount_2w = snowcount_2w_hist\n  snowcount_4w = snowcount_4w_hist\n  snowcount_6w = snowcount_6w_hist\n  raincount_2w = raincount_2w_hist\n  raincount_4w = raincount_4w_hist\n  raincount_6w = raincount_6w_hist\n  \n  #Rule 1: If PO + 6W date is less than the last available historical date, take all historical weather variables\n  if pd.to_datetime(po_date_6w) <= pd.to_datetime(last_historical_date):\n    rainfall_mm_2w = rainfall_mm_2w_hist\n    rainfall_mm_4w = rainfall_mm_4w_hist\n    rainfall_mm_6w = rainfall_mm_6w_hist\n    snowdepth_2w = snowdepth_2w_hist\n    snowdepth_4w = snowdepth_4w_hist\n    snowdepth_6w = snowdepth_6w_hist\n    tempmax_2w = tempmax_2w_hist\n    tempmax_4w = tempmax_4w_hist\n    tempmax_6w = tempmax_6w_hist\n    tempmin_2w = tempmin_2w_hist\n    tempmin_4w = tempmin_4w_hist\n    tempmin_6w = tempmin_6w_hist\n    windspeed_2w = windspeed_2w_hist\n    windspeed_4w = windspeed_4w_hist\n    windspeed_6w = windspeed_6w_hist\n    fogcount_2w = fogcount_2w_hist\n    fogcount_4w = fogcount_4w_hist\n    fogcount_6w = fogcount_6w_hist\n    snowcount_2w = snowcount_2w_hist\n    snowcount_4w = snowcount_4w_hist\n    snowcount_6w = snowcount_6w_hist\n    raincount_2w = raincount_2w_hist\n    raincount_4w = raincount_4w_hist\n    raincount_6w = raincount_6w_hist\n  \n  #Rule 2: If PO + 2W date is less than the last available historical date and PO + 4W is greather than first available forecast date, take historical 2W weather variables and combine with the 4W and 6W weather variables from weather forecast data\n  elif pd.to_datetime(po_date_2w) <= pd.to_datetime(last_historical_date) and pd.to_datetime(po_date_4w) >= pd.to_datetime(last_historical_date):\n    rainfall_mm_2w = rainfall_mm_2w_hist\n    rainfall_mm_4w = rainfall_mm_4w_fcst\n    rainfall_mm_6w = rainfall_mm_6w_fcst\n    snowdepth_2w = snowdepth_2w_hist\n    snowdepth_4w = snowdepth_4w_fcst\n    snowdepth_6w = snowdepth_6w_fcst\n    tempmax_2w = tempmax_2w_hist\n    tempmax_4w = tempmax_4w_fcst\n    tempmax_6w = tempmax_6w_fcst\n    tempmin_2w = tempmin_2w_hist\n    tempmin_4w = tempmin_4w_fcst\n    tempmin_6w = tempmin_6w_fcst\n    windspeed_2w = windspeed_2w_hist\n    windspeed_4w = windspeed_4w_fcst\n    windspeed_6w = windspeed_6w_fcst\n    fogcount_2w = fogcount_2w_hist\n    fogcount_4w = fogcount_4w_fcst\n    fogcount_6w = fogcount_6w_fcst\n    snowcount_2w = snowcount_2w_hist\n    snowcount_4w = snowcount_4w_fcst\n    snowcount_6w = snowcount_6w_fcst\n    raincount_2w = raincount_2w_hist\n    raincount_4w = raincount_4w_fcst\n    raincount_6w = raincount_6w_fcst\n    \n  #Rule 3: If PO + 4W date is less than the last available historical date and PO + 6W is greather than first available forecast date, take historical 2W, 4W weather variables and combine with the 6W weather variables from weather forecast data\n  elif pd.to_datetime(po_date_4w) <= pd.to_datetime(last_historical_date) and pd.to_datetime(po_date_6w) >= pd.to_datetime(last_historical_date):\n    rainfall_mm_2w = rainfall_mm_2w_hist\n    rainfall_mm_4w = rainfall_mm_4w_hist\n    rainfall_mm_6w = rainfall_mm_6w_fcst\n    snowdepth_2w = snowdepth_2w_hist\n    snowdepth_4w = snowdepth_4w_hist\n    snowdepth_6w = snowdepth_6w_fcst\n    tempmax_2w = tempmax_2w_hist\n    tempmax_4w = tempmax_4w_hist\n    tempmax_6w = tempmax_6w_fcst\n    tempmin_2w = tempmin_2w_hist\n    tempmin_4w = tempmin_4w_hist\n    tempmin_6w = tempmin_6w_fcst\n    windspeed_2w = windspeed_2w_hist\n    windspeed_4w = windspeed_4w_hist\n    windspeed_6w = windspeed_6w_fcst\n    fogcount_2w = fogcount_2w_hist\n    fogcount_4w = fogcount_4w_hist\n    fogcount_6w = fogcount_6w_fcst\n    snowcount_2w = snowcount_2w_hist\n    snowcount_4w = snowcount_4w_hist\n    snowcount_6w = snowcount_6w_fcst\n    raincount_2w = raincount_2w_hist\n    raincount_4w = raincount_4w_hist\n    raincount_6w = raincount_6w_fcst\n    \n  #Rule 4: If PO date is greather than last available historical date or PO + 2W date is greather than the last historical date then take all weather variables from weather forecast data\n  elif (pd.to_datetime(po_date) >= pd.to_datetime(last_historical_date)) or (pd.to_datetime(po_date) <= pd.to_datetime(last_historical_date) and pd.to_datetime(po_date_2w) >= pd.to_datetime(last_historical_date)):\n    rainfall_mm_2w = rainfall_mm_2w_fcst\n    rainfall_mm_4w = rainfall_mm_4w_fcst\n    rainfall_mm_6w = rainfall_mm_6w_fcst\n    snowdepth_2w = snowdepth_2w_fcst\n    snowdepth_4w = snowdepth_4w_fcst\n    snowdepth_6w = snowdepth_6w_fcst\n    tempmax_2w = tempmax_2w_fcst\n    tempmax_4w = tempmax_4w_fcst\n    tempmax_6w = tempmax_6w_fcst\n    tempmin_2w = tempmin_2w_fcst\n    tempmin_4w = tempmin_4w_fcst\n    tempmin_6w = tempmin_6w_fcst\n    windspeed_2w = windspeed_2w_fcst\n    windspeed_4w = windspeed_4w_fcst\n    windspeed_6w = windspeed_6w_fcst\n    fogcount_2w = fogcount_2w_fcst\n    fogcount_4w = fogcount_4w_fcst\n    fogcount_6w = fogcount_6w_fcst\n    snowcount_2w = snowcount_2w_fcst\n    snowcount_4w = snowcount_4w_fcst\n    snowcount_6w = snowcount_6w_fcst\n    raincount_2w = raincount_2w_fcst\n    raincount_4w = raincount_4w_fcst\n    raincount_6w = raincount_6w_fcst\n  \n  #Returning variables based on lead time cutoff\n  if lead_time_cutoff <= 21:\n    return [rainfall_mm_2w, snowdepth_2w, tempmax_2w, tempmin_2w, windspeed_2w, fogcount_2w, snowcount_2w, raincount_2w]\n  elif lead_time_cutoff > 21 and lead_time_cutoff <= 35:\n    return [rainfall_mm_4w, snowdepth_4w, tempmax_4w, tempmin_4w, windspeed_4w, fogcount_4w, snowcount_4w, raincount_4w]\n  else:\n    return [rainfall_mm_6w, snowdepth_6w, tempmax_6w, tempmin_6w, windspeed_6w, fogcount_6w, snowcount_6w, raincount_6w]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6b96e80e-d715-4ab8-9efb-1cf03b59b6fe"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Reading extreme weather events data\nextreme_weather_event_US = spark.read.table('Extreme_weather_data_for_vendors_within_US')\nextreme_weather_event_US = extreme_weather_event_US.toPandas()\nextreme_weather_event_US.fillna(0, inplace=True)\n\nextreme_weather_event_outside_US = spark.read.table('Extreme_weather_data_for_vendors_outside_US')\nextreme_weather_event_outside_US = extreme_weather_event_outside_US.toPandas()\nextreme_weather_event_outside_US.fillna(0, inplace=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Creating Extreme Weather events variables","showTitle":true,"inputWidgets":{},"nuid":"118d070b-14b6-43a1-8c0a-1ac5b7cbfe49"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Creating list of extreme weather events variables to keep\nimp_ext_weather_count_cols = ['winter_storm_count','flash_flood_count','heat_count','hail_count','thunderstorm_wind_count','lightning_count',\n                              'high_wind_count','wildfire_count','heavy_snow_count','strong_wind_count','winter_weather_count',\n                              'extreme_cold/wind_chill_count','flood_count','heavy_rain_count','blizzard_count','cold/wind_chill_count',\n                              'drought_count','tornado_count','lakeshore_flood_count','frost/freeze_count','tropical_storm_count',\n                              'coastal_flood_count','marine_high_wind_count','marine_thunderstorm_wind_count','storm_surge/tide_count',\n                              'tropical_depression_count','dense_fog_count','hurricane_count','marine_tropical_storm_count','ice_storm_count',\n                              'marine_dense_fog_count','excessive_heat_count','waterspout_count','dense_smoke_count','sleet_count']\n\nimp_ext_weather_duration_cols = ['marine_high_wind_duration','marine_thunderstorm_wind_duration','storm_surge/tide_duration',\n                                 'waterspout_duration','tropical_depression_duration','marine_tropical_storm_duration']"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"21390e37-4188-4f8b-b581-75fc8f5762aa"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Function for creating extreme weather events variables\ndef create_exw_vars(po_create_date, vs_location, vs_region, vs_country):\n  po_date_2w, po_date_4w, po_date_6w, location = po_delta_week_dates(po_create_date, vs_location, vs_region)\n  PO_month=pd.to_datetime(po_create_date).month\n  PO_month_6W=pd.to_datetime(po_date_6w).month\n  cols_to_keep = imp_ext_weather_count_cols+imp_ext_weather_duration_cols\n  \n  count_col_list = []\n  duration_col_list = []\n  \n  #creating extreme weather events variables for countries in US, Mexico and Canada\n  if vs_country in ['us', 'mx', 'ca']:\n    for count_col in imp_ext_weather_count_cols:\n      if count_col not in extreme_weather_event_US.columns.tolist():\n        count = 0\n      else:\n        if PO_month<PO_month_6W:\n          count_df=extreme_weather_event_US[(extreme_weather_event_US['name']==location) & (extreme_weather_event_US['Months']>=PO_month) & \n                                            (extreme_weather_event_US['Months']<=PO_month_6W)][count_col]\n        else:\n          count_df=extreme_weather_event_US[(extreme_weather_event_US['name']==location) & ((extreme_weather_event_US['Months']>=PO_month) | \n                                            (extreme_weather_event_US['Months']<=PO_month_6W))][count_col]\n        count_df=count_df[count_df.isnull()==False]\n        count = count_df.sum()\n      count_col = count\n      count_col_list.append(count_col)\n    \n    for dur_col in imp_ext_weather_duration_cols:\n      if dur_col not in extreme_weather_event_US.columns.tolist():\n        overall_event_duration = 0\n      else:\n        if PO_month<PO_month_6W:\n          dur_df=extreme_weather_event_US[(extreme_weather_event_US['name']==location) & (extreme_weather_event_US['Months']>=PO_month) & \n                                          (extreme_weather_event_US['Months']<=PO_month_6W)][dur_col]\n        else:\n          dur_df=extreme_weather_event_US[(extreme_weather_event_US['name']==location) & ((extreme_weather_event_US['Months']>=PO_month) | \n                                          (extreme_weather_event_US['Months']<=PO_month_6W))][dur_col]\n        dur_df=dur_df[dur_df.isnull()==False]\n        duration=dur_df.mean()\n        overall_event_duration=duration*count\n      dur_col = overall_event_duration\n      duration_col_list.append(dur_col)\n  \n  #creating extreme weather events variables for countries in US, Mexico and Canada\n  else:\n    if vs_country in ['au', 'tw', 'vt']:\n      coast_side = 'West'\n    elif vs_country in ['es', 'de', 'br']:\n      coast_side = 'East'\n    \n    for count_col in imp_ext_weather_count_cols:\n      if count_col not in extreme_weather_event_outside_US.columns.tolist():\n        count = 0\n      else:\n        if PO_month<PO_month_6W:\n          count_df=extreme_weather_event_outside_US[(extreme_weather_event_outside_US['Coast']==coast_side) & \n                                                    (extreme_weather_event_outside_US['Months']>=PO_month) & \n                                                    (extreme_weather_event_outside_US['Months']<=PO_month_6W)][count_col]\n        else:\n          count_df=extreme_weather_event_outside_US[(extreme_weather_event_outside_US['Coast']==coast_side) & \n                                                    ((extreme_weather_event_outside_US['Months']>=PO_month) | \n                                                    (extreme_weather_event_outside_US['Months']<=PO_month_6W))][count_col]\n        count_df=count_df[count_df.isnull()==False]\n        count=count_df.sum()\n      count_col = count\n      count_col_list.append(count_col)\n    \n    for dur_col in imp_ext_weather_duration_cols:\n      if dur_col not in extreme_weather_event_US.columns.tolist():\n        overall_event_duration = 0\n      else:\n        if PO_month<PO_month_6W:\n          dur_df=extreme_weather_event_outside_US[(extreme_weather_event_outside_US['Coast']==coast_side) & \n                                                  (extreme_weather_event_outside_US['Months']>=PO_month) & \n                                                  (extreme_weather_event_outside_US['Months']<=PO_month_6W)][dur_col]\n        else:\n          dur_df=extreme_weather_event_outside_US[(extreme_weather_event_outside_US['Coast']==coast_side) & \n                                                  ((extreme_weather_event_outside_US['Months']>=PO_month) | \n                                                   (extreme_weather_event_outside_US['Months']<=PO_month_6W))][dur_col]\n        dur_df=dur_df[dur_df.isnull()==False]\n        duration=dur_df.mean()\n        overall_event_duration=duration*count\n      dur_col = overall_event_duration\n      duration_col_list.append(dur_col)\n  \n  return count_col_list+duration_col_list"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2e8520f3-a3ce-4219-a18a-01a037de19cf"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["traffic_data_final = spark.read.table('Traffic_dataset_raw')\ntraffic_data_final = traffic_data_final.toPandas()\ntraffic_data_final.fillna(0, inplace=True)\ntraffic_data_final['INCIDENT_START_DATE'] = pd.to_datetime(traffic_data_final['INCIDENT_START_DATE'])\ntraffic_data_final['INCIDENT_END_DATE'] = pd.to_datetime(traffic_data_final['INCIDENT_END_DATE'])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Creating Traffic variables","showTitle":true,"inputWidgets":{},"nuid":"eeff824b-77e7-4294-a27b-896fbe6928c0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Function for traffic variables\ndef create_traffic_vars(po_create_date, plant_id, vs_location, vs_region, vs_id, mat_id):\n  lead_time_cutoff = historical_data[(historical_data['Material_No.']==mat_id) & \n                                     (historical_data['lead_time']>0)]['lead_time'].describe()[6]\n  po_date_2w, po_date_4w, po_date_6w, location = po_delta_week_dates(po_create_date, vs_location, vs_region)\n  \n  traffic_col_dict = {}\n  for event_type in traffic_data_final['DELAY_TYPE'].unique().tolist():\n    traffic_col_dict[event_type+'_count_2w']=traffic_data_final[(traffic_data_final['Plant_ID']==plant_id) & (traffic_data_final['updated_VS_ID']==vs_id) & \n                                              (traffic_data_final['INCIDENT_START_DATE']>=po_create_date) & \n                                              (traffic_data_final['INCIDENT_START_DATE']<=po_date_2w) & (traffic_data_final['DELAY_TYPE']==event_type)].shape[0]+traffic_data_final[(traffic_data_final['Plant_ID']==plant_id) & (traffic_data_final['updated_VS_ID']==vs_id) & (traffic_data_final['INCIDENT_START_DATE']<=po_create_date) & (traffic_data_final['INCIDENT_END_DATE']>=po_create_date) & (traffic_data_final['DELAY_TYPE']==event_type)].shape[0]\n    \n    traffic_col_dict[event_type+'_count_4w']=traffic_data_final[(traffic_data_final['Plant_ID']==plant_id) & (traffic_data_final['updated_VS_ID']==vs_id) & (traffic_data_final['INCIDENT_START_DATE']>=po_create_date) & (traffic_data_final['INCIDENT_START_DATE']<=po_date_4w) & (traffic_data_final['DELAY_TYPE']==event_type)].shape[0]+traffic_data_final[(traffic_data_final['Plant_ID']==plant_id) & (traffic_data_final['updated_VS_ID']==vs_id) & (traffic_data_final['INCIDENT_START_DATE']<=po_create_date) & (traffic_data_final['INCIDENT_END_DATE']>=po_create_date) & (traffic_data_final['DELAY_TYPE']==event_type)].shape[0]\n    \n    traffic_col_dict[event_type+'_count_6w']=traffic_data_final[(traffic_data_final['Plant_ID']==plant_id) & (traffic_data_final['updated_VS_ID']==vs_id) & (traffic_data_final['INCIDENT_START_DATE']>=po_create_date) & (traffic_data_final['INCIDENT_START_DATE']<=po_date_6w) & (traffic_data_final['DELAY_TYPE']==event_type)].shape[0]+traffic_data_final[(traffic_data_final['Plant_ID']==plant_id) & (traffic_data_final['updated_VS_ID']==vs_id) & (traffic_data_final['INCIDENT_START_DATE']<=po_create_date) & (traffic_data_final['INCIDENT_END_DATE']>=po_create_date) & (traffic_data_final['DELAY_TYPE']==event_type)].shape[0]\n  \n  if lead_time_cutoff <= 21:\n    col_list = [traffic_col_dict[key] for key in list(traffic_col_dict.keys()) if '_2w' in key]\n  elif lead_time_cutoff > 21 and lead_time_cutoff <= 35:\n    col_list = [traffic_col_dict[key] for key in list(traffic_col_dict.keys()) if '_4w' in key]\n  else:\n    col_list = [traffic_col_dict[key] for key in list(traffic_col_dict.keys()) if '_6w' in key]\n  \n  return col_list"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bcf14a5a-5e75-4e92-a610-73e23cb90242"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["port_data_hist = spark.read.table('Port_congestion_data')\nport_data_hist = port_data_hist.toPandas()\nport_data_hist.fillna(0, inplace=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Creating Port Congestion variables","showTitle":true,"inputWidgets":{},"nuid":"2a895280-7c20-4908-b216-741c49c8d7bf"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["port_data_hist['Country'].unique()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"70737b68-b55d-49a2-a5f4-846e20d71df1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[49]: array([&#39;USA&#39;], dtype=object)</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[49]: array([&#39;USA&#39;], dtype=object)</div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Reading forecast Port Congestion\nport_data = spark.read.table('ves_import_congestion_01_03')\nport_data = port_data.toPandas()\nport_data['Week'] = pd.to_datetime(port_data['dates']).dt.week"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0a32d95f-fd00-45d9-9186-0f28a252c040"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Function for creating port congestion variables\ndef create_port_congestion_vars(historical_data, po_create_date, vs_location, vs_region, vs_country, mat_id):\n  historical_data['PO_Create_Date'] = pd.to_datetime(historical_data['PO_Create_Date'])\n  historical_data_port_subset = historical_data[historical_data['Material_No.']==mat_id]\n  last_historical_date = max(historical_data_port_subset['PO_Create_Date'])\n  lead_time_cutoff = historical_data[(historical_data['Material_No.']==mat_id) & \n                                     (historical_data['lead_time']>0)]['lead_time'].describe()[6]\n  po_date_2w, po_date_4w, po_date_6w, location = po_delta_week_dates(po_create_date, vs_location, vs_region)\n  PO_week=pd.to_datetime(po_create_date).week\n  PO_2week=pd.to_datetime(po_date_2w).week\n  PO_4week=pd.to_datetime(po_date_4w).week\n  PO_6week=pd.to_datetime(po_date_6w).week\n  \n  port_congestion_col_dict = {}\n  #Creating historical port congestion variables\n  if vs_country in ['ca', 'mx']:\n    port_congestion_col_dict['Port_wait_time_mean_2w'] = 0\n    port_congestion_col_dict['Port_wait_time_median_2w'] = 0\n    port_congestion_col_dict['Port_wait_time_max_2w'] = 0\n    port_congestion_col_dict['Port_wait_time_mean_4w'] = 0\n    port_congestion_col_dict['Port_wait_time_median_4w'] = 0\n    port_congestion_col_dict['Port_wait_time_max_4w'] = 0\n    port_congestion_col_dict['Port_wait_time_mean_6w'] = 0\n    port_congestion_col_dict['Port_wait_time_median_6w'] = 0\n    port_congestion_col_dict['Port_wait_time_max_6w'] = 0\n  if vs_country=='us': #(vendors within US)\n    if PO_week<PO_2week:\n      port_congestion_col_dict['Port_wait_time_mean_2w']=port_data_hist[(port_data_hist['PortState']==vs_region) & \n                                                                        (port_data_hist['Week']>=PO_week) & \n                                                                        (port_data_hist['Week']<=PO_2week)]['TotalWait'].mean()\n      port_congestion_col_dict['Port_wait_time_median_2w']=port_data_hist[(port_data_hist['PortState']==vs_region) & \n                                                                          (port_data_hist['Week']>=PO_week) & \n                                                                          (port_data_hist['Week']<=PO_2week)]['TotalWait'].median()\n      port_congestion_col_dict['Port_wait_time_max_2w']=port_data_hist[(port_data_hist['PortState']==vs_region) & \n                                                                       (port_data_hist['Week']>=PO_week) & \n                                                                       (port_data_hist['Week']<=PO_2week)]['TotalWait'].max()\n    else:\n      port_congestion_col_dict['Port_wait_time_mean_2w']=port_data_hist[(port_data_hist['PortState']==vs_region) & \n                                                                        ((port_data_hist['Week']>=PO_week) | \n                                                                        (port_data_hist['Week']<=PO_2week))]['TotalWait'].mean()\n      port_congestion_col_dict['Port_wait_time_median_2w']=port_data_hist[(port_data_hist['PortState']==vs_region) & \n                                                                          ((port_data_hist['Week']>=PO_week) | \n                                                                          (port_data_hist['Week']<=PO_2week))]['TotalWait'].median()\n      port_congestion_col_dict['Port_wait_time_max_2w']=port_data_hist[(port_data_hist['PortState']==vs_region) & \n                                                                       ((port_data_hist['Week']>=PO_week) | \n                                                                       (port_data_hist['Week']<=PO_2week))]['TotalWait'].max()\n    \n    if PO_week<PO_4week:\n      port_congestion_col_dict['Port_wait_time_mean_4w']=port_data_hist[(port_data_hist['PortState']==vs_region) & \n                                                                        (port_data_hist['Week']>=PO_week) & \n                                                                        (port_data_hist['Week']<=PO_4week)]['TotalWait'].mean()\n      port_congestion_col_dict['Port_wait_time_median_4w']=port_data_hist[(port_data_hist['PortState']==vs_region) & \n                                                                          (port_data_hist['Week']>=PO_week) & \n                                                                          (port_data_hist['Week']<=PO_4week)]['TotalWait'].median()\n      port_congestion_col_dict['Port_wait_time_max_4w']=port_data_hist[(port_data_hist['PortState']==vs_region) & \n                                                                       (port_data_hist['Week']>=PO_week) & \n                                                                       (port_data_hist['Week']<=PO_4week)]['TotalWait'].max()\n    else:\n      port_congestion_col_dict['Port_wait_time_mean_4w']=port_data_hist[(port_data_hist['PortState']==vs_region) & \n                                                                        ((port_data_hist['Week']>=PO_week) | \n                                                                        (port_data_hist['Week']<=PO_4week))]['TotalWait'].mean()\n      port_congestion_col_dict['Port_wait_time_median_4w']=port_data_hist[(port_data_hist['PortState']==vs_region) & \n                                                                          ((port_data_hist['Week']>=PO_week) | \n                                                                          (port_data_hist['Week']<=PO_4week))]['TotalWait'].median()\n      port_congestion_col_dict['Port_wait_time_max_4w']=port_data_hist[(port_data_hist['PortState']==vs_region) & \n                                                                       ((port_data_hist['Week']>=PO_week) | \n                                                                       (port_data_hist['Week']<=PO_4week))]['TotalWait'].max()\n    \n    if PO_week<PO_6week:\n      port_congestion_col_dict['Port_wait_time_mean_6w']=port_data_hist[(port_data_hist['PortState']==vs_region) & \n                                                                        (port_data_hist['Week']>=PO_week) & \n                                                                        (port_data_hist['Week']<=PO_6week)]['TotalWait'].mean()\n      port_congestion_col_dict['Port_wait_time_median_6w']=port_data_hist[(port_data_hist['PortState']==vs_region) & \n                                                                          (port_data_hist['Week']>=PO_week) & \n                                                                          (port_data_hist['Week']<=PO_6week)]['TotalWait'].median()\n      port_congestion_col_dict['Port_wait_time_max_6w']=port_data_hist[(port_data_hist['PortState']==vs_region) & \n                                                                       (port_data_hist['Week']>=PO_week) & \n                                                                       (port_data_hist['Week']<=PO_6week)]['TotalWait'].max()\n    else:\n      port_congestion_col_dict['Port_wait_time_mean_6w']=port_data_hist[(port_data_hist['PortState']==vs_region) & \n                                                                        ((port_data_hist['Week']>=PO_week) | \n                                                                        (port_data_hist['Week']<=PO_6week))]['TotalWait'].mean()\n      port_congestion_col_dict['Port_wait_time_median_6w']=port_data_hist[(port_data_hist['PortState']==vs_region) & \n                                                                          ((port_data_hist['Week']>=PO_week) | \n                                                                          (port_data_hist['Week']<=PO_6week))]['TotalWait'].median()\n      port_congestion_col_dict['Port_wait_time_max_6w']=port_data_hist[(port_data_hist['PortState']==vs_region) & \n                                                                       ((port_data_hist['Week']>=PO_week) | \n                                                                       (port_data_hist['Week']<=PO_6week))]['TotalWait'].max()\n    \n  elif ((vs_country=='au') | (vs_country=='vt') | (vs_country=='tw')): #(vendors in APAC)\n    if PO_week<PO_2week:\n      port_congestion_col_dict['Port_wait_time_mean_2w']=port_data_hist[((port_data_hist['Country']==vs_country) |\n                                                                         (port_data_hist['Coast']=='West Coast'))& \n                                                                        (port_data_hist['Week']>=PO_week) & \n                                                                        (port_data_hist['Week']<=PO_2week)]['TotalWait'].mean()\n      port_congestion_col_dict['Port_wait_time_median_2w']=port_data_hist[((port_data_hist['Country']==vs_country) |(port_data_hist['Coast']=='West Coast'))& \n                                                (port_data_hist['Week']>=PO_week) & (port_data_hist['Week']<=PO_2week)]['TotalWait'].median()\n      port_congestion_col_dict['Port_wait_time_max_2w']=port_data_hist[((port_data_hist['Country']==vs_country) |(port_data_hist['Coast']=='West Coast'))& \n                                             (port_data_hist['Week']>=PO_week) & (port_data_hist['Week']<=PO_2week)]['TotalWait'].max()\n    else:\n      port_congestion_col_dict['Port_wait_time_mean_2w']=port_data_hist[((port_data_hist['Country']==vs_country) |\n                                                                         (port_data_hist['Coast']=='West Coast'))& \n                                                                        ((port_data_hist['Week']>=PO_week) | \n                                                                        (port_data_hist['Week']<=PO_2week))]['TotalWait'].mean()\n      port_congestion_col_dict['Port_wait_time_median_2w']=port_data_hist[((port_data_hist['Country']==vs_country) |(port_data_hist['Coast']=='West Coast'))& \n                                                ((port_data_hist['Week']>=PO_week) | (port_data_hist['Week']<=PO_2week))]['TotalWait'].median()\n      port_congestion_col_dict['Port_wait_time_max_2w']=port_data_hist[((port_data_hist['Country']==vs_country) |(port_data_hist['Coast']=='West Coast'))& \n                                             ((port_data_hist['Week']>=PO_week) | (port_data_hist['Week']<=PO_2week))]['TotalWait'].max()\n    \n    if PO_week<PO_4week:\n      port_congestion_col_dict['Port_wait_time_mean_4w']=port_data_hist[((port_data_hist['Country']==vs_country) |(port_data_hist['Coast']=='West Coast'))& (port_data_hist['Week']>=PO_week) & (port_data_hist['Week']<=PO_4week)]['TotalWait'].mean()\n      port_congestion_col_dict['Port_wait_time_median_4w']=port_data_hist[((port_data_hist['Country']==vs_country) |(port_data_hist['Coast']=='West Coast'))& (port_data_hist['Week']>=PO_week) & (port_data_hist['Week']<=PO_4week)]['TotalWait'].median()\n      port_congestion_col_dict['Port_wait_time_max_4w']=port_data_hist[((port_data_hist['Country']==vs_country) |(port_data_hist['Coast']=='West Coast'))& (port_data_hist['Week']>=PO_week) & (port_data_hist['Week']<=PO_4week)]['TotalWait'].max()\n    else:\n      port_congestion_col_dict['Port_wait_time_mean_4w']=port_data_hist[((port_data_hist['Country']==vs_country) |(port_data_hist['Coast']=='West Coast'))& ((port_data_hist['Week']>=PO_week) | (port_data_hist['Week']<=PO_4week))]['TotalWait'].mean()\n      port_congestion_col_dict['Port_wait_time_median_4w']=port_data_hist[((port_data_hist['Country']==vs_country) |(port_data_hist['Coast']=='West Coast'))& ((port_data_hist['Week']>=PO_week) | (port_data_hist['Week']<=PO_4week))]['TotalWait'].median()\n      port_congestion_col_dict['Port_wait_time_max_4w']=port_data_hist[((port_data_hist['Country']==vs_country) |(port_data_hist['Coast']=='West Coast'))& ((port_data_hist['Week']>=PO_week) | (port_data_hist['Week']<=PO_4week))]['TotalWait'].max()\n    \n    if PO_week<PO_6week:\n      port_congestion_col_dict['Port_wait_time_mean_6w']=port_data_hist[((port_data_hist['Country']==vs_country) |(port_data_hist['Coast']=='West Coast'))& (port_data_hist['Week']>=PO_week) & (port_data_hist['Week']<=PO_6week)]['TotalWait'].mean()\n      port_congestion_col_dict['Port_wait_time_median_6w']=port_data_hist[((port_data_hist['Country']==vs_country) |(port_data_hist['Coast']=='West Coast'))& (port_data_hist['Week']>=PO_week) & (port_data_hist['Week']<=PO_6week)]['TotalWait'].median()\n      port_congestion_col_dict['Port_wait_time_max_6w']=port_data_hist[((port_data_hist['Country']==vs_country) |(port_data_hist['Coast']=='West Coast'))& (port_data_hist['Week']>=PO_week) & (port_data_hist['Week']<=PO_6week)]['TotalWait'].max()\n    else:\n      port_congestion_col_dict['Port_wait_time_mean_6w']=port_data_hist[((port_data_hist['Country']==vs_country) |(port_data_hist['Coast']=='West Coast'))& ((port_data_hist['Week']>=PO_week) | (port_data_hist['Week']<=PO_6week))]['TotalWait'].mean()\n      port_congestion_col_dict['Port_wait_time_median_6w']=port_data_hist[((port_data_hist['Country']==vs_country) |(port_data_hist['Coast']=='West Coast'))& ((port_data_hist['Week']>=PO_week) | (port_data_hist['Week']<=PO_6week))]['TotalWait'].median()\n      port_congestion_col_dict['Port_wait_time_max_6w']=port_data_hist[((port_data_hist['Country']==vs_country) |(port_data_hist['Coast']=='West Coast'))& ((port_data_hist['Week']>=PO_week) | (port_data_hist['Week']<=PO_6week))]['TotalWait'].max()\n    \n    \n  elif ((vs_country=='es') | (vs_country=='br') | (vs_country=='de')): #(vendors in South America and EU)\n    if PO_week<PO_2week:\n      port_congestion_col_dict['Port_wait_time_mean_2w']=port_data_hist[((port_data_hist['Country']==vs_country) |(port_data_hist['Coast']=='East Coast'))& (port_data_hist['Week']>=PO_week) & (port_data_hist['Week']<=PO_2week)]['TotalWait'].mean()\n      port_congestion_col_dict['Port_wait_time_median_2w']=port_data_hist[((port_data_hist['Country']==vs_country) |(port_data_hist['Coast']=='East Coast'))& (port_data_hist['Week']>=PO_week) & (port_data_hist['Week']<=PO_2week)]['TotalWait'].median()\n      port_congestion_col_dict['Port_wait_time_max_2w']=port_data_hist[((port_data_hist['Country']==vs_country) |(port_data_hist['Coast']=='East Coast'))& (port_data_hist['Week']>=PO_week) & (port_data_hist['Week']<=PO_2week)]['TotalWait'].max()\n    else:\n      port_congestion_col_dict['Port_wait_time_mean_2w']=port_data_hist[((port_data_hist['Country']==vs_country) |(port_data_hist['Coast']=='East Coast'))& ((port_data_hist['Week']>=PO_week) | (port_data_hist['Week']<=PO_2week))]['TotalWait'].mean()\n      port_congestion_col_dict['Port_wait_time_median_2w']=port_data_hist[((port_data_hist['Country']==vs_country) |(port_data_hist['Coast']=='East Coast'))& ((port_data_hist['Week']>=PO_week) | (port_data_hist['Week']<=PO_2week))]['TotalWait'].median()\n      port_congestion_col_dict['Port_wait_time_max_2w']=port_data_hist[((port_data_hist['Country']==vs_country) |(port_data_hist['Coast']=='East Coast'))& ((port_data_hist['Week']>=PO_week) | (port_data_hist['Week']<=PO_2week))]['TotalWait'].max()\n    \n    if PO_week<PO_4week:\n      port_congestion_col_dict['Port_wait_time_mean_4w']=port_data_hist[((port_data_hist['Country']==vs_country) |(port_data_hist['Coast']=='East Coast'))& (port_data_hist['Week']>=PO_week) & (port_data_hist['Week']<=PO_4week)]['TotalWait'].mean()\n      port_congestion_col_dict['Port_wait_time_median_4w']=port_data_hist[((port_data_hist['Country']==vs_country) |(port_data_hist['Coast']=='East Coast'))& (port_data_hist['Week']>=PO_week) & (port_data_hist['Week']<=PO_4week)]['TotalWait'].median()\n      port_congestion_col_dict['Port_wait_time_max_4w']=port_data_hist[((port_data_hist['Country']==vs_country) |(port_data_hist['Coast']=='East Coast'))& (port_data_hist['Week']>=PO_week) & (port_data_hist['Week']<=PO_4week)]['TotalWait'].max()\n    else:\n      port_congestion_col_dict['Port_wait_time_mean_4w']=port_data_hist[((port_data_hist['Country']==vs_country) |(port_data_hist['Coast']=='East Coast'))& ((port_data_hist['Week']>=PO_week) | (port_data_hist['Week']<=PO_4week))]['TotalWait'].mean()\n      port_congestion_col_dict['Port_wait_time_median_4w']=port_data_hist[((port_data_hist['Country']==vs_country) |(port_data_hist['Coast']=='East Coast'))& ((port_data_hist['Week']>=PO_week) | (port_data_hist['Week']<=PO_4week))]['TotalWait'].median()\n      port_congestion_col_dict['Port_wait_time_max_4w']=port_data_hist[((port_data_hist['Country']==vs_country) |(port_data_hist['Coast']=='East Coast'))& ((port_data_hist['Week']>=PO_week) | (port_data_hist['Week']<=PO_4week))]['TotalWait'].max()\n    \n    if PO_week<PO_6week:\n      port_congestion_col_dict['Port_wait_time_mean_6w']=port_data_hist[((port_data_hist['Country']==vs_country) |(port_data_hist['Coast']=='East Coast'))& (port_data_hist['Week']>=PO_week) & (port_data_hist['Week']<=PO_6week)]['TotalWait'].mean()\n      port_congestion_col_dict['Port_wait_time_median_6w']=port_data_hist[((port_data_hist['Country']==vs_country) |(port_data_hist['Coast']=='East Coast'))& (port_data_hist['Week']>=PO_week) & (port_data_hist['Week']<=PO_6week)]['TotalWait'].median()\n      port_congestion_col_dict['Port_wait_time_max_6w']=port_data_hist[((port_data_hist['Country']==vs_country) |(port_data_hist['Coast']=='East Coast'))& (port_data_hist['Week']>=PO_week) & (port_data_hist['Week']<=PO_6week)]['TotalWait'].max()\n    else:\n      port_congestion_col_dict['Port_wait_time_mean_6w']=port_data_hist[((port_data_hist['Country']==vs_country) |(port_data_hist['Coast']=='East Coast'))& ((port_data_hist['Week']>=PO_week) | (port_data_hist['Week']<=PO_6week))]['TotalWait'].mean()\n      port_congestion_col_dict['Port_wait_time_median_6w']=port_data_hist[((port_data_hist['Country']==vs_country) |(port_data_hist['Coast']=='East Coast'))& ((port_data_hist['Week']>=PO_week) | (port_data_hist['Week']<=PO_6week))]['TotalWait'].median()\n      port_congestion_col_dict['Port_wait_time_max_6w']=port_data_hist[((port_data_hist['Country']==vs_country) |(port_data_hist['Coast']=='East Coast'))& ((port_data_hist['Week']>=PO_week) | (port_data_hist['Week']<=PO_6week))]['TotalWait'].max()\n  \n  ##Creating forecast port congestion variables\n  ##If PO date is greater than last historical date then take port congestion variables from port congestion forecast data\n  if (pd.to_datetime(po_create_date) >= pd.to_datetime(last_historical_date)) or (pd.to_datetime(po_create_date) <= pd.to_datetime(last_historical_date) and pd.to_datetime(po_date_2w) >= pd.to_datetime(last_historical_date)):\n    if vs_country == 'us':\n      if PO_week<PO_2week:\n        port_congestion_col_dict['Port_wait_time_mean_2w']= port_data[(port_data['PortState']==vs_region) & \n                                                                               (port_data['Week']>=PO_week) & \n                                                                               (port_data['Week']<=PO_2week)]['TotalWait'].mean()\n        port_congestion_col_dict['Port_wait_time_median_2w']= port_data[(port_data['PortState']==vs_region) & \n                                                                                 (port_data['Week']>=PO_week) & \n                                                                                 (port_data['Week']<=PO_2week)]['TotalWait'].median()\n        port_congestion_col_dict['Port_wait_time_max_2w']= port_data[(port_data['PortState']==vs_region) & \n                                                                                 (port_data['Week']>=PO_week) & \n                                                                                 (port_data['Week']<=PO_2week)]['TotalWait'].max()\n      else:\n        port_congestion_col_dict['Port_wait_time_mean_2w']= port_data[(port_data['PortState']==vs_region) & \n                                                                               ((port_data['Week']>=PO_week) | \n                                                                               (port_data['Week']<=PO_2week))]['TotalWait'].mean()\n        port_congestion_col_dict['Port_wait_time_median_2w']= port_data[(port_data['PortState']==vs_region) & \n                                                                                 ((port_data['Week']>=PO_week) | \n                                                                                 (port_data['Week']<=PO_2week))]['TotalWait'].median()\n        port_congestion_col_dict['Port_wait_time_max_2w']= port_data[(port_data['PortState']==vs_region) & \n                                                                                 ((port_data['Week']>=PO_week) | \n                                                                                 (port_data['Week']<=PO_2week))]['TotalWait'].max()\n      \n      if PO_week<PO_4week:\n        port_congestion_col_dict['Port_wait_time_mean_4w']= port_data[(port_data['PortState']==vs_region) & \n                                                                               (port_data['Week']>=PO_week) & \n                                                                               (port_data['Week']<=PO_4week)]['TotalWait'].mean()\n        port_congestion_col_dict['Port_wait_time_median_4w']= port_data[(port_data['PortState']==vs_region) & \n                                                                                 (port_data['Week']>=PO_week) & \n                                                                                 (port_data['Week']<=PO_4week)]['TotalWait'].median()\n        port_congestion_col_dict['Port_wait_time_max_4w']= port_data[(port_data['PortState']==vs_region) & \n                                                                                 (port_data['Week']>=PO_week) & \n                                                                                 (port_data['Week']<=PO_4week)]['TotalWait'].max()\n      else:\n        port_congestion_col_dict['Port_wait_time_mean_4w']= port_data[(port_data['PortState']==vs_region) & \n                                                                               ((port_data['Week']>=PO_week) | \n                                                                               (port_data['Week']<=PO_4week))]['TotalWait'].mean()\n        port_congestion_col_dict['Port_wait_time_median_4w']= port_data[(port_data['PortState']==vs_region) & \n                                                                                 ((port_data['Week']>=PO_week) | \n                                                                                 (port_data['Week']<=PO_4week))]['TotalWait'].median()\n        port_congestion_col_dict['Port_wait_time_max_4w']= port_data[(port_data['PortState']==vs_region) & \n                                                                                 ((port_data['Week']>=PO_week) | \n                                                                                 (port_data['Week']<=PO_4week))]['TotalWait'].max()\n      \n      if PO_week<PO_6week:\n        port_congestion_col_dict['Port_wait_time_mean_6w']= port_data[(port_data['PortState']==vs_region) & \n                                                                               (port_data['Week']>=PO_week) & \n                                                                               (port_data['Week']<=PO_6week)]['TotalWait'].mean()\n        port_congestion_col_dict['Port_wait_time_median_6w']= port_data[(port_data['PortState']==vs_region) & \n                                                                                 (port_data['Week']>=PO_week) & \n                                                                                 (port_data['Week']<=PO_6week)]['TotalWait'].median()\n        port_congestion_col_dict['Port_wait_time_max_6w']= port_data[(port_data['PortState']==vs_region) & \n                                                                                 (port_data['Week']>=PO_week) & \n                                                                                 (port_data['Week']<=PO_6week)]['TotalWait'].max()\n      else:\n        port_congestion_col_dict['Port_wait_time_mean_6w']= port_data[(port_data['PortState']==vs_region) & \n                                                                               ((port_data['Week']>=PO_week) | \n                                                                               (port_data['Week']<=PO_6week))]['TotalWait'].mean()\n        port_congestion_col_dict['Port_wait_time_median_6w']= port_data[(port_data['PortState']==vs_region) & \n                                                                                 ((port_data['Week']>=PO_week) | \n                                                                                 (port_data['Week']<=PO_6week))]['TotalWait'].median()\n        port_congestion_col_dict['Port_wait_time_max_6w']= port_data[(port_data['PortState']==vs_region) & \n                                                                                 ((port_data['Week']>=PO_week) | \n                                                                                 (port_data['Week']<=PO_6week))]['TotalWait'].max()\n    elif ((vs_country=='au') | (vs_country=='vt') | (vs_country=='tw')):\n      if PO_week<PO_2week:\n        port_congestion_col_dict['Port_wait_time_mean_2w']= port_data[((port_data['Country']==vs_country) |\n                                                                               (port_data['Coast']=='West Coast'))&\n                                                                               (port_data['Week']>=PO_week) & \n                                                                               (port_data['Week']<=PO_2week)]['TotalWait'].mean()\n        port_congestion_col_dict['Port_wait_time_median_2w']= port_data[((port_data['Country']==vs_country) |\n                                                                               (port_data['Coast']=='West Coast'))&\n                                                                                 (port_data['Week']>=PO_week) & \n                                                                                 (port_data['Week']<=PO_2week)]['TotalWait'].median()\n        port_congestion_col_dict['Port_wait_time_max_2w']= port_data[((port_data['Country']==vs_country) |\n                                                                               (port_data['Coast']=='West Coast'))&\n                                                                                 (port_data['Week']>=PO_week) & \n                                                                                 (port_data['Week']<=PO_2week)]['TotalWait'].max()\n      else:\n        port_congestion_col_dict['Port_wait_time_mean_2w']= port_data[((port_data['Country']==vs_country) |\n                                                                               (port_data['Coast']=='West Coast'))&\n                                                                               ((port_data['Week']>=PO_week) | \n                                                                               (port_data['Week']<=PO_2week))]['TotalWait'].mean()\n        port_congestion_col_dict['Port_wait_time_median_2w']= port_data[((port_data['Country']==vs_country) |\n                                                                               (port_data['Coast']=='West Coast'))&\n                                                                                 ((port_data['Week']>=PO_week) | \n                                                                                 (port_data['Week']<=PO_2week))]['TotalWait'].median()\n        port_congestion_col_dict['Port_wait_time_max_2w']= port_data[((port_data['Country']==vs_country) |\n                                                                               (port_data['Coast']=='West Coast'))&\n                                                                                 ((port_data['Week']>=PO_week) | \n                                                                                 (port_data['Week']<=PO_2week))]['TotalWait'].max()\n      \n      if PO_week<PO_4week:\n        port_congestion_col_dict['Port_wait_time_mean_4w']= port_data[((port_data['Country']==vs_country) |\n                                                                               (port_data['Coast']=='West Coast'))&\n                                                                               (port_data['Week']>=PO_week) & \n                                                                               (port_data['Week']<=PO_4week)]['TotalWait'].mean()\n        port_congestion_col_dict['Port_wait_time_median_4w']= port_data[((port_data['Country']==vs_country) |\n                                                                               (port_data['Coast']=='West Coast'))&\n                                                                                 (port_data['Week']>=PO_week) & \n                                                                                 (port_data['Week']<=PO_4week)]['TotalWait'].median()\n        port_congestion_col_dict['Port_wait_time_max_4w']= port_data[((port_data['Country']==vs_country) |\n                                                                               (port_data['Coast']=='West Coast'))&\n                                                                                 (port_data['Week']>=PO_week) & \n                                                                                 (port_data['Week']<=PO_4week)]['TotalWait'].max()\n      else:\n        port_congestion_col_dict['Port_wait_time_mean_4w']= port_data[((port_data['Country']==vs_country) |\n                                                                               (port_data['Coast']=='West Coast'))&\n                                                                               ((port_data['Week']>=PO_week) | \n                                                                               (port_data['Week']<=PO_4week))]['TotalWait'].mean()\n        port_congestion_col_dict['Port_wait_time_median_4w']= port_data[((port_data['Country']==vs_country) |\n                                                                               (port_data['Coast']=='West Coast'))&\n                                                                                 ((port_data['Week']>=PO_week) | \n                                                                                 (port_data['Week']<=PO_4week))]['TotalWait'].median()\n        port_congestion_col_dict['Port_wait_time_max_4w']= port_data[((port_data['Country']==vs_country) |\n                                                                               (port_data['Coast']=='West Coast'))&\n                                                                                 ((port_data['Week']>=PO_week) | \n                                                                                 (port_data['Week']<=PO_4week))]['TotalWait'].max()\n      \n      if PO_week < PO_6week:\n        port_congestion_col_dict['Port_wait_time_mean_6w']= port_data[((port_data['Country']==vs_country) |\n                                                                               (port_data['Coast']=='West Coast'))&\n                                                                               (port_data['Week']>=PO_week) & \n                                                                               (port_data['Week']<=PO_6week)]['TotalWait'].mean()\n        port_congestion_col_dict['Port_wait_time_median_6w']= port_data[((port_data['Country']==vs_country) |\n                                                                               (port_data['Coast']=='West Coast'))&\n                                                                                 (port_data['Week']>=PO_week) & \n                                                                                 (port_data['Week']<=PO_6week)]['TotalWait'].median()\n        port_congestion_col_dict['Port_wait_time_max_6w']= port_data[((port_data['Country']==vs_country) |\n                                                                               (port_data['Coast']=='West Coast'))&\n                                                                                 (port_data['Week']>=PO_week) & \n                                                                                 (port_data['Week']<=PO_6week)]['TotalWait'].max()\n      else:\n        port_congestion_col_dict['Port_wait_time_mean_6w']= port_data[((port_data['Country']==vs_country) |\n                                                                               (port_data['Coast']=='West Coast'))&\n                                                                               ((port_data['Week']>=PO_week) | \n                                                                               (port_data['Week']<=PO_6week))]['TotalWait'].mean()\n        port_congestion_col_dict['Port_wait_time_median_6w']= port_data[((port_data['Country']==vs_country) |\n                                                                               (port_data['Coast']=='West Coast'))&\n                                                                                 ((port_data['Week']>=PO_week) | \n                                                                                 (port_data['Week']<=PO_6week))]['TotalWait'].median()\n        port_congestion_col_dict['Port_wait_time_max_6w']= port_data[((port_data['Country']==vs_country) |\n                                                                               (port_data['Coast']=='West Coast'))&\n                                                                                 ((port_data['Week']>=PO_week) | \n                                                                                 (port_data['Week']<=PO_6week))]['TotalWait'].max()\n    elif ((vs_country=='es') | (vs_country=='br') | (vs_country=='de')):\n      if PO_week<PO_2week:\n        port_congestion_col_dict['Port_wait_time_mean_2w']= port_data[((port_data['Country']==vs_country) |\n                                                                               (port_data['Coast']=='East Coast'))&\n                                                                               (port_data['Week']>=PO_week) & \n                                                                               (port_data['Week']<=PO_2week)]['TotalWait'].mean()\n        port_congestion_col_dict['Port_wait_time_median_2w']= port_data[((port_data['Country']==vs_country) |\n                                                                               (port_data['Coast']=='East Coast'))&\n                                                                                 (port_data['Week']>=PO_week) & \n                                                                                 (port_data['Week']<=PO_2week)]['TotalWait'].median()\n        port_congestion_col_dict['Port_wait_time_max_2w']= port_data[((port_data['Country']==vs_country) |\n                                                                               (port_data['Coast']=='East Coast'))&\n                                                                                 (port_data['Week']>=PO_week) & \n                                                                                 (port_data['Week']<=PO_2week)]['TotalWait'].max()\n      else:\n        port_congestion_col_dict['Port_wait_time_mean_2w']= port_data[((port_data['Country']==vs_country) |\n                                                                               (port_data['Coast']=='East Coast'))&\n                                                                               ((port_data['Week']>=PO_week) | \n                                                                               (port_data['Week']<=PO_2week))]['TotalWait'].mean()\n        port_congestion_col_dict['Port_wait_time_median_2w']= port_data[((port_data['Country']==vs_country) |\n                                                                               (port_data['Coast']=='East Coast'))&\n                                                                                 ((port_data['Week']>=PO_week) | \n                                                                                 (port_data['Week']<=PO_2week))]['TotalWait'].median()\n        port_congestion_col_dict['Port_wait_time_max_2w']= port_data[((port_data['Country']==vs_country) |\n                                                                               (port_data['Coast']=='East Coast'))&\n                                                                                 ((port_data['Week']>=PO_week) | \n                                                                                 (port_data['Week']<=PO_2week))]['TotalWait'].max()\n      if PO_week<PO_4week:\n        port_congestion_col_dict['Port_wait_time_mean_4w']= port_data[((port_data['Country']==vs_country) |\n                                                                               (port_data['Coast']=='East Coast'))&\n                                                                               (port_data['Week']>=PO_week) & \n                                                                               (port_data['Week']<=PO_4week)]['TotalWait'].mean()\n        port_congestion_col_dict['Port_wait_time_median_4w']= port_data[((port_data['Country']==vs_country) |\n                                                                               (port_data['Coast']=='East Coast'))&\n                                                                                 (port_data['Week']>=PO_week) & \n                                                                                 (port_data['Week']<=PO_4week)]['TotalWait'].median()\n        port_congestion_col_dict['Port_wait_time_max_4w']= port_data[((port_data['Country']==vs_country) |\n                                                                               (port_data['Coast']=='East Coast'))&\n                                                                                 (port_data['Week']>=PO_week) & \n                                                                                 (port_data['Week']<=PO_4week)]['TotalWait'].max()\n      else:\n        port_congestion_col_dict['Port_wait_time_mean_4w']= port_data[((port_data['Country']==vs_country) |\n                                                                               (port_data['Coast']=='East Coast'))&\n                                                                               ((port_data['Week']>=PO_week) | \n                                                                               (port_data['Week']<=PO_4week))]['TotalWait'].mean()\n        port_congestion_col_dict['Port_wait_time_median_4w']= port_data[((port_data['Country']==vs_country) |\n                                                                               (port_data['Coast']=='East Coast'))&\n                                                                                 ((port_data['Week']>=PO_week) | \n                                                                                 (port_data['Week']<=PO_4week))]['TotalWait'].median()\n        port_congestion_col_dict['Port_wait_time_max_4w']= port_data[((port_data['Country']==vs_country) |\n                                                                               (port_data['Coast']=='East Coast'))&\n                                                                                 ((port_data['Week']>=PO_week) | \n                                                                                 (port_data['Week']<=PO_4week))]['TotalWait'].max()\n      if PO_week<PO_6week:\n        port_congestion_col_dict['Port_wait_time_mean_6w']= port_data[((port_data['Country']==vs_country) |\n                                                                               (port_data['Coast']=='East Coast'))&\n                                                                               (port_data['Week']>=PO_week) & \n                                                                               (port_data['Week']<=PO_6week)]['TotalWait'].mean()\n        port_congestion_col_dict['Port_wait_time_median_4w']= port_data[((port_data['Country']==vs_country) |\n                                                                               (port_data['Coast']=='East Coast'))&\n                                                                                 (port_data['Week']>=PO_week) & \n                                                                                 (port_data['Week']<=PO_6week)]['TotalWait'].median()\n        port_congestion_col_dict['Port_wait_time_max_6w']= port_data[((port_data['Country']==vs_country) |\n                                                                               (port_data['Coast']=='East Coast'))&\n                                                                                 (port_data['Week']>=PO_week) & \n                                                                                 (port_data['Week']<=PO_6week)]['TotalWait'].max()\n      else:\n        port_congestion_col_dict['Port_wait_time_mean_6w']= port_data[((port_data['Country']==vs_country) |\n                                                                               (port_data['Coast']=='East Coast'))&\n                                                                               ((port_data['Week']>=PO_week) | \n                                                                               (port_data['Week']<=PO_6week))]['TotalWait'].mean()\n        port_congestion_col_dict['Port_wait_time_median_4w']= port_data[((port_data['Country']==vs_country) |\n                                                                               (port_data['Coast']=='East Coast'))&\n                                                                                 ((port_data['Week']>=PO_week) | \n                                                                                 (port_data['Week']<=PO_6week))]['TotalWait'].median()\n        port_congestion_col_dict['Port_wait_time_max_6w']= port_data[((port_data['Country']==vs_country) |\n                                                                               (port_data['Coast']=='East Coast'))&\n                                                                                 ((port_data['Week']>=PO_week) | \n                                                                                 (port_data['Week']<=PO_6week))]['TotalWait'].max()\n  if lead_time_cutoff <= 21:\n    col_list = [port_congestion_col_dict[key] for key in list(port_congestion_col_dict.keys()) if '_2w' in key]\n  elif lead_time_cutoff > 21 and lead_time_cutoff <= 35:\n    col_list = [port_congestion_col_dict[key] for key in list(port_congestion_col_dict.keys()) if '_4w' in key]\n  else:\n    col_list = [port_congestion_col_dict[key] for key in list(port_congestion_col_dict.keys()) if '_6w' in key]\n  \n  return col_list"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"99d9980a-379e-4cf9-ae02-6c07866d6c81"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Feature creation : \"impact to business\"\na=list()\nfor i in smi_1['Impact to Business']:\n  a.append(i.split(' - ')[0])\nsmi_1['Impact types']=a\n\n#cleaning data removing null values, defining the datatypes and renaming columns\nsmi_1.drop(smi_1[smi_1['Vendor Number'].isnull()].index,inplace=True)\nsmi_1['Material Number']=smi_1['Material Number'].astype(np.int64)\nsmi_1['Vendor Number']=smi_1['Vendor Number'].astype(np.int64)\nsmi_1.drop(smi_1[smi_1['Vendor Site'].isnull()].index,inplace=True)\nsmi_1['Vendor Site']=smi_1['Vendor Site'].astype(np.int64)\nsmi_1.rename(columns={'Vendor Number':'Vendor','Vendor Site':'updated_VS_ID','PO Number':'Purchase_Order','Material Number':'Material_No.','Material Order Quantity':'Purchase_Order_Scheduled_Qty'},inplace=True)\nsmi_1['Vendor']=smi_1['Vendor'].astype(np.int64)\nsmi_1['updated_VS_ID']=smi_1['updated_VS_ID'].astype(np.int64)\nsmi_1['Material_No.']=smi_1['Material_No.'].astype(np.int64)\nsmi_1['Purchase_Order_Scheduled_Qty']=smi_1['Purchase_Order_Scheduled_Qty'].astype(float)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0594afcc-73c0-43bd-947f-4c082791ff0c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def smi_var(smi_data, po_create_date, vs_id, mat_id):\n  l3m_date = pd.to_datetime(po_create_date) - timedelta(90)\n  l12m_date = pd.to_datetime(po_create_date) - timedelta(365)\n  no_of_complaints_3_months = smi_data[(smi_data['updated_VS_ID']==vs_id) & \n                                       (smi_data['Material_No.']==mat_id) & \n                                       (smi_data['Incident Date']<=po_create_date) & \n                                       (smi_data['Incident Date']>=l3m_date)]['updated_VS_ID'].shape[0]\n  no_of_complaints_12_months = smi_data[(smi_data['updated_VS_ID']==vs_id) & \n                                        (smi_data['Material_No.']==mat_id) & \n                                        (smi_data['Incident Date']<=po_create_date) & \n                                        (smi_data['Incident Date']>=l12m_date)]['updated_VS_ID'].shape[0]\n  no_of_complaints_3_months_major = smi_data[(smi_data['updated_VS_ID']==vs_id) & \n                                             (smi_data['Material_No.']==mat_id) & \n                                             (smi_data['Incident Date']<=po_create_date) & \n                                             (smi_data['Incident Date']>=l3m_date) & \n                                             (smi_data['Impact types']=='Major')]['updated_VS_ID'].shape[0]\n  no_of_complaints_12_months_major = smi_data[(smi_data['updated_VS_ID']==vs_id) & \n                                              (smi_data['Material_No.']==mat_id) & \n                                              (smi_data['Incident Date']<=po_create_date) & \n                                              (smi_data['Incident Date']>=l12m_date) & \n                                              (smi_data['Impact types']=='Major')]['updated_VS_ID'].shape[0]\n  no_of_complaints_3_months_minor = smi_data[(smi_data['updated_VS_ID']==vs_id) & \n                                             (smi_data['Material_No.']==mat_id) & \n                                             (smi_data['Incident Date']<=po_create_date) & \n                                             (smi_data['Incident Date']>=l3m_date) & \n                                             (smi_data['Impact types']=='Minor')]['updated_VS_ID'].shape[0]\n  no_of_complaints_12_months_minor = smi_data[(smi_data['updated_VS_ID']==vs_id) & \n                                              (smi_data['Material_No.']==mat_id) & \n                                              (smi_data['Incident Date']<=po_create_date) & \n                                              (smi_data['Incident Date']>=l12m_date) & \n                                              (smi_data['Impact types']=='Minor')]['updated_VS_ID'].shape[0]\n  no_of_complaints_3_months_open = smi_data[(smi_data['updated_VS_ID']==vs_id) & \n                                             (smi_data['Material_No.']==mat_id) & \n                                             (smi_data['Incident Date']<=po_create_date) & \n                                             (smi_data['Incident Date']>=l3m_date) & \n                                             (smi_data['Status']=='Open')]['updated_VS_ID'].shape[0]\n  no_of_complaints_3_months_open_major = smi_data[(smi_data['updated_VS_ID']==vs_id) & \n                                                  (smi_data['Material_No.']==mat_id) & \n                                                  (smi_data['Incident Date']<=po_create_date) & \n                                                  (smi_data['Incident Date']>=l3m_date) & \n                                                  (smi_data['Status']=='Open') & \n                                                  (smi_data['Impact types']=='Major')]['updated_VS_ID'].shape[0]\n  no_of_complaints_3_months_open_minor = smi_data[(smi_data['updated_VS_ID']==vs_id) & \n                                                  (smi_data['Material_No.']==mat_id) & \n                                                  (smi_data['Incident Date']<=po_create_date) & \n                                                  (smi_data['Incident Date']>=l3m_date) & \n                                                  (smi_data['Status']=='Open') & \n                                                  (smi_data['Impact types']=='Minor')]['updated_VS_ID'].shape[0]\n  no_of_Complaint_type_Documentation_l12m=smi_data[(smi_data['updated_VS_ID']==vs_id) & \n                                                   (smi_data['Material_No.']==mat_id) & \n                                                   (smi_data['Incident Date']<=po_create_date) & \n                                                   (smi_1['Incident Date']>=l12m_date) & \n                                                   (smi_data['Complaint Types']=='Documentation')]['updated_VS_ID'].shape[0]\n  no_of_Complaint_type_Indigenous_Material_l12m=smi_data[(smi_data['updated_VS_ID']==vs_id) & \n                                                   (smi_data['Material_No.']==mat_id) & \n                                                   (smi_data['Incident Date']<=po_create_date) & \n                                                   (smi_1['Incident Date']>=l12m_date) & \n                                                   (smi_data['Complaint Types']=='Indigenous Material')]['updated_VS_ID'].shape[0]\n  no_of_Complaint_type_Packaging_l12m=smi_data[(smi_data['updated_VS_ID']==vs_id) & \n                                                   (smi_data['Material_No.']==mat_id) & \n                                                   (smi_data['Incident Date']<=po_create_date) & \n                                                   (smi_1['Incident Date']>=l12m_date) & \n                                                   (smi_data['Complaint Types']=='Packaging')]['updated_VS_ID'].shape[0]\n  no_of_Complaint_type_Transportation_l12m=smi_data[(smi_data['updated_VS_ID']==vs_id) & \n                                                   (smi_data['Material_No.']==mat_id) & \n                                                   (smi_data['Incident Date']<=po_create_date) & \n                                                   (smi_1['Incident Date']>=l12m_date) & \n                                                   (smi_data['Complaint Types']=='Transportation')]['updated_VS_ID'].shape[0]\n  no_of_Complaint_type_Ingredient_l12m=smi_data[(smi_data['updated_VS_ID']==vs_id) & \n                                                   (smi_data['Material_No.']==mat_id) & \n                                                   (smi_data['Incident Date']<=po_create_date) & \n                                                   (smi_1['Incident Date']>=l12m_date) & \n                                                   (smi_data['Complaint Types']=='Ingredient')]['updated_VS_ID'].shape[0]\n  no_of_Complaint_type_Comsumer_l12m=smi_data[(smi_data['updated_VS_ID']==vs_id) & \n                                                   (smi_data['Material_No.']==mat_id) & \n                                                   (smi_data['Incident Date']<=po_create_date) & \n                                                   (smi_1['Incident Date']>=l12m_date) & \n                                                   (smi_data['Complaint Types']=='Consumer')]['updated_VS_ID'].shape[0]\n  no_of_Complaint_type_Foreign_Material_l12m=smi_data[(smi_data['updated_VS_ID']==vs_id) & \n                                                   (smi_data['Material_No.']==mat_id) & \n                                                   (smi_data['Incident Date']<=po_create_date) & \n                                                   (smi_1['Incident Date']>=l12m_date) & \n                                                   (smi_data['Complaint Types']=='Foreign Material')]['updated_VS_ID'].shape[0]\n  if no_of_Complaint_type_Documentation_l12m != 0:\n    Complaint_type_Documentation_l12m_distinct = 1\n  else:\n    Complaint_type_Documentation_l12m_distinct = 0\n  \n  if no_of_Complaint_type_Indigenous_Material_l12m != 0:\n    Complaint_type_Indigenous_Material_l12m_distinct = 1\n  else:\n    Complaint_type_Indigenous_Material_l12m_distinct = 0\n  \n  if no_of_Complaint_type_Packaging_l12m != 0:\n    Complaint_type_Packaging_l12m_distinct = 1\n  else:\n    Complaint_type_Packaging_l12m_distinct = 0\n    \n  if no_of_Complaint_type_Transportation_l12m != 0:\n    Complaint_type_Transportation_l12m_distinct = 1\n  else:\n    Complaint_type_Transportation_l12m_distinct = 0\n    \n  if no_of_Complaint_type_Ingredient_l12m != 0:\n    Complaint_type_Ingredient_l12m_distinct = 1\n  else:\n    Complaint_type_Ingredient_l12m_distinct = 0\n    \n  if no_of_Complaint_type_Comsumer_l12m != 0:\n    Complaint_type_Consumer_l12m_distinct = 1\n  else:\n    Complaint_type_Consumer_l12m_distinct = 0\n    \n  if no_of_Complaint_type_Foreign_Material_l12m != 0:\n    Complaint_type_Foreign_Material_l12m_distinct = 1\n  else:\n    Complaint_type_Foreign_Material_l12m_distinct = 0\n  smi_var_list = [no_of_complaints_3_months, no_of_complaints_12_months, no_of_complaints_3_months_major, no_of_complaints_3_months_minor, \n                  no_of_complaints_12_months_major, no_of_complaints_12_months_minor, no_of_complaints_3_months_open, \n                  no_of_complaints_3_months_open_major, no_of_complaints_3_months_open_minor, no_of_Complaint_type_Documentation_l12m, \n                  no_of_Complaint_type_Packaging_l12m, no_of_Complaint_type_Transportation_l12m, no_of_Complaint_type_Ingredient_l12m, \n                  no_of_Complaint_type_Comsumer_l12m, no_of_Complaint_type_Foreign_Material_l12m, no_of_Complaint_type_Indigenous_Material_l12m, \n                  Complaint_type_Documentation_l12m_distinct, Complaint_type_Packaging_l12m_distinct, Complaint_type_Transportation_l12m_distinct, \n                  Complaint_type_Ingredient_l12m_distinct, Complaint_type_Consumer_l12m_distinct, Complaint_type_Foreign_Material_l12m_distinct, \n                  Complaint_type_Indigenous_Material_l12m_distinct]\n  return smi_var_list"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d884ebdc-01a2-4169-abe6-65483bf3d1be"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#list of columns smi cols kept \nsmi_col_list = ['no.of.complaint_3_months', 'no.of.complaint_12_months', 'no.of.complaint_3_months_major', 'no.of.complaint_3_months_minor', \n                'no.of.complaint_12_months_major', 'no.of.complaint_12_months_minor', 'no.of.complaint_3_months_open', \n                'no.of.complaint_3_months_open_major', 'no.of.complaint_3_months_open_minor', 'no.of.Complaint_type_Documentation_l12m', \n                'no.of.Complaint_type_Packaging_l12m', 'no.of.Complaint_type_Transportation_l12m', 'no.of.Complaint_type_Ingredient_l12m', \n                'no.of.Complaint_type_Consumer_l12m', 'no.of.Complaint_type_Foreign_Material_l12m', \n                'no.of.Complaint_type_Indigenous_Material_l12m', 'Complaint_type_Documentation_l12m_distinct', \n                'Complaint_type_Packaging_l12m_distinct', 'Complaint_type_Transportation_l12m_distinct', 'Complaint_type_Ingredient_l12m_distinct', \n                'Complaint_type_Consumer_l12m_distinct', 'Complaint_type_Foreign_Material_l12m_distinct', \n                'Complaint_type_Indigenous_Material_l12m_distinct']"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e8935b19-1841-4053-bbc4-3be3ce0cfc79"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["fin.drop(fin[fin['Risk Level'].isnull()].index,inplace=True)\ndata1=pd.DataFrame(fin['Risk Level'])\ndata1['Rating']=fin['Rating']\ndata2=pd.get_dummies(data1)\nfinancial=pd.concat([fin,data2],axis=1)\nfinancial.drop(['Risk Level','Rating'],axis=1,inplace=True)\nfinancial.rename(columns={'Supplier Number':'Vendor'},inplace=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1e11eba4-42c5-49d9-9a33-db943f6f4b19"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["freq=pd.get_dummies(freq,columns=['Delivery_freq'])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f3bfbc5f-cc9d-476c-9ce5-57510c88be61"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#po_qty_to_del_qty ratio attribute generation\ndef po_qty_to_del_qty(historical_data, plant_id, vs_id, mat_id, po_create_date, po_qty):\n  historical_data['Delivery_date'] = pd.to_datetime(historical_data['Delivery_date'])\n  historical_data_v1 = historical_data[(historical_data['Plant_ID']==plant_id) & \n                                       (historical_data['Material_No.']==mat_id) & \n                                       (historical_data['updated_VS_ID']==vs_id)]\n  historical_data_v1 = historical_data_v1.sort_values(['Delivery_date'])\n  freq_df = freq[(freq['Plant_ID']==plant_id) & \n                 (freq['updated_VS_ID']==vs_id) & \n                 (freq['Material_No.']==mat_id)][[col for col in freq.columns.tolist() if col != 'days']].drop_duplicates()\n  freq_df.loc[freq_df['Delivery_freq_Daily']==1, 'Delivery_Freq.'] = 'Daily'\n  freq_df.loc[freq_df['Delivery_freq_Weekly']==1, 'Delivery_Freq.'] = 'Weekly'\n  freq_df.loc[freq_df['Delivery_freq_Half Yearly']==1, 'Delivery_Freq.'] = 'Half Yearly'\n  freq_df.loc[freq_df['Delivery_freq_Monthly']==1, 'Delivery_Freq.'] = 'Monthly'\n  freq_df.loc[freq_df['Delivery_freq_Quarterly']==1, 'Delivery_Freq.'] = 'Quarterly'\n  freq_df.loc[freq_df['Delivery_freq_Yearly']==1, 'Delivery_Freq.'] = 'Yearly'\n  freq_df.drop(columns=[col for col in freq_df.columns.tolist() if '_freq_' in col], inplace=True)\n  historical_data_v2 = historical_data_v1.merge(freq_df, on=['Plant_ID', 'updated_VS_ID', 'Material_No.'], how='left')\n  historical_data_v2.reset_index()\n  MovingAverage = 0\n  if (historical_data_v2['Delivery_Freq.'].unique()[0]== 'Daily'):\n    if len(historical_data_v2)<=5:\n      MovingAverage = historical_data_v2['Delivered_Quantity'].mean()\n    else:\n      MovingAverage = historical_data_v2.tail(5)['Delivered_Quantity'].mean()\n  elif (historical_data_v2['Delivery_Freq.'].unique()[0]== 'Weekly'):\n    if len(historical_data_v2)<=2:\n      MovingAverage = historical_data_v2['Delivered_Quantity'].mean()\n    elif len(historical_data_v2)>2:\n      MovingAverage = historical_data_v2.tail(3)['Delivered_Quantity'].mean()\n  else:\n    if len(historical_data_v2)<=2:\n      MovingAverage = historical_data_v2['Delivered_Quantity'].mean()\n    elif len(historical_data_v2)>2:\n      MovingAverage = historical_data_v2.tail(2)['Delivered_Quantity'].mean()\n  \n  POqty_to_AvgDelQty = po_qty/MovingAverage\n  return POqty_to_AvgDelQty"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e18e0ca1-c579-4a21-9534-6a2fe10ea885"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# list of columns to keep for models using internal and external variables\ndef create_col_list_order_int_ext(df):\n  col_list_order = ['vendor_percentage','vendor_material_cnt_per_plant','distance','POqty_to_AvgDelQty','no.of.complaint_3_months',\n                    'no.of.complaint_12_months','no.of.complaint_3_months_major','no.of.complaint_3_months_minor',\n                    'no.of.complaint_12_months_major','no.of.complaint_12_months_minor','no.of.complaint_3_months_open',\n                    'no.of.complaint_3_months_open_major','no.of.complaint_3_months_open_minor','no.of.Complaint_type_Documentation_l12m',\n                    'no.of.Complaint_type_Packaging_l12m','no.of.Complaint_type_Transportation_l12m','no.of.Complaint_type_Ingredient_l12m',\n                    'no.of.Complaint_type_Consumer_l12m','no.of.Complaint_type_Foreign_Material_l12m',\n                    'no.of.Complaint_type_Indigenous_Material_l12m']+[col for col in df.columns.tolist() if '_2W' in col]+[col for col in df.columns.tolist() if '_4W' in col]+[col for col in df.columns.tolist() if '_6W' in col]+[col for col in df.columns.tolist() if 'Port_wait_time_' in col]+[col for col in df.columns.tolist() if 'closed_road_or_infinte_delay_count_' in col]+[col for col in df.columns.tolist() if 'moderate_count_' in col]+[col for col in df.columns.tolist() if 'major_count_' in col]+['coastal_flood_count',\n                    'high_wind_count','dense_smoke_count','tropical_storm_count','wildfire_count','winter_weather_count','blizzard_count',\n                    'cold/wind_chill_count','tropical_depression_count','hurricane_count','heavy_rain_count','marine_tropical_storm_count',\n                    'lakeshore_flood_count','sleet_count','drought_count','marine_dense_fog_count','waterspout_count','frost/freeze_count',\n                    'thunderstorm_wind_count','dense_fog_count','strong_wind_count','marine_thunderstorm_wind_count','tornado_count',\n                    'hail_count','storm_surge/tide_count','marine_high_wind_count','winter_storm_count','extreme_cold/wind_chill_count',\n                    'heat_count','lightning_count','excessive_heat_count','flash_flood_count','flood_count','heavy_snow_count',\n                    'ice_storm_count','waterspout_duration','storm_surge/tide_duration','marine_high_wind_duration',\n                    'marine_tropical_storm_duration','tropical_depression_duration','marine_thunderstorm_wind_duration','dom_or_int_int',\n                    'sku_type_single','nestle_managed_freight_yes','mode_of_transport_road','Material_group_type_R',\n                    'single_or_multisource_single','Risk_Level_High','Risk_Level_Low','Risk_Level_Medium','Rating_A','Rating_B',\n                    'Rating_C','Rating_D','Rating_D_-_FND','Rating_F','Rating_Inactive','Rating_Out_of_Scope','Delivery_freq_Daily',\n                    'Delivery_freq_Half_Yearly','Delivery_freq_Monthly','Delivery_freq_Quarterly','Delivery_freq_Weekly',\n                    'Delivery_freq_Yearly','Complaint_type_Documentation_l12m_distinct','Complaint_type_Packaging_l12m_distinct',\n                    'Complaint_type_Transportation_l12m_distinct','Complaint_type_Ingredient_l12m_distinct',\n                    'Complaint_type_Consumer_l12m_distinct','Complaint_type_Foreign_Material_l12m_distinct',\n                    'Complaint_type_Indigenous_Material_l12m_distinct']\n  return col_list_order"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"70a9bde7-c464-499e-b9aa-aaded1338513"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Getting columns for daily weather data\ndef getting_daily_weather_col_list(historical_data, mat_id):\n  lead_time_cutoff = historical_data[(historical_data['Material_No.']==mat_id) & \n                                     (historical_data['lead_time']>0)]['lead_time'].describe()[6]\n  if lead_time_cutoff <= 21:\n    daily_weather_col_list = ['rainfall_mm_2W', 'snowdepth_2W', 'tempmax_2W', 'tempmin_2W', 'windspeed_2W', 'fog_count_2W', 'snow_count_2W', \n                              'rain_count_2W']\n  elif lead_time_cutoff > 21 and lead_time_cutoff <= 35:\n    daily_weather_col_list = ['rainfall_mm_4W', 'snowdepth_4W', 'tempmax_4W', 'tempmin_4W', 'windspeed_4W', 'fog_count_4W', 'snow_count_4W', \n                              'rain_count_4W']\n  else:\n    daily_weather_col_list = ['rainfall_mm_6W', 'snowdepth_6W', 'tempmax_6W', 'tempmin_6W', 'windspeed_6W', 'fog_count_6W', 'snow_count_6W', \n                              'rain_count_6W']\n  return daily_weather_col_list\n\n#Getting columns for traffic data\ndef getting_traffic_col_list(historical_data, mat_id):\n  lead_time_cutoff = historical_data[(historical_data['Material_No.']==mat_id) & \n                                     (historical_data['lead_time']>0)]['lead_time'].describe()[6]\n  if lead_time_cutoff <= 21:\n    traffic_col_list = ['closed_road_or_infinte_delay_count_2w','moderate_count_2w','major_count_2w']\n  elif lead_time_cutoff > 21 and lead_time_cutoff <= 35:\n    traffic_col_list = ['closed_road_or_infinte_delay_count_4w','moderate_count_4w','major_count_4w']\n  else:\n    traffic_col_list = ['closed_road_or_infinte_delay_count_6w','moderate_count_6w','major_count_6w']\n  return traffic_col_list\n\n#Getting columns for port congestion data\ndef getting_port_congestion_col_list(historical_data, mat_id):\n  lead_time_cutoff = historical_data[(historical_data['Material_No.']==mat_id) & \n                                     (historical_data['lead_time']>0)]['lead_time'].describe()[6]\n  if lead_time_cutoff <= 21:\n    port_congestion_col_list = ['Port_wait_time_mean_2w','Port_wait_time_median_2w','Port_wait_time_max_2w']\n  elif lead_time_cutoff > 21 and lead_time_cutoff <= 35:\n    port_congestion_col_list = ['Port_wait_time_mean_4w','Port_wait_time_median_4w','Port_wait_time_max_4w']\n  else:\n    port_congestion_col_list = ['Port_wait_time_mean_6w','Port_wait_time_median_6w','Port_wait_time_max_6w']\n  return port_congestion_col_list\n\n#Getting columns for port congestion data\ndef getting_extreme_weather_col_list():\n  return imp_ext_weather_count_cols + imp_ext_weather_duration_cols"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3f92ba0b-d474-4ff9-9ad6-9d805cd6cbb0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# list of columns to keep for models using internal variables\ncol_list_order_int = ['vendor_percentage', 'vendor_material_cnt_per_plant', 'distance', 'POqty_to_AvgDelQty', 'no.of.complaint_3_months', 'no.of.complaint_12_months', 'no.of.complaint_3_months_major', 'no.of.complaint_3_months_minor', 'no.of.complaint_12_months_major', 'no.of.complaint_12_months_minor', 'no.of.complaint_3_months_open', 'no.of.complaint_3_months_open_major', 'no.of.complaint_3_months_open_minor', 'no.of.Complaint_type_Documentation_l12m', 'no.of.Complaint_type_Packaging_l12m', 'no.of.Complaint_type_Transportation_l12m', 'no.of.Complaint_type_Ingredient_l12m', 'no.of.Complaint_type_Consumer_l12m', 'no.of.Complaint_type_Foreign_Material_l12m', 'no.of.Complaint_type_Indigenous_Material_l12m', 'dom_or_int_int', 'sku_type_single', 'nestle_managed_freight_yes', 'mode_of_transport_road', 'Material_group_type_R', 'single_or_multisource_single','Risk_Level_High', 'Risk_Level_Low', 'Risk_Level_Medium', 'Rating_A', 'Rating_B', 'Rating_C', 'Rating_D', 'Rating_D_-_FND', 'Rating_F', 'Rating_Inactive', 'Rating_Out_of_Scope', 'Delivery_freq_Daily', 'Delivery_freq_Half_Yearly', 'Delivery_freq_Monthly', 'Delivery_freq_Quarterly', 'Delivery_freq_Weekly', 'Delivery_freq_Yearly', 'Complaint_type_Documentation_l12m_distinct', 'Complaint_type_Packaging_l12m_distinct', 'Complaint_type_Transportation_l12m_distinct', 'Complaint_type_Ingredient_l12m_distinct', 'Complaint_type_Consumer_l12m_distinct', 'Complaint_type_Foreign_Material_l12m_distinct', 'Complaint_type_Indigenous_Material_l12m_distinct']"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6d9bdc40-4906-4f8d-a2a6-37826f3c76ea"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def pred_output(historical_data, plant_id, vs_id, mat_id, po_create_date, po_qty):\n  historical_data_v1 = historical_data[(historical_data['Plant_ID']==plant_id) & \n                                       (historical_data['updated_VS_ID']==vs_id)]\n  vs_location = historical_data_v1['updated_VS_location'].unique()[0]\n  vs_region = historical_data_v1['updated_VS_region'].unique()[0]\n  vs_country = historical_data_v1['updated_VS_country'].unique()[0]\n  if mat_id not in material_best_model['Material_ID'].unique().tolist():#for 3 material, best model is not available hardcoding it with xgboost\n    mat_model = 'xgb_int_ext_reg'\n  else:\n    mat_model = material_best_model[material_best_model['Material_ID']==mat_id]['best_score_model'].unique()[0]\n  \n  #Getting Main Vendor ID from histrical data to get financial data for the corresponding Main Vendor\n  vendor = historical_data_v1[historical_data_v1['Material_No.']==mat_id]['Vendor'].unique()[0]\n  \n  #Getting distance between Plant and VS from historical data\n  distance = historical_data_v1['distance'].unique()[0]\n  \n  #Getting PO Create Month from po_create_date\n  PO_Create_Month = 'PO_Create_Month_'+str(datetime.datetime.strptime(po_create_date, \"%Y-%m-%d\").month)\n  \n  #Getting vendor percentage and vendor material cnt per plant feature from historical data\n  vendor_percentage = historical_data_v1[historical_data_v1['Material_No.']==mat_id]['vendor_percentage'].unique()[0]\n  vendor_material_cnt_per_plant = historical_data_v1[historical_data_v1['Material_No.']==mat_id]['vendor_material_cnt_per_plant'].unique()[0]\n  \n  #Getting SMI Variables corresponding to the PO Create Date\n  smi_var_list = smi_var(smi_1, po_create_date, vs_id, mat_id)\n  \n  #Getting financial data for the main vendor ID generated above, if financial data for a vendor is not available, taking the variables as 0\n  test_fin=financial[financial['Vendor']==vendor]\n  if test_fin.shape[0]>0:\n    vendor_fin_df = financial[financial['Vendor']==vendor][[col for col in financial.columns.tolist() if col != 'Supplier']].drop_duplicates()\n  else:\n    vendor_fin_df = financial[financial['Vendor']==vendor][[col for col in financial.columns.tolist() if col != 'Supplier']].drop_duplicates()\n    for i in vendor_fin_df.columns.tolist():\n      vendor_fin_df.loc[i]=0\n    vendor_fin_df.loc['Vendor']=vendor\n    \n  #Getting freq data for a Plant, Material and VS\n  freq_df = freq[(freq['Plant_ID']==plant_id) & \n                 (freq['updated_VS_ID']==vs_id) & \n                 (freq['Material_No.']==mat_id)][[col for col in freq.columns.tolist() if col != 'days']].drop_duplicates()\n  \n  #Renaming freq column to match with columns in Historical data\n  if 'Delivery_freq_Half Yearly' in freq_df.columns.tolist():\n    freq_df.rename(columns={'Delivery_freq_Half Yearly':'Delivery_freq_Half_Yearly'}, inplace=True)\n    \n  #Getting PO Qty to Average Delivery QTY based on the historical delivery data between an given Plant and a given Vendor for a given Material\n  POqty_to_AvgDelQty = po_qty_to_del_qty(historical_data, plant_id, vs_id, mat_id, po_create_date, po_qty)\n  \n  #Getting the domestic/international flag, sku_type, simgle_or_multisource, mode_of_transport, nestle_managed_frieght, material group type from Historical data\n  dom_or_int_int = historical_data_v1['dom_or_int_int'].unique()[0]\n  sku_type_single = historical_data_v1[historical_data_v1['Material_No.']==mat_id]['sku_type_single'].unique()[0]\n  single_or_multisource_single = historical_data_v1[historical_data_v1['Material_No.']==mat_id]['single_or_multisource_single'].unique()[0]\n  mode_of_transport_road = historical_data_v1[historical_data_v1['Material_No.']==mat_id]['mode_of_transport_road'].unique()[0]\n  nestle_managed_freight_yes = historical_data_v1[historical_data_v1['Material_No.']==mat_id]['nestle_managed_freight_yes'].unique()[0]\n  Material_group_type_R = historical_data_v1[historical_data_v1['Material_No.']==mat_id]['Material_group_type_R'].unique()[0]\n  \n  #Creating a copy from freq df to add other independent features to get the final data containg independent features for predicting lead time\n  df_int = freq_df.copy()\n  df_int['distance'] = distance\n  df_int['vendor_percentage'] = vendor_percentage\n  df_int['vendor_material_cnt_per_plant'] = vendor_material_cnt_per_plant\n#   df_int[PO_Create_Month] = 1\n  \n  #Joining column names with '_' to match with historical data\n  for col in vendor_fin_df.columns.tolist():\n    if ('Risk' in col) or ('Rating' in col):\n      col1 = '_'.join(col.split(' '))\n      df_int[col1] = vendor_fin_df[col].unique()[0]\n  \n  #Adding SMI variables and other features to the independent feature dataset\n  for i in range(len(smi_var_list)):\n    df_int[smi_col_list[i]] = smi_var_list[i]\n  df_int['POqty_to_AvgDelQty'] = POqty_to_AvgDelQty\n  df_int['dom_or_int_int'] = dom_or_int_int\n  df_int['sku_type_single'] = sku_type_single\n  df_int['single_or_multisource_single'] = single_or_multisource_single\n  df_int['mode_of_transport_road'] = mode_of_transport_road\n  df_int['nestle_managed_freight_yes'] = nestle_managed_freight_yes\n  df_int['Material_group_type_R'] = Material_group_type_R\n  df_int = df_int[col_list_order_int]\n  \n  #Getting daily weather data corresponding to VS location and PO Create Date\n  df_int_ext = df_int.copy()\n  daily_weather_col_list = getting_daily_weather_col_list(historical_data, mat_id)\n  traffic_col_list = getting_traffic_col_list(historical_data, mat_id)\n  port_congestion_col_list = getting_port_congestion_col_list(historical_data, mat_id)\n  extreme_weather_col_list = getting_extreme_weather_col_list()\n  #Getting daily weather events\n  weather_var_list = create_daily_weather_vars(po_create_date, vs_location, vs_region, mat_id)\n  #Getting extreme weather events \n  exw_vars = create_exw_vars(po_create_date, vs_location, vs_region, vs_country)\n  #Getting traffic data \n  traffic_vars = create_traffic_vars(po_create_date, plant_id, vs_location, vs_region, vs_id, mat_id)\n  #Getting port congestion \n  port_congestion_vars = create_port_congestion_vars(historical_data, po_create_date, vs_location, vs_region, vs_country, mat_id)\n  \n  for i in range(len(weather_var_list)):\n    df_int_ext[daily_weather_col_list[i]] = weather_var_list[i]\n  \n  for i in range(len(exw_vars)):\n    df_int_ext[extreme_weather_col_list[i]] = exw_vars[i]\n  \n  for i in range(len(traffic_vars)):\n    df_int_ext[traffic_col_list[i]] = traffic_vars[i]\n  \n  for i in range(len(port_congestion_vars)):\n    df_int_ext[port_congestion_col_list[i]] = port_congestion_vars[i]\n  \n  df_int_ext = df_int_ext.reset_index()\n  \n  #Ordering the columns in the same order in which the materials were modelled\n  col_list_order_int_ext = create_col_list_order_int_ext(df_int_ext)\n  df_int_ext = df_int_ext[col_list_order_int_ext]\n  df_int_ext.fillna(0, inplace=True)\n  \n  #Extracting the model object from the directory where the models were saved\n  if mat_model != 'avg':\n    if '_ext' in mat_model:\n      mat_model_name = mat_model.split('_int')[0]\n      file_name = '/dbfs/FileStore/models/' + '2022_03_20/'+str(mat_id)+'/'+mat_model_name+'_int_ext_reg.pkl'\n      loaded_model = pickle.load(open(file_name, \"rb\"))\n      lead_time_pred = loaded_model.predict(df_int_ext)[0]\n      try:\n        eli5_output = eli5.explain_prediction_df(estimator=loaded_model, doc=df_int_ext.iloc[0])\n        eli5_output = eli5_output[['feature', 'weight', 'value']]\n        eli5_output.drop(columns=['value'],inplace=True)\n        eli5_output['method']='eli5'\n      except:\n        explainer = shap.TreeExplainer(loaded_model)\n        shap_values = explainer.shap_values(df_int_ext.iloc[0])\n        eli5_output= pd.DataFrame(shap_values,df_int_ext.columns,columns=['weight'])\n        eli5_output.reset_index(inplace=True)\n        eli5_output.rename(columns={'index':'feature'},inplace=True)\n        eli5_output['method']='shap'\n      eli5_output_v1 = eli5_output[eli5_output['weight']>=0]\n      eli5_output_v1.sort_values(['weight'],ascending=False,inplace=True)\n      eli5_output_v2 = eli5_output_v1[eli5_output_v1['feature']!='<BIAS>']\n      df_int=df_int_ext.transpose().reset_index()\n      df_int.rename(columns={'index':'feature',0:'fet_val'},inplace=True)\n      eli5_output_v2=eli5_output_v2.merge(df_int,on=['feature'],how='inner')\n      for feature,fest_val,index in zip(eli5_output_v2['feature'],eli5_output_v2['fet_val'],eli5_output_v2.index):\n        if (('tempmax'.lower() not in feature.lower()) & ('tempmin'.lower() not in feature.lower())):\n          if fest_val<=0:\n            eli5_output_v2.drop(index,inplace=True)\n          else:\n            pass\n        else:\n          pass\n      eli5_output_v2.reset_index(inplace=True)\n      eli5_output_v2.drop(columns=['index','fet_val'],inplace=True)\n      eli5_output_final = eli5_output_v2.head(5)\n    elif '_int_ext' not in mat_model:\n      file_name = '/dbfs/FileStore/models/' + run_date_phase_1+'/'+str(mat_id)+'/'+mat_model+'.pkl'   #enter file path\n      loaded_model = pickle.load(open(file_name, \"rb\"))\n      bus_day_count_pred = loaded_model.predict(df_int)[0]\n      try:\n        #Generating explainations for predictions with eli5\n        eli5_output = eli5.explain_prediction_df(estimator=loaded_model, doc=df_int.iloc[0])\n        eli5_output = eli5_output[['feature', 'weight', 'value']]\n        eli5_output.drop(columns=['value'],inplace=True)\n        eli5_output['method']='eli5'\n      except:\n        #If eli5 explainations are not available then generating explainations using shap values\n        explainer = shap.TreeExplainer(loaded_model)\n        shap_values = explainer.shap_values(df_int.iloc[0])\n        eli5_output= pd.DataFrame(shap_values,df_int.columns,columns=['weight'])\n        eli5_output.reset_index(inplace=True)\n        eli5_output.rename(columns={'index':'feature'},inplace=True)\n        eli5_output['method']='shap'\n      eli5_output_v1 = eli5_output[eli5_output['weight']>=0]\n      eli5_output_v1.sort_values('weight',ascending=False,inplace=True)\n      eli5_output_v2 = eli5_output_v1[eli5_output_v1['feature']!='<BIAS>']\n      df_int=df_int_ext.transpose().reset_index()\n      df_int.rename(columns={'index':'feature',0:'fet_val'},inplace=True)\n      eli5_output_v2=eli5_output_v2.merge(df_int,on=['feature'],how='inner')\n      for feature,fest_val,index in zip(eli5_output_v2['feature'],eli5_output_v2['fet_val'],eli5_output_v2.index):\n        if (('tempmax'.lower() not in feature.lower()) & ('tempmin'.lower() not in feature.lower())):\n          if fest_val<=0:\n            eli5_output_v2.drop(index,inplace=True)\n          else:\n            pass\n        else:\n          pass\n      eli5_output_v2.reset_index(inplace=True)\n      eli5_output_v2.drop(columns=['index','fet_val'],inplace=True)\n      eli5_output_final = eli5_output_v2.head(5)\n      lead_time_pred = ((pd.to_datetime(po_create_date) + BDay(int(math.ceil(bus_day_count_pred)))) - pd.to_datetime(po_create_date)).days\n  else:\n    #If model is not built for a material then using monthly average as predicted lead time\n    lead_time_pred = historical_data_v1[(historical_data_v1['Material_No.']==mat_id) & \n                                        (historical_data_v1[PO_Create_Month]==1)]['lead_time'].mean()\n    mat_avg = historical_data_v1[(historical_data_v1['Material_No.']==mat_id)]['lead_time'].mean()\n    if lead_time_pred > mat_avg:\n      weight = lead_time_pred-mat_avg\n    else:\n      weight = 0\n    eli5_details = {\n      'feature' : [PO_Create_Month],\n      'weight' : weight,\n      'method' : 'none'\n    }\n    eli5_output_final = pd.DataFrame(eli5_details)\n  \n  #If the lead time is not predicted then, getting the prediction as the average business day count for a Plant, VS and Material combo\n  if math.isnan(lead_time_pred) == True:\n    lead_time_pred = historical_data_v1[(historical_data_v1['Material_No.']==mat_id)]['lead_time'].mean()\n    eli5_details = {\n      'feature' : ['material_average_lead_time'],\n      'weight' : 0,\n      'method' : 'none'\n    }\n    eli5_output_final = pd.DataFrame(eli5_details)\n    \n  return lead_time_pred,eli5_output_final"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Predicting Lead time and identifying the drivers of lead time","showTitle":true,"inputWidgets":{},"nuid":"77d1e757-9a0b-4904-971b-00b3ddee99ed"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# def pred_output(historical_data, plant_id, vs_id, mat_id, po_create_date, po_qty):\n#   historical_data_v1 = historical_data[(historical_data['Plant_ID']==plant_id) & \n#                                        (historical_data['updated_VS_ID']==vs_id)]\n#   vs_location = historical_data_v1['updated_VS_location'].unique()[0]\n#   vs_region = historical_data_v1['updated_VS_region'].unique()[0]\n#   vs_country = historical_data_v1['updated_VS_country'].unique()[0]\n#   if mat_id not in material_best_model['Material_ID'].unique().tolist():#for 3 material, best model is not available hardcoding it with xgboost\n#     mat_model = 'xgb_int_ext_reg'\n#   else:\n#     mat_model = material_best_model[material_best_model['Material_ID']==mat_id]['best_score_model'].unique()[0]\n  \n#   #Getting Main Vendor ID from histrical data to get financial data for the corresponding Main Vendor\n#   vendor = historical_data_v1[historical_data_v1['Material_No.']==mat_id]['Vendor'].unique()[0]\n  \n#   #Getting distance between Plant and VS from historical data\n#   distance = historical_data_v1['distance'].unique()[0]\n  \n#   #Getting PO Create Month from po_create_date\n#   PO_Create_Month = 'PO_Create_Month_'+str(datetime.datetime.strptime(po_create_date, \"%Y-%m-%d\").month)\n  \n#   #Getting vendor percentage and vendor material cnt per plant feature from historical data\n#   vendor_percentage = historical_data_v1[historical_data_v1['Material_No.']==mat_id]['vendor_percentage'].unique()[0]\n#   vendor_material_cnt_per_plant = historical_data_v1[historical_data_v1['Material_No.']==mat_id]['vendor_material_cnt_per_plant'].unique()[0]\n  \n#   #Getting SMI Variables corresponding to the PO Create Date\n#   smi_var_list = smi_var(smi_1, po_create_date, vs_id, mat_id)\n  \n#   #Getting financial data for the main vendor ID generated above, if financial data for a vendor is not available, taking the variables as 0\n#   test_fin=financial[financial['Vendor']==vendor]\n#   if test_fin.shape[0]>0:\n#     vendor_fin_df = financial[financial['Vendor']==vendor][[col for col in financial.columns.tolist() if col != 'Supplier']].drop_duplicates()\n#   else:\n#     vendor_fin_df = financial[financial['Vendor']==vendor][[col for col in financial.columns.tolist() if col != 'Supplier']].drop_duplicates()\n#     for i in vendor_fin_df.columns.tolist():\n#       vendor_fin_df.loc[i]=0\n#     vendor_fin_df.loc['Vendor']=vendor\n    \n#   #Getting freq data for a Plant, Material and VS\n#   freq_df = freq[(freq['Plant_ID']==plant_id) & \n#                  (freq['updated_VS_ID']==vs_id) & \n#                  (freq['Material_No.']==mat_id)][[col for col in freq.columns.tolist() if col != 'days']].drop_duplicates()\n  \n#   #Renaming freq column to match with columns in Historical data\n#   if 'Delivery_freq_Half Yearly' in freq_df.columns.tolist():\n#     freq_df.rename(columns={'Delivery_freq_Half Yearly':'Delivery_freq_Half_Yearly'}, inplace=True)\n    \n#   #Getting PO Qty to Average Delivery QTY based on the historical delivery data between an given Plant and a given Vendor for a given Material\n#   POqty_to_AvgDelQty = po_qty_to_del_qty(historical_data, plant_id, vs_id, mat_id, po_create_date, po_qty)\n  \n#   #Getting the domestic/international flag, sku_type, simgle_or_multisource, mode_of_transport, nestle_managed_frieght, material group type from Historical data\n#   dom_or_int_int = historical_data_v1['dom_or_int_int'].unique()[0]\n#   sku_type_single = historical_data_v1[historical_data_v1['Material_No.']==mat_id]['sku_type_single'].unique()[0]\n#   single_or_multisource_single = historical_data_v1[historical_data_v1['Material_No.']==mat_id]['single_or_multisource_single'].unique()[0]\n#   mode_of_transport_road = historical_data_v1[historical_data_v1['Material_No.']==mat_id]['mode_of_transport_road'].unique()[0]\n#   nestle_managed_freight_yes = historical_data_v1[historical_data_v1['Material_No.']==mat_id]['nestle_managed_freight_yes'].unique()[0]\n#   Material_group_type_R = historical_data_v1[historical_data_v1['Material_No.']==mat_id]['Material_group_type_R'].unique()[0]\n  \n#   #Creating a copy from freq df to add other independent features to get the final data containg independent features for predicting lead time\n#   df_int = freq_df.copy()\n#   df_int['distance'] = distance\n#   df_int['vendor_percentage'] = vendor_percentage\n#   df_int['vendor_material_cnt_per_plant'] = vendor_material_cnt_per_plant\n# #   df_int[PO_Create_Month] = 1\n  \n#   #Joining column names with '_' to match with historical data\n#   for col in vendor_fin_df.columns.tolist():\n#     if ('Risk' in col) or ('Rating' in col):\n#       col1 = '_'.join(col.split(' '))\n#       df_int[col1] = vendor_fin_df[col].unique()[0]\n  \n#   #Adding SMI variables and other features to the independent feature dataset\n#   for i in range(len(smi_var_list)):\n#     df_int[smi_col_list[i]] = smi_var_list[i]\n#   df_int['POqty_to_AvgDelQty'] = POqty_to_AvgDelQty\n#   df_int['dom_or_int_int'] = dom_or_int_int\n#   df_int['sku_type_single'] = sku_type_single\n#   df_int['single_or_multisource_single'] = single_or_multisource_single\n#   df_int['mode_of_transport_road'] = mode_of_transport_road\n#   df_int['nestle_managed_freight_yes'] = nestle_managed_freight_yes\n#   df_int['Material_group_type_R'] = Material_group_type_R\n#   df_int = df_int[col_list_order_int]\n  \n#   #Getting daily weather data corresponding to VS location and PO Create Date\n#   df_int_ext = df_int.copy()\n#   daily_weather_col_list = getting_daily_weather_col_list(historical_data, mat_id)\n#   traffic_col_list = getting_traffic_col_list(historical_data, mat_id)\n#   port_congestion_col_list = getting_port_congestion_col_list(historical_data, mat_id)\n#   extreme_weather_col_list = getting_extreme_weather_col_list()\n#   #Getting daily weather events\n#   weather_var_list = create_daily_weather_vars(po_create_date, vs_location, vs_region, mat_id)\n#   #Getting extreme weather events \n#   exw_vars = create_exw_vars(po_create_date, vs_location, vs_region, vs_country)\n#   #Getting traffic data \n#   traffic_vars = create_traffic_vars(po_create_date, plant_id, vs_location, vs_region, vs_id, mat_id)\n#   #Getting port congestion \n#   port_congestion_vars = create_port_congestion_vars(historical_data, po_create_date, vs_location, vs_region, vs_country, mat_id)\n  \n#   for i in range(len(weather_var_list)):\n#     df_int_ext[daily_weather_col_list[i]] = weather_var_list[i]\n  \n#   for i in range(len(exw_vars)):\n#     df_int_ext[extreme_weather_col_list[i]] = exw_vars[i]\n  \n#   for i in range(len(traffic_vars)):\n#     df_int_ext[traffic_col_list[i]] = traffic_vars[i]\n  \n#   for i in range(len(port_congestion_vars)):\n#     df_int_ext[port_congestion_col_list[i]] = port_congestion_vars[i]\n  \n#   df_int_ext = df_int_ext.reset_index()\n  \n#   #Ordering the columns in the same order in which the materials were modelled\n#   col_list_order_int_ext = create_col_list_order_int_ext(df_int_ext)\n#   df_int_ext = df_int_ext[col_list_order_int_ext]\n#   df_int_ext.fillna(0, inplace=True)\n  \n#   #Extracting the model object from the directory where the models were saved\n#   if mat_model != 'avg':\n#     if '_ext' in mat_model:\n#       mat_model_name = mat_model.split('_int')[0]\n#       file_name = '/dbfs/FileStore/models/' + '2022_03_20/'+str(mat_id)+'/'+mat_model_name+'_int_ext_reg.pkl'\n#       loaded_model = pickle.load(open(file_name, \"rb\"))\n#       lead_time_pred = loaded_model.predict(df_int_ext)[0]\n#       #print(lead_time_pred)\n#       #print(df_int_ext.iloc[0])\n#       #print(eli5.explain_prediction(estimator=loaded_model, doc=df_int_ext.iloc[0]))\n#       eli5_output = eli5.explain_prediction_df(estimator=loaded_model, doc=df_int_ext.iloc[0])\n#       eli5_output = eli5_output[['feature', 'weight', 'value']]\n#       eli5_output.drop(columns=['value'],inplace=True)\n#       eli5_output['method']='eli5'\n#       eli5_output_v1 = eli5_output[eli5_output['weight']>=0]\n#       eli5_output_v1.sort_values(['weight'],ascending=False,inplace=True)\n#       eli5_output_v2 = eli5_output_v1[eli5_output_v1['feature']!='<BIAS>']\n#       df_int=df_int_ext.transpose().reset_index()\n#       df_int.rename(columns={'index':'feature',0:'fet_val'},inplace=True)\n#       eli5_output_v2=eli5_output_v2.merge(df_int,on=['feature'],how='inner')\n#       for feature,fest_val,index in zip(eli5_output_v2['feature'],eli5_output_v2['fet_val'],eli5_output_v2.index):\n#         if (('tempmax'.lower() not in feature.lower()) & ('tempmin'.lower() not in feature.lower())):\n#           if fest_val<=0:\n#             eli5_output_v2.drop(index,inplace=True)\n#           else:\n#             pass\n#         else:\n#           pass\n#       eli5_output_v2.reset_index(inplace=True)\n#       eli5_output_v2.drop(columns=['index'],inplace=True)\n#       eli5_output_final = eli5_output_v2.head(5)\n#     elif '_int_ext' not in mat_model:\n#       file_name = '/dbfs/FileStore/models/' + run_date_phase_1+'/'+str(mat_id)+'/'+mat_model+'.pkl'\n#       loaded_model = pickle.load(open(file_name, \"rb\"))\n#       bus_day_count_pred = loaded_model.predict(df_int)[0]\n#       #Generating explainations for predictions with eli5\n#       eli5_output = eli5.explain_prediction_df(estimator=loaded_model, doc=df_int.iloc[0])\n#       eli5_output = eli5_output[['feature', 'weight', 'value']]\n#       eli5_output.drop(columns=['value'],inplace=True)\n#       eli5_output['method']='eli5'\n#       eli5_output_v1 = eli5_output[eli5_output['weight']>=0]\n#       eli5_output_v1.sort_values('weight',ascending=False,inplace=True)\n#       eli5_output_v2 = eli5_output_v1[eli5_output_v1['feature']!='<BIAS>']\n#       df_int=df_int_ext.transpose().reset_index()\n#       df_int.rename(columns={'index':'feature',0:'feature_val'},inplace=True)\n#       eli5_output_v2=eli5_output_v2.merge(df_int,on=['feature'],how='inner')\n#       for feature,fest_val,index in zip(eli5_output_v2['feature'],eli5_output_v2['feature_val'],eli5_output_v2.index):\n#         if (('tempmax'.lower() not in feature.lower()) & ('tempmin'.lower() not in feature.lower())):\n#           if fest_val<=0:\n#             eli5_output_v2.drop(index,inplace=True)\n#           else:\n#             pass\n#         else:\n#           pass\n#       eli5_output_v2.reset_index(inplace=True)\n#       eli5_output_v2.drop(columns=['index'],inplace=True)\n#       eli5_output_final = eli5_output_v2.head(5)\n#       lead_time_pred = ((pd.to_datetime(po_create_date) + BDay(int(math.ceil(bus_day_count_pred)))) - pd.to_datetime(po_create_date)).days\n#   else:\n#     #If model is not built for a material then using monthly average as predicted lead time\n#     lead_time_pred = historical_data_v1[(historical_data_v1['Material_No.']==mat_id) & \n#                                         (historical_data_v1[PO_Create_Month]==1)]['lead_time'].mean()\n#     mat_avg = historical_data_v1[(historical_data_v1['Material_No.']==mat_id)]['lead_time'].mean()\n#     if lead_time_pred > mat_avg:\n#       weight = lead_time_pred-mat_avg\n#     else:\n#       weight = 0\n#     eli5_details = {\n#       'feature' : [PO_Create_Month],\n#       'weight' : weight,\n#       'method' : 'none'\n#     }\n#     eli5_output_final = pd.DataFrame(eli5_details)\n  \n#   #If the lead time is not predicted then, getting the prediction as the average business day count for a Plant, VS and Material combo\n#   if math.isnan(lead_time_pred) == True:\n#     lead_time_pred = historical_data_v1[(historical_data_v1['Material_No.']==mat_id)]['lead_time'].mean()\n#     eli5_details = {\n#       'feature' : ['material_average_lead_time'],\n#       'weight' : 0,\n#       'method' : 'none'\n#     }\n#     eli5_output_final = pd.DataFrame(eli5_details)\n    \n#   return lead_time_pred,eli5_output_final"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"42233863-0e47-4922-b9a2-4b6d6c62febb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# lead_time_predictor,eli5_output_final  = pred_output(historical_data, 5004, 100922625, 22001236,\n# '2021-08-04',39670.0)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"355ce539-5adc-4a9e-a29e-288df9ae4ae4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# eli5_output_final"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c3e5a6e4-7c4d-47a3-9ee9-df8e7ba57b08"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# lead_time_predictor,eli5_output_final = pred_output(historical_data, 5004, 101042953, 22002218,\n# '2022-01-20',40320.0)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"556b2b1e-dff0-48a8-aa25-648710cdb8f7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# lead_time_predictor,eli5_output_final = pred_output(historical_data, 5004, 100365002, 22002248,\n# '2022-02-28',207.0)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7e1e37bb-077c-4f34-b14d-d40c2a0a6cf3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# lead_time_predictor,eli5_output_final = pred_output(historical_data, 5959, 100838018, 22013999,\n# '2021-12-01',165.0)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f2594c3e-0074-4153-8654-4446c2ec718c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# lead_time_predictor,eli5_output_final = pred_output(historical_data, 5004, 100922611, 43058765,\n# '2022-02-08',1000.0)\n# eli5_output_final"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d66a0cb3-172b-4001-b416-8a564c8b9ac9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# 5004 101042953 22002218 2022-01-20 40320.0\n# 5004 100365002 22002248 2022-02-28 207.0\n# 5004 100922611 43058765 2022-02-08 1000.0\n# 5004 101112438 22001316 2022-03-08 584.0\n# 5959 100838018 22013999 2021-12-01 165.0"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ab4bbec6-684d-4fcd-97c5-97db01e1fc87"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"2.c lead_time_predict","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":1541108005201216}},"nbformat":4,"nbformat_minor":0}

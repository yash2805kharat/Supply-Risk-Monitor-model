{"cells":[{"cell_type":"code","source":["%run \"./2.c lead_time_predict\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Lead time predict notebook import","showTitle":true,"inputWidgets":{},"nuid":"08e4c0ea-43b1-45ef-ba15-9f10f38cfed4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["import pandas as pd\nimport numpy as np\nfrom scipy.stats import norm\n\nimport os\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nimport pickle\nfrom datetime import datetime as dt\nfrom datetime import timedelta\nimport xgboost\nfrom pandas.tseries.offsets import BDay\nimport math\nimport calendar\nimport datetime\nfrom datetime import date, timedelta\n\n%matplotlib inline"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Importing Library","showTitle":true,"inputWidgets":{},"nuid":"5155e56a-f1cb-42fc-8c47-9e9d129b4a15"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["pd.set_option('display.max_rows', 1000)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dee60193-6eba-499e-b772-60ad93c5444e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["h_inv_data='Historical_inventory_rawData_169_03_01'  #enter table name\n#reading historical inventory data\nh_inv = spark.table(h_inv_data)\nh_inv=h_inv.toPandas()\n\n\nMb51_data='consumptionmb51_roh_zpck_28_12'   #enter table name\n# MB51 import data\nMb51 = spark.table(Mb51_data)\nMb51 = Mb51.toPandas()\n\nves_data='model_data_vf_19_01'   #enter table name\n#ves data import\nves = spark.table(ves_data)\nves= ves.toPandas()\nves = ves[ves['PO_Create_Date']!='1888-01-01']\nves = ves[ves['Delivered_Quantity']!=0]\n\nves_w_po='enter file path to VES_data_final_06_12.csv'  \n#reading ves old data to get the planned lead time\nves_old=pd.read_csv(ves_w_po)\n\n\n# models_to_use import\nmodels = spark.table('prediction_models_to_use')\nmodels=models.toPandas()\n\nmaterial_in_scope='enter file path to Material_master.xlsx'\n#reading material description from material_in_scope\nmat_descp=pd.read_excel(material_in_scope)\n\nvendor_description='enter file path to vendor_desc-1.xlsx'\nvendor_desc=pd.read_excel(vendor_description)\n\nfeature_desc='enter file path to feature_description-4.xlsx'\nfeature_desc=pd.read_excel(feature_desc)\n\nsample_input='enter file path to sample_data.xlsx'\nsample_input=pd.read_excel(sample_input)\n\n# model_run_date='2022-02-27'\nmodel_run_date='2022-03-25'  #enter model run date hardcoded"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Files & Tables imported","showTitle":true,"inputWidgets":{},"nuid":"96dad90b-4e5b-4633-b8af-9bd37861a490"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["for_out='forecasting_df1'\npend_out='pendings_df1'\nfore_wit_sps='forecasting_with_sps_df1'\nactual_vs_forecasted_po='actual_vs_forecasted_POs_df1'\nact_vs_fore_int='actual_vs_forecasted_invt_df1'\nSPS_w_non_p_days_v1='SPS_week_noprods_df1'\nleadtime_reasons_sps=\"leadtime_callouts\"\nSPS_leadtime_reasons_output=\"2_SPS\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Output table","showTitle":true,"inputWidgets":{},"nuid":"56c3d3fd-24a7-4466-b56c-46843f6fa1d8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["Start_dates = '2022-02-28'"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Forecast input date","showTitle":true,"inputWidgets":{},"nuid":"cba78ab8-a2e0-412a-85c8-f844fb8534fa"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["*For calculating the SPS (Stockout Possibility Score) consumption, inventory, material received, order placement will be simulated for the materials over the next 27 Weeks.\n*For this the following would be required: \n  1. Daily inventory in Hand\n  2. Historical MB51 consumption\n  3. Identifying the method of reorder namely inventory based reorder point or frequency based reorder point or both\n  4. getting expected lead time to estimate material received date"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"99274d90-d3cd-4887-a8a9-eccf9de4f6c9"}}},{"cell_type":"code","source":["#getting required fields from inventory\nh_inv_f=h_inv[['SnapshotDate','MaterialID','LocationID','BatchID','InventoryStockUnRestricted','InventoryUnitOfMeasure']]\nh_inv_f['SnapshotDate']=pd.to_datetime(h_inv['SnapshotDate'],format=\"%Y-%m-%d\")\n\n# Creating Week attribute \nh_inv_f['Week']=h_inv_f['SnapshotDate'].dt.week\nh_inv_f['SnapshotDate']=pd.to_datetime(h_inv['SnapshotDate'],format=\"%Y-%m-%d\").dt.date"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Calculating Inventory in Hand","showTitle":true,"inputWidgets":{},"nuid":"049c7663-e2d6-4d31-a4c3-ef86fa3f3161"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#To check if material has more than one UoM\ndat_check=h_inv_f[['MaterialID','InventoryUnitOfMeasure']]\ndat_check.drop_duplicates(inplace=True)\n\ndat_check1=pd.pivot_table(dat_check,values='InventoryUnitOfMeasure',index=['MaterialID'],aggfunc='count')\nprint(len(dat_check1['InventoryUnitOfMeasure'].unique()))\ndat_check1['InventoryUnitOfMeasure'].value_counts()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5b2e60e5-5235-4347-80bc-d0efceabc307"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#identifying total inventory stock unrestricted across batches for a given plant,material and day\nh_inv_f['InventoryStockUnRestricted_daily']=h_inv_f.groupby(by=['LocationID','MaterialID','SnapshotDate'])['InventoryStockUnRestricted'].transform(np.sum)\n\n#dropping batchID to get the plant, material and day wise inventory stock unrestricted\nh_inv_f.drop(columns=['BatchID','InventoryStockUnRestricted'],axis=1,inplace=True)\nh_inv_f.drop_duplicates(inplace=True)\n\n#sorting value with respect location ,material, snapshotdate and batch\nh_inv_fi=h_inv_f.sort_values(by=['LocationID','MaterialID','SnapshotDate']).reset_index()\nh_inv_fi.drop(columns='index',axis=1,inplace=True)\nh_inv_fi['SnapshotDate']=pd.to_datetime(h_inv_fi['SnapshotDate'],format=\"%Y-%m-%d\")\nprint(h_inv_fi.shape)\nh_inv_fi.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"61b2dc79-b86e-44c8-b843-38929ed1b4e5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#Code to fill MB51 missing dates\nMb51['Posting_Date'] = pd.to_datetime(Mb51['Posting_Date'])\nMb51matls = Mb51[['Plant', 'Material']].drop_duplicates()\n\n#Populating missing dates\nMb51alldates = pd.DataFrame()\nfor plant, matl in zip(Mb51matls['Plant'], Mb51matls['Material']):\n  Start = min(Mb51[(Mb51['Plant'] == plant) & (Mb51['Material'] == matl)]['Posting_Date'])\n  End = max(Mb51[(Mb51['Plant'] == plant) & (Mb51['Material'] == matl)]['Posting_Date'])\n\n  dRan1 = pd.date_range(start =Start, end =End, freq ='D')\n  dRan1 = pd.DataFrame({'Plant':plant, 'Material': matl, 'Date':dRan1})\n  \n  Mb51alldates = Mb51alldates.append(dRan1, ignore_index= True)\n  \n#merging all dates with MB51\nMb51matls = pd.merge(Mb51alldates, Mb51, left_on = ['Plant', 'Material', 'Date'], right_on = ['Plant', 'Material', 'Posting_Date'], how = 'left')\nMb51matls.drop(['Posting_Date'], inplace = True, axis = 1)\n\n#replacing null values with 0\nMb51matls['Qty_in_BUoM'] = Mb51matls['Qty_in_BUoM'].fillna(0)\n\n#creating week attribute\nMb51matls['week'] = Mb51matls['Date'].dt.week"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Getting Consumption from MB51","showTitle":true,"inputWidgets":{},"nuid":"2d93f4e2-6f62-48ed-96a8-410df634bee5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["Mb51matls['Plant'].unique()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"962947ad-1aa5-42c7-a26b-322ca95c1377"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#Creating inventory consumption data table from MB51  \ninv_con1 = pd.pivot_table(Mb51matls,values='Qty_in_BUoM',index=['Plant','Material','week'],aggfunc=['mean', 'std']).reset_index()\ninv_con1.columns =[s1 + str(s2) for (s1,s2) in inv_con1.columns.tolist()]\ninv_con = inv_con1.rename(columns = {'Plant':'LocationID', 'Material':'MaterialID', 'week': 'Week', 'meanQty_in_BUoM':'daily_mean_consumption', 'stdQty_in_BUoM': 'std_dev_consumption'})"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"57bd20f8-2c33-41ea-b353-21c5f4b6d90a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#1. populating data for reorder point calculations\n\n#dropping null values and infinite values in column POqty_to_AvgDelQty\nves = ves.dropna(subset=['POqty_to_AvgDelQty'])\nves = ves[ves['POqty_to_AvgDelQty']!=np.inf]\n\n#selecting attributes needed from ves data\nves_date=ves[['Plant_ID','Material_No.','PO_Create_Date','Purchase_Order_Scheduled_Qty']]\n\n#Finding the total purchase order quantity for a given plant,material and po create date\nves_date['Total_ordered_QTY'] = ves_date.groupby(by=['Plant_ID','Material_No.','PO_Create_Date'])['Purchase_Order_Scheduled_Qty'].transform(np.sum)\nves_date.drop(columns=['Purchase_Order_Scheduled_Qty'],inplace=True)\nves_date.drop_duplicates(inplace=True)\nves_date.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Reorder Point calculation","showTitle":true,"inputWidgets":{},"nuid":"4c41968c-f9d3-42d8-99d4-d0f9028e52ee"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#2. Getting inventory in hand at the time of order placement\n\n# merging historical inventory with ves_date to get po create and po qty. \nRop1=pd.merge(h_inv_fi,ves_date,how='left',left_on=['LocationID','MaterialID','SnapshotDate'],right_on=['Plant_ID','Material_No.','PO_Create_Date']).reset_index()\nRop1.drop(columns=['index','Plant_ID','Material_No.'],axis=1,inplace=True)\n\n#filtering only the reorder dates from the combined data\nRop1=Rop1[Rop1['Total_ordered_QTY'].notna()]\n\n#sorting reorder point by plant, material and po create date and getting a reference index\nRop1.sort_values(by=['LocationID','MaterialID','PO_Create_Date'],inplace=True)\nRop1.reset_index(inplace=True)\nRop1.reset_index(inplace=True)\nRop1.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dcb11ef9-6fc0-419c-9b92-cd5218198b63"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#3. calculating the days between 2 consecutive orders\ndef checkPrevious(x):\n  try:\n    if((x['LocationID'] == Rop1.loc[x.level_0-1,'LocationID']) and (x['MaterialID'] == Rop1.loc[x.level_0-1, 'MaterialID'])):\n      return (x.PO_Create_Date - Rop1.loc[x.level_0 -1, 'PO_Create_Date']).days\n    else:\n      return 0\n  except:\n    print(\"Exception\")\n    return 0\n\n#getting day gap attibute between 2 purchase orders for the plant, material combinations\nRop1['days']= Rop1.apply(checkPrevious, 1)\nRop1.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"90f73a66-9aed-4ae4-9bda-6d544bf872c5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["* Material orders follow either an inventory based or frequency based reorder Method or a hybrid of both. \n* To classify the materials on the reorder method: \n  1. The % of orders historically placed +/-20% around the historic mean/median inventory at hand at time of order placement and (inventory based method)\n  2. The % of orders placed around +/-20% of the average time between 2 consecutive orders is found (frequency based method)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f374ab02-69c3-48b9-9e14-10643b9a57cc"}}},{"cell_type":"code","source":["#creating a table with unique set of plant and material combinations from the reorder point data\nreorder_method_check=Rop1[['LocationID','MaterialID']]\nreorder_method_check.drop_duplicates(inplace=True)\nreorder_method_check.shape[0]\n\n#mean,median,mode calculation and weightage of it on plant,mat combination to identify the order placement method\nfreqop=[]\ninvtop=[]\ninvtop_2=[]\nmodes=[]\nmedians=[]\nmeans=[]\nfor l_id,m_id in zip(reorder_method_check['LocationID'],reorder_method_check['MaterialID']):\n  a=Rop1[(Rop1['LocationID']==l_id) & (Rop1['MaterialID']==m_id)].copy()\n  c=a['days'].mean()\n  d=a['InventoryStockUnRestricted_daily'].median(axis=0)\n  e=a['InventoryStockUnRestricted_daily'].mean()\n  freqop.append(np.round(((a[(a['days']>=c*.8) & (a['days']<=c*1.2)].shape[0]/a.shape[0])*100),0))\n  invtop.append(np.round(((a[(a['InventoryStockUnRestricted_daily']>=d*.8) & (a['InventoryStockUnRestricted_daily']<=d*1.2)].shape[0]/a.shape[0])*100),0))\n  invtop_2.append(np.round(((a[(a['InventoryStockUnRestricted_daily']>=e*.8) & (a['InventoryStockUnRestricted_daily']<=e*1.2)].shape[0]/a.shape[0])*100),0))\n  modes.append(c)\n  medians.append(d)\n  means.append(e)\n  \n#method weightage along with values\nreorder_method_check['Frequency_Based_OP']=freqop\nreorder_method_check['Inventory_Based_OP_median']=invtop\nreorder_method_check['Inventory_Based_OP_mean']=invtop_2\nreorder_method_check['freq_val']=modes\nreorder_method_check['median_val']=medians\nreorder_method_check['mean_val']=means"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8c93acfc-6fd3-4c0e-8575-78d4dc47e778"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#flagging method of reorder point based on weightage of method (threshold 50%)\naty=[]\nfor fpq, ibm, ibe in zip(reorder_method_check['Frequency_Based_OP'],reorder_method_check['Inventory_Based_OP_median'],reorder_method_check['Inventory_Based_OP_mean']):\n  if (fpq<50) and (ibm<50) and (ibe<50): #if all values are less than threshold its hybrid\n    aty.append('hybrid')\n  else:\n    if (fpq>ibm) and (ibm>=ibe): # order percentage of freq>median>=mean trigger method as frequency\n      aty.append('frequency')\n    elif (fpq>ibe) and (ibm<=ibe): #order percentage of freq>mean>=median trigger method as frequency\n      aty.append('frequency')\n    elif (ibm>ibe) and (ibe>=fpq): #order percentage of median>mean>=frequency trigger method as median\n      aty.append('median')\n    elif (ibm>fpq) and (ibe<=fpq): #order percentage of median>frequency>=mean trigger method as median\n      aty.append('median')\n    elif (ibe>ibm) and (ibm>=fpq): #order percentage of mean>median>=frequency trigger method as mean\n      aty.append('mean')\n    elif (ibe>fpq) and (ibm<=fpq): #order percentage of mean>frequency>=median trigger method as mean\n      aty.append('mean')\n    elif (ibm==ibe) and (ibm>fpq): #order percentage of mean=median>frequency trigger method as median\n      aty.append('median')\n    elif (ibm==ibe) and (ibm==fpq): #order percentage of freq=mean=median trigger method as frequency\n      aty.append('frequency')\n    elif (fpq==ibm) and (ibm>ibe): #order percentage of freq=median>mean trigger method as frequency\n      aty.append('frequency')\n    elif (fpq==ibe) and (ibm<ibe): #order percentage of freq=mean>median trigger method as frequency\n      aty.append('frequency')\n\n#creating attribute for method flag\nreorder_method_check['flag']=aty\nreorder_method_check.reset_index(inplace=True)\nreorder_method_check.drop(['index'],axis=1,inplace=True)\n\n#tagging combinations of plant, material which has median_val 0 and flag median as not defined\nreorder_method_check.loc[(reorder_method_check['median_val']==0) & (reorder_method_check['flag']=='median'),'flag']='not_defined'\n\n#tagging combinations of plant, material with only one order which has freq_val 0 and flag frequency as not defined\nreorder_method_check.loc[(reorder_method_check['freq_val']==0) & (reorder_method_check['flag']=='frequency'),'flag']='not_defined'\nreorder_method_check['flag'].value_counts()\n\n#defining column data types \nreorder_method_check['mean_val']=round(reorder_method_check['mean_val'],0)\nreorder_method_check['mean_val']=reorder_method_check['mean_val'].astype(np.int64)\nreorder_method_check['freq_val']=round(reorder_method_check['freq_val'],0)\nreorder_method_check['freq_val']=reorder_method_check['freq_val'].astype(np.int64)\n\n#checking no of materials\nlen(reorder_method_check[(reorder_method_check['flag']!='not_defined')]['MaterialID'].unique())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"373849ff-6ce6-4b93-8c17-cd9efb483ade"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["reorder_method_check['flag'].value_counts()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d24eed06-1c4b-4a41-bbb2-3f7990c8288f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["reorder_method_check[reorder_method_check['flag']=='not_defined']"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d80528ff-3684-4063-8c69-e1e493270402"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#Finding the historic average fullfillment % of delivery quantity w.r.t to Purchase order qty.\nDelivery_qty = pd.pivot_table(ves,values=['Purchase_Order_Scheduled_Qty','Delivered_Quantity'],index=['Plant_ID','Material_No.', 'updated_VS_ID'],aggfunc='sum').reset_index()\nDelivery_qty['Fulfillment_rate'] = Delivery_qty['Delivered_Quantity']/Delivery_qty['Purchase_Order_Scheduled_Qty']\nDelivery_qty.loc[Delivery_qty['Fulfillment_rate']>1, 'Fulfillment_rate'] =1"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Vendor Attributes: Share of orders, Delivery Fulfillment Rate, Expected Order Quantity","showTitle":true,"inputWidgets":{},"nuid":"82199310-a4aa-4b78-9783-4e842347707b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#Finding the vendor share for a plant, material combination for purchase order\nOrder_share = Delivery_qty.copy()\nOrder_share.drop(['Delivered_Quantity', 'Fulfillment_rate'], inplace = True, axis =1)\n\nTotal_order = Order_share.groupby(['Material_No.', 'Plant_ID'])['Purchase_Order_Scheduled_Qty'].sum().reset_index()\nOrder_share = pd.merge(Order_share, Total_order, how = 'left', on = ['Material_No.', 'Plant_ID'])\nOrder_share['Vendor_share'] = Order_share['Purchase_Order_Scheduled_Qty_x']/Order_share['Purchase_Order_Scheduled_Qty_y']\nOrder_share.drop(['Purchase_Order_Scheduled_Qty_x', 'Purchase_Order_Scheduled_Qty_y'], inplace = True, axis = 1)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4c11c010-66af-43c4-b3a8-59f904b3cd07"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#Calculating order quantity for each vendor for a given plant , material combination and estimating how much the vendor will deliver\n\n#getting total reorder quantity for plant, material combo\nRoQ_Vendor=pd.pivot_table(Rop1.round({'Total_ordered_QTY':0}),values='Total_ordered_QTY',index=['LocationID','MaterialID'],aggfunc='mean').reset_index()\nRoQ_Vendor['Total_ordered_QTY']=RoQ_Vendor['Total_ordered_QTY'].astype(np.int64)\n\n#merging reorder quantity with order share to get vendor wise reorder quantity\nRoQ_Vendor = pd.merge(RoQ_Vendor, Order_share, how = 'left', right_on = ['Plant_ID', 'Material_No.'], left_on = ['LocationID', 'MaterialID'])\nRoQ_Vendor['Vendor_ROQ'] = RoQ_Vendor['Vendor_share']*RoQ_Vendor['Total_ordered_QTY']\nRoQ_Vendor['Vendor_ROQ'] = RoQ_Vendor['Vendor_ROQ'].round(0)\nRoQ_Vendor.drop(['Material_No.', 'Plant_ID', 'Vendor_share'], axis =1, inplace= True)\n\nRoQ_Vendor.rename(columns={'Total_ordered_QTY':'Avg_ordered_QTY'},inplace=True)\nRoQ_Vendor.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2a37311a-681f-4305-8325-1a6d41ae2de7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# 1. calculating average leadtime for plant, material combinations\n#cleaning ves data for getting lead time\nldt = ves.copy()\nldt = ldt.dropna(subset=['POqty_to_AvgDelQty'])\nldt = ldt[ldt['POqty_to_AvgDelQty']!=np.inf]\n\n#creating lead time attribute\nldt=ldt[['Plant_ID','Material_No.','First_GR_Date','PO_Create_Date']]\nldt['First_GR_Date']=pd.to_datetime(ldt['First_GR_Date'],utc=True)\nldt['First_GR_Date']=ldt['First_GR_Date'].dt.date\nldt['First_GR_Date']=pd.to_datetime(ldt['First_GR_Date'])\nldt['lead_time']=(ldt['First_GR_Date']-ldt['PO_Create_Date']).dt.days"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Getting Lead times","showTitle":true,"inputWidgets":{},"nuid":"a70c17bc-59c4-4aed-be94-9eaf78c704cc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# 2. Getting the Planned lead time\n\npldt=ves_old[['Plant','Material No.','Sum of Planned Days']].copy()\nprint('number of planned lead time records less than one',pldt[pldt['Sum of Planned Days']<1].shape[0])\n\n#identifying average planned lead time for a given plant and material\npldt_pivot=pd.pivot_table(pldt,values='Sum of Planned Days',index=['Plant','Material No.'],aggfunc='mean').reset_index()\npldt_pivot['Sum of Planned Days']=round(pldt_pivot['Sum of Planned Days'],0)\nprint('number of unique materials',len(pldt_pivot['Material No.'].unique()))\n\n#renaming the columns\npldt_pivot.rename(columns={'Plant':'LocationID','Material No.':'MaterialID','Sum of Planned Days':'Planned_avg_lead_time'},inplace=True)\npldt_pivot.head(3)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b24dd5ea-2873-43cb-9a06-00e4ed22d0eb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#lead time data cut w.r.t plant,material\nldt_cut=pd.pivot_table(ldt,values='lead_time',index=['Plant_ID','Material_No.'],aggfunc='mean').reset_index()\n\n#merging RoQ_Vendor with lead time\nvendor_plant_data=pd.merge(RoQ_Vendor,ldt_cut,left_on=['LocationID','MaterialID'],right_on=['Plant_ID','Material_No.'],how='inner')\nvendor_plant_data.drop(columns=['Plant_ID','Material_No.'],inplace=True)\nvendor_plant_data['lead_time']=round(vendor_plant_data['lead_time'],0)\nvendor_plant_data.rename(columns={'lead_time':'Avg_lead_time'},inplace=True)\nvendor_plant_data['Avg_lead_time']=vendor_plant_data['Avg_lead_time'].astype(np.int64)\n\n#merging vendor_plant_data with delivery qty\nvendor_plant_data = pd.merge(vendor_plant_data, Delivery_qty, how = 'left', left_on = ['LocationID', 'MaterialID', 'updated_VS_ID'], right_on = ['Plant_ID', 'Material_No.', 'updated_VS_ID'])\nvendor_plant_data.drop(['Plant_ID', 'Material_No.', 'Delivered_Quantity', 'Purchase_Order_Scheduled_Qty'], axis =1, inplace = True)\n\n#merging vendor_plant_data with planned lead time\nvendor_plant_data = pd.merge(vendor_plant_data, pldt_pivot, how = 'inner', on = ['LocationID', 'MaterialID'])\n\n#merging vendor_plant_data with check to get the flag and mthod values\nvendor_plant_data=pd.merge(vendor_plant_data,reorder_method_check, on =['LocationID','MaterialID'],how='left')\nvendor_plant_data.drop(columns=['Frequency_Based_OP','Inventory_Based_OP_median','Inventory_Based_OP_mean'],axis=1,inplace=True)\nvendor_plant_data=vendor_plant_data[vendor_plant_data['flag']!='not_defined']"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Compiling the Vendor - Plant data: Lead times, RoQ, Fulfillment, Reorder method","showTitle":true,"inputWidgets":{},"nuid":"e307eded-b294-4ecc-b252-f67f75b6b3e2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Checking common data availability across inventory and plant-vendor data\n\n# creating table with unique plant, material combination from vendor_plant_data\nRop12=vendor_plant_data[['LocationID','MaterialID']]\nRop12.drop_duplicates(inplace=True)\n\n#getting plant and material only for those which has historical inventory data on Start Date\ninv_check=h_inv_fi[(h_inv_fi['SnapshotDate'] == Start_dates)][['LocationID','MaterialID']]\ninv_check.drop_duplicates(inplace=True)\n\n#filtering the plant and materials data which has historical inventory data on Start_dates\nprint(Rop12.shape,vendor_plant_data.shape)\nvendor_plant_data=pd.merge(vendor_plant_data,inv_check,on=['LocationID','MaterialID'],how='inner')\nRop12=pd.merge(Rop12,inv_check,on=['LocationID','MaterialID'],how='inner')\nprint(Rop12.shape,vendor_plant_data.shape)\nprint('Unique material count: ',len(Rop12['MaterialID'].unique()))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cc170057-49f6-426c-a7ca-cb78550c86bc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# def order_placed is used by model_based_prediction to determine when to place the order\ndef order_placed (SnapshotDate,Plants,Matls,Exp_invt,counter):\n  \n  #getting planned lead time\n  lead_time=pldt_pivot[(pldt_pivot['LocationID']==Plants) & (pldt_pivot['MaterialID']==Matls)]['Planned_avg_lead_time'].values[0]\n  \n  op=pd.DataFrame(data=[[SnapshotDate,Plants,Matls,Exp_invt,lead_time,counter]],columns=['SnapshotDate','LocationID','MaterialID','InventoryStockUnRestricted_daily','lead_time','counter'])\n  op['SnapshotDate']=pd.to_datetime(op['SnapshotDate']).dt.date\n  op['SnapshotDate']=pd.to_datetime(op['SnapshotDate'])\n  \n  # getting planned_gr date with extended_gr date of 2,4 and 6 weeks\n  try:\n    op['Planned_GR_date'] = pd.to_datetime(op['SnapshotDate']).dt.date + pd.to_timedelta(op['lead_time'], unit='D')\n  except:\n    ags=[]\n    for i,j in zip(op['SnapshotDate'],op['lead_time']):\n      ags.append(i+timedelta(int(j)))\n    op['Planned_GR_date']=ags\n\n  op['Planned_GR_date']=pd.to_datetime(op['Planned_GR_date']).dt.date\n  op['Planned_GR_date']=pd.to_datetime(op['Planned_GR_date'])\n  op['Extended_GR_date_2']=pd.to_datetime(op['Planned_GR_date'])+timedelta(14)\n  op['Extended_GR_date_2']=pd.to_datetime(op['Extended_GR_date_2']).dt.date\n  op['Extended_GR_date_2']=pd.to_datetime(op['Extended_GR_date_2'])\n  op['Extended_GR_date_4']=pd.to_datetime(op['Planned_GR_date'])+timedelta(28)\n  op['Extended_GR_date_4']=pd.to_datetime(op['Extended_GR_date_4']).dt.date\n  op['Extended_GR_date_4']=pd.to_datetime(op['Extended_GR_date_4'])\n  op['Extended_GR_date_6']=pd.to_datetime(op['Planned_GR_date'])+timedelta(42)\n  op['Extended_GR_date_6']=pd.to_datetime(op['Extended_GR_date_6']).dt.date\n  op['Extended_GR_date_6']=pd.to_datetime(op['Extended_GR_date_6'])\n  \n  Mb51mat=Mb51matls[(Mb51matls['Plant']==Plants) & (Mb51matls['Material']==Matls)]\n  avg_consump_w_0=pd.pivot_table(Mb51mat,values='Qty_in_BUoM',index=['Plant','Material'],aggfunc='mean').reset_index()\n  avg_con_w_0=abs(avg_consump_w_0[(avg_consump_w_0['Plant']==Plants) & (avg_consump_w_0['Material']==Matls)]['Qty_in_BUoM'].values[0])\n  \n  #creating a dataframe with all dates starting from snapshot date to extended_gr_date_6 and populating it with daily mean consumption\n  inv_con1=inv_con[(inv_con['LocationID']==Plants) & (inv_con['MaterialID']==Matls)]\n  alldates=pd.date_range(start=op['SnapshotDate'].values[0], end=op['Extended_GR_date_6'].values[0])\n  tempdf1=pd.DataFrame(alldates,columns=['dates'])\n  tempdf1['LocationID']=Plants\n  tempdf1['MaterialID']=Matls\n  tempdf1['Week']=tempdf1['dates'].dt.week\n  inv_consumption=pd.merge(tempdf1,inv_con1,on=['LocationID','MaterialID','Week'],how='left')       \n\n  consump_2=inv_consumption[(inv_consumption['LocationID']==Plants) & (inv_consumption['MaterialID']==Matls) & (inv_consumption['dates']>=op['Planned_GR_date'].values[0]) & (inv_consumption['dates']<op['Extended_GR_date_2'].values[0])]['daily_mean_consumption'].sum()\n\n  consump_4=inv_consumption[(inv_consumption['LocationID']==Plants) & (inv_consumption['MaterialID']==Matls) & (inv_consumption['dates']>=op['Planned_GR_date'].values[0]) & (inv_consumption['dates']<op['Extended_GR_date_4'].values[0])]['daily_mean_consumption'].sum()\n\n  consump_6=inv_consumption[(inv_consumption['LocationID']==Plants) & (inv_consumption['MaterialID']==Matls) & (inv_consumption['dates']>=op['Planned_GR_date'].values[0]) & (inv_consumption['dates']<op['Extended_GR_date_6'].values[0])]['daily_mean_consumption'].sum()\n  \n  # getting consumption ratio for 2,4 and 6 weeks along with inventory ratio\n  op['Expected_consumption_btw_gr_dates_2']=abs(consump_2)\n  op['Expected_consumption_btw_gr_dates_4']=abs(consump_4)\n  op['Expected_consumption_btw_gr_dates_6']=abs(consump_6)\n  op['inventory_ratio_with_0']=abs(op['InventoryStockUnRestricted_daily'].values[0]/avg_con_w_0)\n  op['Expected_consumption_ratio_2_with_0']=abs(consump_2/avg_con_w_0)\n  op['Expected_consumption_ratio_4_with_0']=abs(consump_4/avg_con_w_0)\n  op['Expected_consumption_ratio_6_with_0']=abs(consump_6/avg_con_w_0)\n\n  features=['counter','inventory_ratio_with_0','Expected_consumption_ratio_2_with_0', 'Expected_consumption_ratio_4_with_0', 'Expected_consumption_ratio_6_with_0']\n  \n  #Extracting the model object from the directory where the models were saved\n  op1=op[features].copy()\n  #print(op1)\n  file_nameds = '/dbfs/FileStore/models/classifiers/'+f\"{model_run_date}\"+'/'+str(Plants)+'/'+str(Matls)+'/'+ '_class_if.pkl'\n  loaded_model_classif = pickle.load(open(file_nameds, \"rb\"))\n  reorder_points = loaded_model_classif.predict(op1)[0]\n  \n  return reorder_points"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7496fb78-1072-4ffe-a753-7966725499af"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["###Setting up base for the 26 week forecast. \n# The inventory consumption/inflow and PO flag -> 'forecasted'\n# Identifying open Purchase orders and their expected delivery -> 'pending'\n# Vendors -> List of vendors for the material plant combination and their attributes\n\n\nforecasted=pd.DataFrame()\npending=pd.DataFrame()\nvendors=pd.DataFrame()\neli5_reasons=pd.DataFrame() ### dataframe for logging reasons behind higher leadtime\n\nStart_date = datetime.datetime.strptime(Start_dates, '%Y-%m-%d')\nfor Plant,Matl in zip(Rop12['LocationID'],Rop12['MaterialID']):\n  try:\n    model_type=models[(models['LocationID']==Plant) & (models['MaterialID']==Matl)]['model'].values[0]\n\n  ##### Checking model type\n    if model_type=='trend_based':\n\n      ##### Getting the Reorder trigger attributes\n      ROP_freq = vendor_plant_data.loc[(vendor_plant_data['LocationID'] == Plant) & (vendor_plant_data['MaterialID'] == Matl), 'freq_val'].values[0]\n      ROP_median = vendor_plant_data.loc[(vendor_plant_data['LocationID'] == Plant) & (vendor_plant_data['MaterialID'] == Matl), 'median_val'].values[0]\n      ROP_mean = vendor_plant_data.loc[(vendor_plant_data['LocationID'] == Plant) & (vendor_plant_data['MaterialID'] == Matl), 'mean_val'].values[0]\n      ROP_method = models[(models['LocationID']==Plant) & (models['MaterialID']==Matl)]['flag'].values[0]\n\n      if (ROP_method == 'mean'):\n        ROP = ROP_mean\n      else:\n        ROP = ROP_median\n\n      ############################## Dataframe for logging POs and expected dates of receipts#########################################\n      vendors1 = vendor_plant_data[(vendor_plant_data['LocationID']==Plant) & (vendor_plant_data['MaterialID']==Matl)]\n      vendors_v1 = vendors1[['LocationID', 'MaterialID', 'updated_VS_ID', 'Fulfillment_rate', 'Vendor_ROQ','Avg_lead_time','Planned_avg_lead_time']]\n\n      # Checking if there are open purchase orders in the VES and logging the same in the 'pending' dataframe\n      pending_v1 = ves[(ves['Plant_ID']==Plant) & (ves['Material_No.']==Matl) & (ves['PO_Create_Date'] <= Start_date) & (ves['Delivery_date'] >= Start_date)][['Plant_ID', 'Material_No.', 'PO_Create_Date', 'Purchase_Order_Scheduled_Qty', 'updated_VS_ID']]\n\n      if (pending_v1.shape[0] >0): #if there are open pending orders\n        pending_v1 = ves[(ves['Plant_ID']==Plant) & (ves['Material_No.']==Matl) & (ves['PO_Create_Date'] <= Start_date) & (ves['Delivery_date'] >= Start_date)][['Plant_ID', 'Material_No.', 'PO_Create_Date', 'Purchase_Order_Scheduled_Qty', 'updated_VS_ID']]\n        pending_v1 = pd.merge(pending_v1, vendors_v1, on = ['updated_VS_ID'], how = 'left')\n        pending_v1['Vendor_ROQ'] = pending_v1['Purchase_Order_Scheduled_Qty']\n        pds=[]\n        for pl_id,v_id,mt_id,po_c_d,p_qty in zip(pending_v1['LocationID'],pending_v1['updated_VS_ID'],pending_v1['MaterialID'],pending_v1['PO_Create_Date'].dt.date.astype(str),pending_v1['Vendor_ROQ']):\n\n          #print(pl_id, v_id, mt_id, po_c_d, p_qty)\n          lead_time_pred,tempeli5 = pred_output(historical_data, pl_id, v_id, mt_id, po_c_d, p_qty) #predicting lead time for open orders\n          tempeli5['LocationID']=pl_id\n          tempeli5['updated_VS_ID']=v_id\n          tempeli5['MaterialID']=mt_id\n          tempeli5['PO_Create_Date']=po_c_d\n          tempeli5['lead_time_pred']=lead_time_pred\n          tempeli5['Exp_Gr_date']=pd.to_datetime(tempeli5['PO_Create_Date']).dt.date+pd.to_timedelta(lead_time_pred, unit='D')\n          eli5_reasons=eli5_reasons.append(tempeli5,ignore_index= True)\n          pds.append(lead_time_pred)\n        pending_v1['lead_time']=pds    \n\n        pending_v1 = pending_v1[['LocationID', 'MaterialID', 'updated_VS_ID', 'Fulfillment_rate', 'Vendor_ROQ', 'PO_Create_Date',  'lead_time', 'Avg_lead_time', 'Planned_avg_lead_time']]\n\n        #Getting expected delivery date and logging in pending\n        try:\n          pending_v1['Exp_GR_Date'] = pending_v1['PO_Create_Date'].dt.date + pd.to_timedelta(pending_v1['lead_time'], unit='D') \n        except:\n          ags=[]\n          for i,j in zip(pending_v1['PO_Create_Date'],pending_v1['lead_time']):\n            ags.append(i+timedelta(int(j)))\n          pending_v1['Exp_GR_Date']=ags\n          pending_v1['Exp_GR_Date']=pending_v1['Exp_GR_Date'].dt.date\n        pending_v1['Delivery_qty'] = pending_v1['Vendor_ROQ']*pending_v1['Fulfillment_rate']\n        date_since_order = np.timedelta64( Start_date - max(ves[(ves['Plant_ID']==Plant) & (ves['Material_No.']==Matl) & (ves['PO_Create_Date'] < Start_date)]['PO_Create_Date']), 'D')\n        date_since_order = date_since_order.astype(int)\n\n      else: #if no pending orders, create df with dummy values\n        pending_v1 = pd.DataFrame({'LocationID': [Plant], 'MaterialID': [Matl], 'updated_VS_ID': [0], 'Fulfillment_rate': [0.0], 'Vendor_ROQ': [0.0], 'PO_Create_Date': ['2000-01-01'],'lead_time': [0],'Avg_lead_time':[0],'Planned_avg_lead_time':[0]})\n        pending_v1['PO_Create_Date'] =   pd.to_datetime(pending_v1['PO_Create_Date'], format=\"%Y-%m-%d\") \n        pending_v1['Exp_GR_Date'] = pending_v1['PO_Create_Date'].dt.date + pd.to_timedelta(pending_v1['lead_time'].values[0], unit='D')\n        pending_v1['Delivery_qty'] = pending_v1['Vendor_ROQ']*pending_v1['Fulfillment_rate']\n        date_since_order = np.timedelta64( Start_date - max(ves[(ves['Plant_ID']==Plant) & (ves['Material_No.']==Matl) & (ves['PO_Create_Date'] < Start_date)]['PO_Create_Date']), 'D')\n        date_since_order = date_since_order.astype(int)\n\n      ############################## Dataframe for consumption, receipts and PO triggers#########################################\n      #Creating only the first row of the forecasted dataframe with the following elements:\n      # 1. Snapshot Date\n      # 2. Material ID\n      # 3. Location ID\n      # 4. Uinit of Measure\n      # 5. Week\n      # 6. Inventory stock in hand (from the inventory history)\n      # 7. Average Consumption\n      # 8. Std Deviation of consumption\n      # 9. Material received\n      # 10. Expected inventory at the end of the day = inventory in hand - consumption + \n      # 11. Counter: Count of days since last order \n      # 12. Reorder flag\n\n      forecasted_v1 = h_inv_fi[(h_inv_fi['SnapshotDate'] == Start_date) & (h_inv_fi['MaterialID'] ==Matl) & (h_inv_fi['LocationID'] == Plant)]\n      forecasted_v1=pd.merge(forecasted_v1,inv_con,on=['LocationID','MaterialID','Week'],how='left')\n      forecasted_v1['Matl_Recp'] = pending_v1.loc[pending_v1['Exp_GR_Date'] == pd.to_datetime(Start_date) , 'Delivery_qty'].sum()\n      forecasted_v1.loc[forecasted_v1['daily_mean_consumption'].isnull()==True,'daily_mean_consumption']=0\n      forecasted_v1['Exp_inv'] = max((forecasted_v1['InventoryStockUnRestricted_daily'].astype(np.int64) + forecasted_v1['daily_mean_consumption'].astype(np.int64) + forecasted_v1['Matl_Recp'].astype(np.int64)).values[0],0)\n\n\n      forecasted_v1['counter'] = date_since_order\n      forecasted_v1['Reorder'] = 0\n\n      # check if order needs to be placed on start date. Uf yes, log PO Create date, Vendor, lead time, expected delivery date, PO Quantity, Expected delivery in Pending based on the method of reorder\n      # Inventory based reorder check\n\n      if max(pending_v1['PO_Create_Date'])==Start_date:\n        forecasted_v1['Reorder']=1\n\n      elif ((ROP_method == 'median') | (ROP_method == 'mean')):\n        if ((forecasted_v1['InventoryStockUnRestricted_daily'].values[0] >= ROP) & (forecasted_v1['Exp_inv'].values[0] < ROP)):\n          forecasted_v1['Reorder'] = 1\n\n\n      # Frequency based reorder check\n      elif (ROP_method == 'frequency'):\n        if (date_since_order >= ROP_freq):\n          forecasted_v1['Reorder'] = 1\n\n      # Hybrid Reorder check\n      elif (ROP_method == 'hybrid'): #(here ROP is median, ROP_freq is mode)\n        if (((date_since_order >= ROP_freq) & (forecasted_v1['Exp_inv'].values[0]<ROP))  | ((forecasted_v1['InventoryStockUnRestricted_daily'].values[0] >= ROP) & (forecasted_v1['Exp_inv'].values[0] < ROP))):\n          forecasted_v1['Reorder'] = 1\n\n      if (forecasted_v1['Reorder'].values[0] == 1):\n        po_place = vendors_v1.copy()\n        po_place['PO_Create_Date'] = Start_date\n        po_place['PO_Create_Date'] = pd.to_datetime(po_place['PO_Create_Date'], format=\"%Y-%m-%d\")\n\n        pds=[]\n        for pl_id,v_id,mt_id,po_c_d,p_qty in zip(po_place['LocationID'],po_place['updated_VS_ID'],po_place['MaterialID'],po_place['PO_Create_Date'].dt.date.astype(str),po_place['Vendor_ROQ']):\n          #print(pl_id, v_id, mt_id, po_c_d, p_qty)\n          lead_time_pred,tempeli5 = pred_output(historical_data, pl_id, v_id, mt_id, po_c_d, p_qty)\n          tempeli5['LocationID']=pl_id\n          tempeli5['updated_VS_ID']=v_id\n          tempeli5['MaterialID']=mt_id\n          tempeli5['PO_Create_Date']=po_c_d\n          tempeli5['lead_time_pred']=lead_time_pred\n          tempeli5['Exp_Gr_date']=pd.to_datetime(tempeli5['PO_Create_Date']).dt.date+pd.to_timedelta(lead_time_pred, unit='D')\n          eli5_reasons=eli5_reasons.append(tempeli5,ignore_index= True)\n          pds.append(lead_time_pred)\n        po_place['lead_time']=pds\n\n        try:\n          po_place['Exp_GR_Date'] = po_place['PO_Create_Date'].dt.date + pd.to_timedelta(po_place['lead_time'], unit='D')\n        except:\n          ags=[]\n          for i,j in zip(po_place['PO_Create_Date'],po_place['lead_time']):\n            ags.append(i+timedelta(int(j)))\n          po_place['Exp_GR_Date']=ags\n          po_place['Exp_GR_Date']=po_place['Exp_GR_Date'].dt.date\n        po_place['Delivery_qty'] = po_place['Vendor_ROQ']*po_place['Fulfillment_rate']\n        pending_v1 = pending_v1.append(po_place, ignore_index= True)\n      forecasted=forecasted.append(forecasted_v1,ignore_index= True)\n      pending=pending.append(pending_v1,ignore_index= True)\n      vendors=vendors.append(vendors_v1,ignore_index= True)\n    ####End of loop\n\n    ##### Checking model type\n    elif model_type=='model_based_prediction':\n      ############################## Dataframe for logging POs and expected dates of receipts#########################################\n      vendors1 = vendor_plant_data[(vendor_plant_data['LocationID']==Plant) & (vendor_plant_data['MaterialID']==Matl)]\n      vendors_v1 = vendors1[['LocationID', 'MaterialID', 'updated_VS_ID', 'Fulfillment_rate', 'Vendor_ROQ','Avg_lead_time','Planned_avg_lead_time']]\n\n      # Checking if there are open purchase orders in the VES and logging the same in the 'pending' dataframe\n      pending_v1 = ves[(ves['Plant_ID']==Plant) & (ves['Material_No.']==Matl) & (ves['PO_Create_Date'] <= Start_date) & (ves['Delivery_date'] >= Start_date)][['Plant_ID', 'Material_No.', 'PO_Create_Date', 'Purchase_Order_Scheduled_Qty', 'updated_VS_ID']]\n\n      if (pending_v1.shape[0] >0): #if there are open pending orders\n        pending_v1 = ves[(ves['Plant_ID']==Plant) & (ves['Material_No.']==Matl) & (ves['PO_Create_Date'] <= Start_date) & (ves['Delivery_date'] >= Start_date)][['Plant_ID', 'Material_No.', 'PO_Create_Date', 'Purchase_Order_Scheduled_Qty', 'updated_VS_ID']]\n        pending_v1 = pd.merge(pending_v1, vendors_v1, on = ['updated_VS_ID'], how = 'left')\n        pending_v1['Vendor_ROQ'] = pending_v1['Purchase_Order_Scheduled_Qty']\n        pds=[]\n        for pl_id,v_id,mt_id,po_c_d,p_qty in zip(pending_v1['LocationID'],pending_v1['updated_VS_ID'],pending_v1['MaterialID'],pending_v1['PO_Create_Date'].dt.date.astype(str),pending_v1['Vendor_ROQ']):\n\n          lead_time_pred,tempeli5 = pred_output(historical_data, pl_id, v_id, mt_id, po_c_d, p_qty) #predicting lead time for open orders\n          tempeli5['LocationID']=pl_id\n          tempeli5['updated_VS_ID']=v_id\n          tempeli5['MaterialID']=mt_id\n          tempeli5['PO_Create_Date']=po_c_d\n          tempeli5['lead_time_pred']=lead_time_pred\n          tempeli5['Exp_Gr_date']=pd.to_datetime(tempeli5['PO_Create_Date']).dt.date+pd.to_timedelta(lead_time_pred, unit='D')\n          eli5_reasons=eli5_reasons.append(tempeli5,ignore_index= True)\n          pds.append(lead_time_pred)\n        pending_v1['lead_time']=pds    \n\n        pending_v1 = pending_v1[['LocationID', 'MaterialID', 'updated_VS_ID', 'Fulfillment_rate', 'Vendor_ROQ', 'PO_Create_Date',  'lead_time', 'Avg_lead_time', 'Planned_avg_lead_time']]\n\n        #Getting expected delivery date and logging in pending\n        try:\n          pending_v1['Exp_GR_Date'] = pending_v1['PO_Create_Date'].dt.date + pd.to_timedelta(pending_v1['lead_time'], unit='D') \n        except:\n          ags=[]\n          for i,j in zip(pending_v1['PO_Create_Date'],pending_v1['lead_time']):\n            ags.append(i+timedelta(int(j)))\n          pending_v1['Exp_GR_Date']=ags\n          pending_v1['Exp_GR_Date']=pending_v1['Exp_GR_Date'].dt.date\n        pending_v1['Delivery_qty'] = pending_v1['Vendor_ROQ']*pending_v1['Fulfillment_rate']\n\n        date_since_order = np.timedelta64( Start_date - max(ves[(ves['Plant_ID']==Plant) & (ves['Material_No.']==Matl) & (ves['PO_Create_Date'] < Start_date)]['PO_Create_Date']), 'D')\n        date_since_order = date_since_order.astype(int)\n\n      else: #if no pending orders, create df with dummy values\n        pending_v1 = pd.DataFrame({'LocationID': [Plant], 'MaterialID': [Matl], 'updated_VS_ID': [0], 'Fulfillment_rate': [0.0], 'Vendor_ROQ': [0.0], 'PO_Create_Date': ['2000-01-01'],'lead_time': [0],'Avg_lead_time':[0],'Planned_avg_lead_time':[0]})\n        pending_v1['PO_Create_Date'] =   pd.to_datetime(pending_v1['PO_Create_Date'], format=\"%Y-%m-%d\") \n        pending_v1['Exp_GR_Date'] = pending_v1['PO_Create_Date'].dt.date + pd.to_timedelta(pending_v1['lead_time'].values[0], unit='D')\n        pending_v1['Delivery_qty'] = pending_v1['Vendor_ROQ']*pending_v1['Fulfillment_rate']\n\n        date_since_order = np.timedelta64( Start_date - max(ves[(ves['Plant_ID']==Plant) & (ves['Material_No.']==Matl) & (ves['PO_Create_Date'] < Start_date)]['PO_Create_Date']), 'D')\n        date_since_order = date_since_order.astype(int)\n\n      ############################## Dataframe for consumption, receipts and PO triggers#########################################\n      #Creating only the first row of the forecasted dataframe with the following elements:\n      # 1. Snapshot Date\n      # 2. Material ID\n      # 3. Location ID\n      # 4. Uinit of Measure\n      # 5. Week\n      # 6. Inventory stock in hand (from the inventory history)\n      # 7. Average Consumption\n      # 8. Std Deviation of consumption\n      # 9. Material received\n      # 10. Expected inventory at the end of the day = inventory in hand - consumption + \n      # 11. Counter: Count of days since last order \n      # 12. Reorder flag\n\n      forecasted_v1 = h_inv_fi[(h_inv_fi['SnapshotDate'] == Start_date) & (h_inv_fi['MaterialID'] ==Matl) & (h_inv_fi['LocationID'] == Plant)]\n      forecasted_v1=pd.merge(forecasted_v1,inv_con,on=['LocationID','MaterialID','Week'],how='left')\n      forecasted_v1['Matl_Recp'] = pending_v1.loc[pending_v1['Exp_GR_Date'] == pd.to_datetime(Start_date) , 'Delivery_qty'].sum()\n      forecasted_v1.loc[forecasted_v1['daily_mean_consumption'].isnull()==True,'daily_mean_consumption']=0\n      forecasted_v1['Exp_inv'] = max((forecasted_v1['InventoryStockUnRestricted_daily'].astype(np.int64) + forecasted_v1['daily_mean_consumption'].astype(np.int64) + forecasted_v1['Matl_Recp'].astype(np.int64)).values[0],0)\n      forecasted_v1['counter'] = date_since_order\n\n      # check if order needs to be placed on start date. If yes, log PO Create date, Vendor, lead time, expected delivery date, PO Quantity, Expected delivery in Pending based on the predited order placement\n      # Inventory based reorder check\n\n      if max(pending_v1['PO_Create_Date'])==Start_date:\n        forecasted_v1['Reorder']=1\n\n      #order placement prediction\n      else:\n        reorder_point = order_placed(forecasted_v1['SnapshotDate'].values[0],forecasted_v1['LocationID'].values[0],forecasted_v1['MaterialID'].values[0],forecasted_v1['Exp_inv'].values[0],forecasted_v1['counter'].values[0])\n\n        forecasted_v1['Reorder'] = reorder_point\n\n\n      if (forecasted_v1['Reorder'].values[0] == 1):\n        po_place = vendors_v1.copy()\n        po_place['PO_Create_Date'] = Start_date\n        po_place['PO_Create_Date'] = pd.to_datetime(po_place['PO_Create_Date'], format=\"%Y-%m-%d\")\n\n        pds=[]\n        for pl_id,v_id,mt_id,po_c_d,p_qty in zip(po_place['LocationID'],po_place['updated_VS_ID'],po_place['MaterialID'],po_place['PO_Create_Date'].dt.date.astype(str),po_place['Vendor_ROQ']):\n          #print(pl_id, v_id, mt_id, po_c_d, p_qty)\n          lead_time_pred,tempeli5 = pred_output(historical_data, pl_id, v_id, mt_id, po_c_d, p_qty)\n          tempeli5['LocationID']=pl_id\n          tempeli5['updated_VS_ID']=v_id\n          tempeli5['MaterialID']=mt_id\n          tempeli5['PO_Create_Date']=po_c_d\n          tempeli5['lead_time_pred']=lead_time_pred\n          tempeli5['Exp_Gr_date']=pd.to_datetime(tempeli5['PO_Create_Date']).dt.date+pd.to_timedelta(lead_time_pred, unit='D')\n          eli5_reasons=eli5_reasons.append(tempeli5,ignore_index= True)\n          pds.append(lead_time_pred)\n        po_place['lead_time']=pds\n\n        try:\n          po_place['Exp_GR_Date'] = po_place['PO_Create_Date'].dt.date + pd.to_timedelta(po_place['lead_time'], unit='D')\n        except:\n          ags=[]\n          for i,j in zip(po_place['PO_Create_Date'],po_place['lead_time']):\n            ags.append(i+timedelta(int(j)))\n          po_place['Exp_GR_Date']=ags\n          po_place['Exp_GR_Date']=po_place['Exp_GR_Date'].dt.date\n        po_place['Delivery_qty'] = po_place['Vendor_ROQ']*po_place['Fulfillment_rate']\n        pending_v1 = pending_v1.append(po_place, ignore_index= True)\n      forecasted=forecasted.append(forecasted_v1,ignore_index= True)\n      pending=pending.append(pending_v1,ignore_index= True)\n      vendors=vendors.append(vendors_v1,ignore_index= True)\n  ####End of loop \n    else:\n      print('unable to create model')\n\n  except:\n    print(Plant,Matl,\"- unable to build model\")\n\nforecasted['InventoryStockUnRestricted_daily']=forecasted['InventoryStockUnRestricted_daily'].astype(np.int64)\nforecasted['daily_mean_consumption']=forecasted['daily_mean_consumption'].astype(np.int64)\nforecasted['Exp_inv']=forecasted['Exp_inv'].astype(np.int64)\npending['Delivery_qty']=pending['Delivery_qty'].astype(np.int64)\npending['Exp_GR_Date']=pd.to_datetime(pending['Exp_GR_Date'])\neli5_reasons.drop_duplicates(inplace=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Forecasting consumption and PO creation","showTitle":true,"inputWidgets":{},"nuid":"ccc2f079-1538-4766-afef-dab95090ed1e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["print(eli5_reasons.shape)\neli5_reasons.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1357c21c-d959-4cb0-b61c-6de514e589d4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["print(pending.shape)\npending.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"19be20b2-5774-46d8-89dc-cecfb7eda764"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["print(forecasted.shape)\nforecasted.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3f477341-a420-4b06-80bd-e00ace73c785"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["print(vendors.shape)\nvendors.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2368072a-64b0-4151-a55d-2676ec8cde54"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["############Forecasting consumption, order placement, material receipts and expected inventory for next 180 days\n\nforecasting=pd.DataFrame()\npendings=pd.DataFrame()\nleadtime_reasons=pd.DataFrame()\n\nStart_date = datetime.datetime.strptime(Start_dates, '%Y-%m-%d')\nfor Plant,Matl in zip(Rop12['LocationID'],Rop12['MaterialID']):\n  try:\n    model_type=models[(models['LocationID']==Plant) & (models['MaterialID']==Matl)]['model'].values[0]\n    forecasted1=forecasted[(forecasted['LocationID']==Plant) & (forecasted['MaterialID']==Matl)].copy()\n    pending1=pending[(pending['LocationID']==Plant)&(pending['MaterialID']==Matl)].copy()\n    vendors1=vendors[(vendors['LocationID']==Plant)&(vendors['MaterialID']==Matl)].copy()\n    leadtime_reasons1=eli5_reasons[(eli5_reasons['LocationID']==Plant)&(eli5_reasons['MaterialID']==Matl)].copy()\n\n    ##### Checking model type\n    if model_type=='model_based_prediction':\n      for i in range(1,180):\n        #Last updated date\n        td=timedelta(i)\n        todate = Start_date+td\n        tempdf = forecasted1.tail(1).copy() # taking the latest entry of the forecasted\n        tempdf['SnapshotDate'] = todate\n        tempdf['Week'] = int(todate.isocalendar()[1])\n        if tempdf['Reorder'].values[0] ==1:\n          tempdf['counter']=1\n          tempdf['Reorder'] = 0\n        else:        \n          tempdf['counter'] = tempdf['counter'].values[0] + 1\n          tempdf['Reorder'] = 0\n\n        # Update Consumption stats\n        try:\n          tempdf['daily_mean_consumption'] = inv_con.loc[(inv_con['MaterialID'] == Matl) & (inv_con['LocationID'] == Plant) & (inv_con['Week'] == int(todate.isocalendar()[1])),'daily_mean_consumption'].values[0]\n          tempdf['std_dev_consumption'] = inv_con.loc[(inv_con['MaterialID'] == Matl) & (inv_con['LocationID'] == Plant) & (inv_con['Week'] == int(todate.isocalendar()[1])), 'std_dev_consumption'].values[0]\n        except:\n          tempdf['daily_mean_consumption'] = 0\n          tempdf['std_dev_consumption'] = 0\n\n        # Update Material Receipt\n        tempdf['Matl_Recp'] = pending1.loc[pending1['Exp_GR_Date'] == pd.to_datetime(todate), 'Delivery_qty'].sum()\n\n        # Update the Expected inventory\n        inv_calc = max((tempdf['Exp_inv'] + tempdf['Matl_Recp'] + tempdf['daily_mean_consumption']).values[0], 0) #Non negative inventory\n        tempdf['Exp_inv']= int(inv_calc)\n\n        #   Order Placement prediction\n        if (forecasted1['Reorder'].tail(3).sum()==0):\n          reorder_point = order_placed(tempdf['SnapshotDate'].values[0],tempdf['LocationID'].values[0],tempdf['MaterialID'].values[0],tempdf['Exp_inv'].values[0],tempdf['counter'].values[0])        \n          tempdf['Reorder'] = reorder_point\n        else:\n          tempdf['Reorder']=0\n\n      # Order logging in 'Pending' by suppliers, PO Create date, Expected delivery, PO Qty and expected delivery qty:\n        if(tempdf['Reorder'].values[0] ==1):\n          po_place = vendors1.copy()\n          po_place['PO_Create_Date'] = todate\n          po_place['PO_Create_Date'] = pd.to_datetime(po_place['PO_Create_Date'], format=\"%Y-%m-%d\")\n          pds=[]\n          for pl_id,v_id,mt_id,po_c_d,p_qty in zip(po_place['LocationID'], po_place['updated_VS_ID'], po_place['MaterialID'], po_place['PO_Create_Date'].dt.date.astype(str), po_place['Vendor_ROQ']):\n            lead_time_pred,tempeli5 = pred_output(historical_data, pl_id, v_id, mt_id, po_c_d, p_qty)\n            tempeli5['LocationID']=pl_id\n            tempeli5['updated_VS_ID']=v_id\n            tempeli5['MaterialID']=mt_id\n            tempeli5['PO_Create_Date']=po_c_d\n            tempeli5['lead_time_pred']=lead_time_pred\n            tempeli5['Exp_Gr_date']=pd.to_datetime(tempeli5['PO_Create_Date']).dt.date+pd.to_timedelta(lead_time_pred, unit='D')\n            leadtime_reasons1=leadtime_reasons1.append(tempeli5,ignore_index= True)\n            pds.append(lead_time_pred)\n          po_place['lead_time']=pds\n          try:\n            po_place['Exp_GR_Date'] = po_place['PO_Create_Date'].dt.date + pd.to_timedelta(po_place['lead_time'], unit='D')\n          except:\n            ags=[]\n            for i,j in zip(po_place['PO_Create_Date'],po_place['lead_time']):\n              ags.append(i+timedelta(int(j)))\n            po_place['Exp_GR_Date']=ags\n            po_place['Exp_GR_Date']=po_place['Exp_GR_Date'].dt.date\n          po_place['Delivery_qty'] = po_place['Vendor_ROQ']*po_place['Fulfillment_rate']\n\n          pending1 = pending1.append(po_place, ignore_index= True)\n        forecasted1=forecasted1.append(tempdf,ignore_index=True)\n      forecasting=forecasting.append(forecasted1,ignore_index=True)\n      leadtime_reasons=leadtime_reasons.append(leadtime_reasons1,ignore_index=True)\n      print(forecasting.shape)\n      pendings=pendings.append(pending1,ignore_index=True)\n      ####End of loop\n\n    ##### Checking model type\n    elif model_type=='trend_based':\n      ##### Getting the Reorder trigger attributes\n      ROP_freq = vendor_plant_data.loc[(vendor_plant_data['LocationID'] == Plant) & (vendor_plant_data['MaterialID'] == Matl), 'freq_val'].values[0]\n      ROP_median = vendor_plant_data.loc[(vendor_plant_data['LocationID'] == Plant) & (vendor_plant_data['MaterialID'] == Matl), 'median_val'].values[0]\n      ROP_mean = vendor_plant_data.loc[(vendor_plant_data['LocationID'] == Plant) & (vendor_plant_data['MaterialID'] == Matl), 'mean_val'].values[0]\n      ROP_method = models[(models['LocationID']==Plant) & (models['MaterialID']==Matl)]['flag'].values[0]\n\n      if (ROP_method == 'mean'):\n        ROP = ROP_mean\n      else:\n        ROP = ROP_median\n      for i in range(1,180):\n        #Last updated date\n        td=timedelta(i)\n        todate = Start_date+td\n        tempdf = forecasted1.tail(1).copy() # taking the latest entry of the forecasted\n        tempdf['SnapshotDate'] = todate\n        tempdf['Week'] = int(todate.isocalendar()[1])\n\n        if tempdf['Reorder'].values[0] ==1:\n          tempdf['counter']=1\n          tempdf['Reorder'] = 0\n        else:        \n          tempdf['counter'] = tempdf['counter'].values[0] + 1\n          tempdf['Reorder'] = 0\n\n        # Update Consumption stats\n        try:\n          tempdf['daily_mean_consumption'] = inv_con.loc[(inv_con['MaterialID'] == Matl) & (inv_con['LocationID'] == Plant) & (inv_con['Week'] == int(todate.isocalendar()[1])),'daily_mean_consumption'].values[0]\n          tempdf['std_dev_consumption'] = inv_con.loc[(inv_con['MaterialID'] == Matl) & (inv_con['LocationID'] == Plant) & (inv_con['Week'] == int(todate.isocalendar()[1])), 'std_dev_consumption'].values[0]\n        except:\n          tempdf['daily_mean_consumption'] = 0\n          tempdf['std_dev_consumption'] = 0\n\n        # Update Material Receipt\n        tempdf['Matl_Recp'] = pending1.loc[pending1['Exp_GR_Date'] == pd.to_datetime(todate), 'Delivery_qty'].sum()\n\n        # Order Placement Check - Mean/Median or hybrid or frequency and triggering order if needed\n        if((ROP_method == 'median') | (ROP_method == 'mean')):\n          if ((tempdf['Exp_inv'].values[0] >= ROP) & ((tempdf['Exp_inv'].values[0] + tempdf['Matl_Recp'].values[0] + tempdf['daily_mean_consumption'].values[0]) < ROP)):\n            tempdf['Reorder'] =1\n\n        elif(ROP_method == 'frequency'):\n          if (tempdf['counter'].values[0] >= ROP_freq):\n            tempdf['Reorder'] =1\n\n        elif(ROP_method == 'hybrid'):\n          if (((tempdf['Exp_inv'].values[0] >= ROP) & ((tempdf['Exp_inv'].values[0] + tempdf['Matl_Recp'].values[0] + tempdf['daily_mean_consumption'].values[0]) < ROP)) | ((tempdf['counter'].values[0] >= ROP_freq) & (tempdf['Exp_inv'].values[0]<ROP))):\n            tempdf['Reorder'] =1\n\n      # Order logging in 'Pending' by suppliers, PO Create date, Expected delivery, PO Qty and expected delivery qty:\n        if(tempdf['Reorder'].values[0] ==1):\n          po_place = vendors1.copy()\n          po_place['PO_Create_Date'] = todate\n          po_place['PO_Create_Date'] = pd.to_datetime(po_place['PO_Create_Date'], format=\"%Y-%m-%d\")\n          pds=[]\n          for pl_id,v_id,mt_id,po_c_d,p_qty in zip(po_place['LocationID'], po_place['updated_VS_ID'], po_place['MaterialID'], po_place['PO_Create_Date'].dt.date.astype(str), po_place['Vendor_ROQ']):\n            lead_time_pred,tempeli5 = pred_output(historical_data, pl_id, v_id, mt_id, po_c_d, p_qty)\n            tempeli5['LocationID']=pl_id\n            tempeli5['updated_VS_ID']=v_id\n            tempeli5['MaterialID']=mt_id\n            tempeli5['PO_Create_Date']=po_c_d\n            tempeli5['lead_time_pred']=lead_time_pred\n            tempeli5['Exp_Gr_date']=pd.to_datetime(tempeli5['PO_Create_Date']).dt.date+pd.to_timedelta(lead_time_pred, unit='D')\n            leadtime_reasons1=leadtime_reasons1.append(tempeli5,ignore_index= True)\n            pds.append(lead_time_pred)\n          po_place['lead_time']=pds\n          try:\n            po_place['Exp_GR_Date'] = po_place['PO_Create_Date'].dt.date + pd.to_timedelta(po_place['lead_time'], unit='D')\n          except:\n            ags=[]\n            for i,j in zip(po_place['PO_Create_Date'],po_place['lead_time']):\n              ags.append(i+timedelta(int(j)))\n            po_place['Exp_GR_Date']=ags\n            po_place['Exp_GR_Date']=po_place['Exp_GR_Date'].dt.date\n          po_place['Delivery_qty'] = po_place['Vendor_ROQ']*po_place['Fulfillment_rate']\n\n          pending1 = pending1.append(po_place, ignore_index= True)\n\n        # Update the Expected inventory\n        inv_calc = max((tempdf['Exp_inv'] + tempdf['Matl_Recp'] + tempdf['daily_mean_consumption']).values[0], 0) #Non negative inventory\n        tempdf['Exp_inv']= int(inv_calc)\n\n\n        forecasted1=forecasted1.append(tempdf,ignore_index=True)\n      forecasting=forecasting.append(forecasted1,ignore_index=True)\n      leadtime_reasons=leadtime_reasons.append(leadtime_reasons1,ignore_index=True)\n      print(forecasting.shape)\n      pendings=pendings.append(pending1,ignore_index=True)\n\n    else:\n      print('unable to build model')\n  except:\n    print(Plant,Matl,\"- unable to build model\")\n    \npendings['Exp_GR_Date']=pd.to_datetime(pendings['Exp_GR_Date'])\nleadtime_reasons['Exp_gr_week']=pd.to_datetime(leadtime_reasons['Exp_Gr_date']).dt.week"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0b2fd7eb-d168-40d3-9566-49266220b1c8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#cleaning leadtime driver description\nprint(leadtime_reasons.shape)\nleadtime_reasons.drop_duplicates(inplace=True)\nprint(leadtime_reasons.shape)\nleadtime_reasons=leadtime_reasons.merge(feature_desc,on='feature',how='left')\nprint(leadtime_reasons.shape)\nleadtime_reasons.drop(columns=['feature'],inplace=True)\nleadtime_reasons.rename(columns={'explanation':'feature'},inplace=True)\nleadtime_reasons.loc[leadtime_reasons['feature'].isnull()==True,'feature']='Higher leadtime observed historically for this month'\nleadtime_reasons.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0b17c0a7-6c6f-447c-a4ac-a402d69251da"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["col_names = ['_'.join(col.split(' ')) for col in leadtime_reasons.columns.tolist()]\nleadtime_reasons.columns = col_names\nreas = spark.createDataFrame(leadtime_reasons)\nleadtime_reasons_sps = \"leadtime_callout\"\nreas.write.saveAsTable(leadtime_reasons_sps,mode = 'overwrite')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"41e1005c-42a6-4858-82af-328b02633159"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["print(forecasting.shape)\nforecasting.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6c4d1cf2-35ea-4ccb-b80f-1ae56bd1e06e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["col_names = ['_'.join(col.split(' ')) for col in forecasting.columns.tolist()]\nforecasting.columns = col_names\nfore = spark.createDataFrame(forecasting)\nfore.write.saveAsTable(for_out,mode = 'overwrite')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"aafbaa54-2091-4812-9bd4-df4fcb739f06"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["col_names = ['_'.join(col.split(' ')) for col in vendors.columns.tolist()]\nvendors.columns = col_names\nvending = spark.createDataFrame(vendors)\nvending.write.saveAsTable('vendor_table',mode = 'overwrite')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"343afe2b-3569-4bd0-afd4-f1c6fb5609a2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["pendings['Exp_GR_Date']=pd.to_datetime(pendings['Exp_GR_Date'])\nprint(pendings.shape)\npendings.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c5810653-d55b-4cdf-8336-c18542470932"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["col_names = ['_'.join(col.split(' ')) for col in pendings.columns.tolist()]\npendings.columns = col_names\npends = spark.createDataFrame(pendings)\npends.write.saveAsTable(pend_out,mode = 'overwrite')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"714cb3a5-402f-48e2-851f-6ad1ddae886e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["Rop555=forecasting[['LocationID','MaterialID']]\nRop555.drop_duplicates(inplace=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bacdf450-a3e8-4e9d-9525-e6432f907522"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["Matl_SPS1d=pd.DataFrame()\nMatl_SPS2d=pd.DataFrame()\nfor Plant,Matl in zip(Rop555['LocationID'],Rop555['MaterialID']):\n  forecasted=forecasting[(forecasting['LocationID']==Plant) & (forecasting['MaterialID']==Matl)].copy()\n  pending1=pendings[(pendings['LocationID']==Plant)&(pendings['MaterialID']==Matl)].copy()\n  vendors1=vendors[(vendors['LocationID']==Plant)&(vendors['MaterialID']==Matl)].copy()\n  forecasted['std_dev_consumption']=round(forecasted['std_dev_consumption'].astype(float),2)\n  forecasted['std_dev_consumption'] = forecasted['std_dev_consumption']\n  forecasted['Recvd_total'] = forecasted['Matl_Recp'].cumsum()\n  \n  #Aggregating Consumption & standard deviation for only days consumption has happend\n  forecasted['Actual_consumed'] =  np.where(forecasted['Exp_inv']>0, -1*forecasted['daily_mean_consumption'], 0)\n  forecasted['agg_std_dev'] = np.where(forecasted['Exp_inv']>0, forecasted['std_dev_consumption'], 0)\n\n  forecasted['Consumed_total'] = (forecasted['Actual_consumed'].cumsum())\n  forecasted['agg_std_dev'] = np.square(forecasted['agg_std_dev'])\n  forecasted['agg_std_dev'] = forecasted['agg_std_dev'].cumsum()\n  forecasted['agg_std_dev'] = np.sqrt(forecasted['agg_std_dev'])\n  \n  #generating SPS score\n  forecasted['SPS'] = 1-norm.cdf(forecasted['InventoryStockUnRestricted_daily'] + forecasted['Recvd_total'], forecasted['Consumed_total'], forecasted['agg_std_dev'])\n  \n  #for null SPS values if there is no inventory but expected consumption then SPS is 0.5 else its 0\n  for daily_mean,fore_sps,std_dev_consump,indices in zip(forecasted['daily_mean_consumption'],forecasted['SPS'],forecasted['std_dev_consumption'],forecasted.index):\n    if ((daily_mean==0) & (math.isnan(fore_sps)==True)):\n      forecasted['SPS'][indices]=0\n    if ((std_dev_consump>0) & (math.isnan(fore_sps)==True)):\n      forecasted['SPS'][indices]=0.5\n    else:\n      pass\n  forecasteddf=forecasted.copy()\n  vendors1 = vendors1.drop(['Fulfillment_rate', 'Avg_lead_time', 'Vendor_ROQ','updated_VS_ID','Planned_avg_lead_time'], axis =1)\n  vendors1.drop_duplicates(inplace=True)\n  Matl_SPS_2 = pd.pivot_table(forecasted,values='SPS',index=['LocationID','MaterialID', 'Week'],aggfunc='max').reset_index()\n  \n  Matl_SPS_2 = pd.merge(Matl_SPS_2, vendors1, how = 'left', on = ['LocationID','MaterialID'])\n  Matl_SPS2d=Matl_SPS2d.append(Matl_SPS_2,ignore_index=True)\n  Matl_SPS = pd.merge(forecasteddf, vendors1, how = 'left', on = ['LocationID','MaterialID'])\n  Matl_SPS1d=Matl_SPS1d.append(Matl_SPS,ignore_index=True)\n  \nMatl_SPS1d['SPS']=Matl_SPS1d['SPS'].astype(np.float)\nMatl_SPS2d['SPS']=Matl_SPS2d['SPS'].astype(np.float)\n  \nprint(Matl_SPS1d.shape)\nMatl_SPS1d.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Calculating SPS","showTitle":true,"inputWidgets":{},"nuid":"ff225702-90f7-49cf-8af9-5b448b6cf773"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["matdg = spark.createDataFrame(Matl_SPS1d)\nmatdg.write.saveAsTable(fore_wit_sps,mode = 'overwrite')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"69d57948-7277-44a2-8479-086aea7b4ad9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# getting planned_date & typical_GR_date from Planned_avg_lead_time and Avg_lead_time\npendings['planned_date']= pd.to_datetime(pendings['PO_Create_Date'])+ pd.to_timedelta(pendings['Planned_avg_lead_time'], unit='D')\npendings['typical_GR_date']= pd.to_datetime(pendings['PO_Create_Date'])+ pd.to_timedelta(pendings['Avg_lead_time'], unit='D')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Reasons for Stockout","showTitle":true,"inputWidgets":{},"nuid":"b96cc3e2-72ed-4bc6-956b-b5dd1e8dae43"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# GR dates derived from predicted lead time,Planned average lead time and average lead time\nexp_gr_date=[]\nplanned_gr_date=[]\ntypical_gr_date=[]\nfor pl_id,mt_id,snap_date in zip(Matl_SPS1d['LocationID'],Matl_SPS1d['MaterialID'],Matl_SPS1d['SnapshotDate']):\n  a=pendings[(pendings['LocationID']==pl_id)&(pendings['MaterialID']==mt_id)&(pendings['Exp_GR_Date']>=snap_date)]\n  try:\n    exp_gr_date.append(min(a['Exp_GR_Date']))\n    planned_gr_date.append(min(a['planned_date']))\n    typical_gr_date.append(min(a['typical_GR_date']))\n    \n  except:\n    exp_gr_date.append('')\n    planned_gr_date.append('')\n    typical_gr_date.append('')\n    \nMatl_SPS1d['Exp_GR_date']=exp_gr_date\nMatl_SPS1d['Planned_GR_date']=planned_gr_date\nMatl_SPS1d['Typical_GR_date']=typical_gr_date"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9c52d1b4-4038-4133-ab45-12db081025bf"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#Stock out possibility value is given for each date:\n# 1.higher_consumption=1 meaning PO to be created earlier/Higher Qty to be ordered\n# 2.lead_time_issue=1 meaning Higher leadtime \n# 3. -0.5 = no stockout\nlead_time_issue=[]\nhigher_consumption=[]\nfor pl_id,mt_id,snap_date,sps_score in zip(Matl_SPS1d['LocationID'],Matl_SPS1d['MaterialID'],Matl_SPS1d['SnapshotDate'],Matl_SPS1d['SPS']):\n  if sps_score>=0.25:\n    a=Matl_SPS1d[(Matl_SPS1d['LocationID']==pl_id)&(Matl_SPS1d['MaterialID']==mt_id)&(Matl_SPS1d['SnapshotDate']==snap_date)]\n    if (((a['Planned_GR_date'].values[0]<=a['SnapshotDate'].values[0]) and (a['SnapshotDate'].values[0]<=a['Exp_GR_date'].values[0])) | ((a['Typical_GR_date'].values[0]<=a['SnapshotDate'].values[0]) and (a['SnapshotDate'].values[0]<=a['Exp_GR_date'].values[0]))):\n      lead_time_issue.append(1)\n      higher_consumption.append(0)\n    else:\n      lead_time_issue.append(0)\n      higher_consumption.append(1)\n  else:\n    lead_time_issue.append(0)\n    higher_consumption.append(0)\n    \nMatl_SPS1d['Higher_Lead_time_expected']=lead_time_issue\nMatl_SPS1d['Higher_Quantity_to_be_placed']=higher_consumption\nMatl_SPS1d['Exp_gr_week']=pd.to_datetime(Matl_SPS1d['Exp_GR_date']).dt.week"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f4317d19-326f-497f-9c97-f319241ecdfd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#consolidating the day wise SPS to weeks along with Exp_gr_week\nMatl_SPS3d = pd.pivot_table(Matl_SPS1d,values=['SPS','Higher_Lead_time_expected','Higher_Quantity_to_be_placed'],index=['LocationID','MaterialID', 'Week','Exp_gr_week'],aggfunc=['max']).reset_index()\nMatl_SPS3d.columns =[s1 + str(s2) for (s1,s2) in Matl_SPS3d.columns.tolist()]\nMatl_SPS3d.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e6f83e09-20f7-42bd-a925-c5d2a61e975c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["To get reasons for higher leadtime when an order is placed the following steps should be executed:\n1) Create a template with LocationID, MaterialID, Week, Exp_gr_week, maxHigher_Lead_time_expected, maxHigher_Quantity_to_be_placed, maxSPS.\n2) For a plant material combination which has maxHigher_Lead_time_expected as 1 in a given week get the top5 leadtime drivers for each vendors by joining with exp_gr_week.\n3) Again create a template but this time without Exp_gr_week.\n4) Join both the tables on LocationID, MaterialID, Week to get the reasons (Note: some weeks might have been flagged as maxHigher_Lead_time_expected but no leadtime drivers would be identified for such cases keep method=\"none\", weight=0, feature=\"Higher leadtime observed historically for this month\", updated_VS_id will still be null in this cases).\n5) For cases when maxHigher_Lead_time_expected is 0 feature is \"none\",weight is \"-1\" and method is \"none\"."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"07547cf1-6d92-45f3-8486-43523ef0fefc"}}},{"cell_type":"code","source":["#getting top 5 reason for leadtime for a plant material combination for a particular exp_gr_week\nprint(leadtime_reasons.shape)\nleadtime_reasons_sorted = leadtime_reasons.set_index(['feature','method','PO_Create_Date']).groupby(['MaterialID','LocationID','Exp_gr_week','updated_VS_ID'])['weight'].nlargest(100).reset_index()\nprint(leadtime_reasons_sorted.shape)\nleadtime_reasons_sorted.drop_duplicates(subset=['MaterialID','LocationID','Exp_gr_week','updated_VS_ID','feature'],keep='first',inplace=True)\nprint(leadtime_reasons_sorted.shape)\nleadtime_reasons_sorted1 = leadtime_reasons_sorted.set_index(['feature','method']).groupby(['MaterialID','LocationID','Exp_gr_week','updated_VS_ID'])['weight'].nlargest(5).reset_index()\nprint(leadtime_reasons_sorted1.shape)\nleadtime_reasons_sorted1.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8dd3bec5-3063-46b6-ae49-0b0a147d4cdb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#populating template with leadtime reasons\nstockout_reasons=Matl_SPS3d.merge(leadtime_reasons_sorted1,on=['MaterialID','LocationID','Exp_gr_week'],how='left')\nprint(stockout_reasons.shape)\n\n#getting top 5 reasons for a plant, material and week combination for each relevant vendor\nsubset_stockout=stockout_reasons[stockout_reasons['maxHigher_Lead_time_expected']==1]\nsubset_stockout = subset_stockout.set_index(['feature','method']).groupby(['MaterialID','LocationID','Week','updated_VS_ID'])['weight'].nlargest(100).reset_index()\nprint(subset_stockout.shape)\nsubset_stockout.drop_duplicates(subset=['MaterialID','LocationID','Week','updated_VS_ID','feature'],keep='first',inplace=True)\nprint(subset_stockout.shape)\nsubset_stockout = subset_stockout.set_index(['feature','method']).groupby(['MaterialID','LocationID','Week','updated_VS_ID'])['weight'].nlargest(5).reset_index()\nprint(subset_stockout.shape)\nsubset_stockout.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5a6e462a-8cf5-42a0-b1b4-4e66d06cf794"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#consolidating the day wise SPS to week wise to create a new template\nMatl_SPS4 = pd.pivot_table(Matl_SPS1d,values=['SPS','Higher_Lead_time_expected','Higher_Quantity_to_be_placed'],index=['LocationID','MaterialID', 'Week'],aggfunc=['max']).reset_index()\nMatl_SPS4.columns =[s1 + str(s2) for (s1,s2) in Matl_SPS4.columns.tolist()]\nMatl_SPS4.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"876ae2dc-f359-480c-8352-9e33f62a0d71"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#getting year attribute from the weeks\nyear_period=[]\nfor weeks in Matl_SPS4['Week']:\n  if ((weeks>=35) and (weeks<=52)):\n    year_period.append(2021)\n  else:\n    year_period.append(2022)\nMatl_SPS4['Year']=year_period\n\n#Scaling the SPS score from 0 - 0.5 to 0 - 10 by multiplying it with 20\nMatl_SPS4['SPS']=round(Matl_SPS4['maxSPS']*20,3)\n\n#getting start date of the week from week number and year\nWeek_date=[]\nfor week_num, years in zip(Matl_SPS4['Week'],Matl_SPS4['Year']):\n  d = \"{}-W{}\".format(years,week_num)\n  Week_date.append(datetime.datetime.strptime(d + '-1', \"%Y-W%W-%w\"))\nMatl_SPS4['Week_Date']=Week_date\n\n#updating week number\nupdate_week=[]\nfor week_num in Matl_SPS4['Week']:\n  update_week.append(\"Week-{}\".format(week_num))\nMatl_SPS4['Weeks']=update_week\n\n#Sorting values by plant, material and week date\nMatl_SPS4.sort_values(by=['LocationID','MaterialID','Week_Date'],inplace=True)\nMatl_SPS4.reset_index(inplace=True)\n\n#ceating week_counter using updated week\ncounter=[]\nStart_date = datetime.datetime.strptime(Start_dates, '%Y-%m-%d')\nfor weeks in Matl_SPS4['Weeks']:\n  if weeks==f\"Week-{int(Start_date.isocalendar()[1])}\":\n    a=0\n  else:\n    a=a+1\n  counter.append(a)\nMatl_SPS4['week_counter'] = counter \n\n#dropping columns\nMatl_SPS4.drop(columns=['Year','maxSPS','index'],inplace=True)\n\n#getting material description\nmat_descp['Sourcing']=[sourcing.split(\"-\")[0] for sourcing in mat_descp['Sourcing']]\nMatl_SPS4=pd.merge(Matl_SPS4,mat_descp,on=['MaterialID'],how='left')\n\n#getting plant names and zipcodes\npt_id=pd.DataFrame(data=[[5004,'Solon',44139],[5258,'Medford',54451],[5259,'Little Chute',54140],[5446,'Mt. Sterling',62353],[5878,'Jonesboro',72401],[5955,'Gaffney',29341],[5959,'Springville',84663]],columns=['LocationID','Plant_name','Zipcode'])\nMatl_SPS4=pd.merge(Matl_SPS4,pt_id,on='LocationID',how='inner')\n\n#renaming the column\nMatl_SPS4.rename(columns={'Mat Des':'Material_Description'},inplace=True)\nprint(Matl_SPS4.shape)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4eab33ef-e801-47a6-b4c4-6d80326ae658"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#merging to get the final template containing reasons for stockout for each week having maxHigher_Lead_time_expected as 1 \nstockout_reasons=Matl_SPS4.merge(subset_stockout,on=['MaterialID','LocationID','Week'],how='left')\nprint(stockout_reasons.shape)\n\nstockout_reasons.drop_duplicates(inplace=True)\n\n#null value treatment\nstockout_reasons['feature'].fillna('None',inplace=True)\nstockout_reasons['weight'].fillna(-1,inplace=True)\nstockout_reasons['method'].fillna('None',inplace=True)\nprint(stockout_reasons.shape)\n\n#cases where maxHigher_Lead_time_expected is 1 but there are no leadtime reasons the following values are setup.\nstockout_reasons.loc[(stockout_reasons['maxHigher_Lead_time_expected']==1) & (stockout_reasons['feature']=='None'),'feature']='Higher leadtime observed historically for this month'\nstockout_reasons.loc[(stockout_reasons['maxHigher_Lead_time_expected']==1) & (stockout_reasons['feature']=='Higher leadtime observed historically for this month'),'weight']=0"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"505909ea-b2a8-4172-91bd-987006d67adc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#Creating week group\ntempdf_week=pd.DataFrame(stockout_reasons['Week'])\ntempdf_week.drop_duplicates(inplace=True)\ntempdf_week.reset_index(inplace=True)\ntempdf_week.drop(columns='index',inplace=True)\ntempdf_week['Week_group']=np.nan\nfor indices in tempdf_week.index:\n  if indices < 6:\n    tempdf_week['Week_group'][indices]=\"1 to 6\"\n  elif ((indices >=6) & (indices < 12):\n    tempdf_week['Week_group'][indices]=\"7 to 12\"\n  elif ((indices >= 12) & (indices < 20)):\n    tempdf_week['Week_group'][indices]=\"13 to 20\"\n  elif ((indices >= 20) & (indices < 26)):\n    tempdf_week['Week_group'][indices]=\"21 to 26\"\ntempdf_week['Week_group']=tempdf_week['Week_group'].astype(str)\ntempdf_week"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a0647721-785b-4728-840b-8d1f3a63cc98"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#merging week group created with stockout_reasons\nprint(stockout_reasons.shape)\nstockout_reason_weekgrp=stockout_reasons.merge(tempdf_week,on='Week',how='left')\nprint(stockout_reason_weekgrp.shape)\n\n#getting max weight and max SPS for each week group in a plant material combination\nstockout_reason_weekgrp['Max_Weight_weekgroup']=stockout_reason_weekgrp.groupby(['LocationID','MaterialID','Week_group'])['weight'].transform(max)\nstockout_reason_weekgrp['Max_SPS_Weekgroup']=stockout_reason_weekgrp.groupby(['LocationID','MaterialID','Week_group'])['SPS'].transform(max)\nstockout_reason_weekgrp.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f258f355-a721-4db9-9a4c-dae1e3198a84"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#getting top 3 reasons for a week group\nsubset_week_group_reasons=stockout_reason_weekgrp.set_index(['feature','method']).groupby(['MaterialID','LocationID','Week_group'])['weight'].nlargest(1000).reset_index()\nprint(subset_week_group_reasons.shape)\nsubset_week_group_reasons.drop_duplicates(subset=['MaterialID','LocationID','Week_group','feature','weight'],keep='first',inplace=True)\nprint(subset_week_group_reasons.shape)\nsubset_week_group_reasons = subset_week_group_reasons.set_index(['feature','method']).groupby(['MaterialID','LocationID','Week_group'])['weight'].nlargest(3).reset_index()\nprint(subset_week_group_reasons.shape)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"47b83f4d-c5dd-4763-b81d-4125dcfff4be"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#creating a sequence_df which contains plant, material, weekgrp and Top3 reasons\nsequence_df=subset_week_group_reasons[['MaterialID','LocationID','Week_group']].copy()\nprint(sequence_df.shape)\nsequence_df.drop_duplicates(inplace=True)\nprint(sequence_df.shape)\nsequence_df['Events_group_top_3']=np.nan\n\nfor mat_id,plt_id,week_grp,indices in zip(sequence_df['MaterialID'],sequence_df['LocationID'],sequence_df['Week_group'],sequence_df.index):\n  tempdf=subset_week_group_reasons[(subset_week_group_reasons['MaterialID']==mat_id) & (subset_week_group_reasons['LocationID']==plt_id) & (subset_week_group_reasons['Week_group']==week_grp)]['feature'].copy()\n  a=tempdf.unique()\n  if len(a)>1:\n    indis = np.where(a=='None')\n    a = np.delete(a, indis)\n    if len(a)>1:\n      indis = np.where(a=='Higher leadtime observed historically for this month')\n      a = np.delete(a, indis)\n    else:\n      pass\n  else:\n    pass\n  a=list(a)\n  g = [' '.join(i.split('_')) for i in a]\n  b=str(list(a))\n  c=b[1:-1]\n  c=c.replace(\"'\",\"\")\n  sequence_df['Events_group_top_3'][indices]=c\nprint(sequence_df.shape)\nsequence_df.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4a951ef3-ace5-4afa-8017-175ee5347564"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#merging stockout reasons with sequence_df\nprint(stockout_reason_weekgrp.shape)\nstockout_reason_final=stockout_reason_weekgrp.merge(sequence_df,on=['MaterialID','LocationID','Week_group'],how='inner')\nprint(stockout_reason_final.shape)\n\n#getting vendor details by merging stockout_reason_final with vendor_desc and renaming the columns with respect to the PowerBI requirement.\nprint(stockout_reason_final.shape)\nstockout_reason_finalset=stockout_reason_final.merge(vendor_desc,on=['updated_VS_ID'],how='left')\nstockout_reason_finalset.rename(columns={'LocationID':'Plant_ID','maxHigher_Lead_time_expected':'Higher_Lead_time_expected','maxHigher_Quantity_to_be_placed':'Higher_Quantity_to_be_placed','week_counter':'Weeknum','feature':'Event','weight':'Impact','Description':'Supplier_Name'},inplace=True)\nstockout_reason_finalset.drop(columns='Week',inplace=True)\nprint(stockout_reason_finalset.shape)\nstockout_reason_finalset.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"13ad76c4-d4a6-4d70-a435-430c7331ba20"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#saving the SPS with leadtime reasons\ncol_names = ['_'.join(col.split(' ')) for col in stockout_reason_finalset.columns.tolist()]\nstockout_reason_finalset.columns = col_names\nSPS_leadtime_reasons_data = spark.createDataFrame(stockout_reason_finalset)\nSPS_leadtime_reasons_data.write.saveAsTable(SPS_leadtime_reasons_output,mode = 'overwrite')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f85fe185-d96d-48c3-b6d2-25b95668b968"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["stockout_reason_finalset.display()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c1145148-17d1-4615-9a28-132289c98e81"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#1. Creating output for actual Vs estimated number of Purchase orders for a given plant, material combination\n\nnum_pos=pd.DataFrame()\nplants=[]\nmatrls=[]\nacts=[]\nestm=[]\nStart_date = '{}'.format(Start_dates)\nStart_date = datetime.datetime.strptime(Start_date, '%Y-%m-%d')\nfor Plant,Matl in zip(Rop12['LocationID'],Rop12['MaterialID']):\n  ves_date['PO_Create_Date'] = pd.to_datetime(ves_date['PO_Create_Date'])\n  PO_original = ves_date[(ves_date['PO_Create_Date'] >= Start_date) & (ves_date['PO_Create_Date'] <= Start_date + timedelta(90)) & (ves_date['Material_No.'] ==Matl) & (ves_date['Plant_ID'] == Plant)]\n  plants.append(Plant)\n  matrls.append(Matl)\n  acts.append(PO_original.shape[0])\n  estm.append(forecasting[(forecasting['LocationID']==Plant) & (forecasting['MaterialID']==Matl) & (forecasting['SnapshotDate']>=Start_date) & (forecasting['SnapshotDate']<=Start_date + timedelta(90))]['Reorder'].sum())\nnum_pos['LocationID']=plants\nnum_pos['MaterialID']=matrls\nnum_pos['Actual_POs_in_this_period']=acts\nnum_pos['Estimated_POs_in_this_period']=estm\nprint(num_pos.shape)\nnum_pos.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Verifying Output","showTitle":true,"inputWidgets":{},"nuid":"8addae17-49a5-4eb8-8ac4-04e48a130c6c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["num_pos.display()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"202d1cd7-6533-44e9-824b-47dc08a9d27a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["mopos = spark.createDataFrame(num_pos)\nmopos.write.saveAsTable(actual_vs_forecasted_po,mode = 'overwrite')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b315909b-44b2-4961-96ab-b5c00bf24680"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#2. Inventory comparison between InventoryStockUnRestricted_daily and expected inventory for a given plant, material and week combination\nact_vs_fore_invt=pd.DataFrame()\nStart_date = '{}'.format(Start_dates)\nStart_date = datetime.datetime.strptime(Start_date, '%Y-%m-%d')\nfor Plant,Matl in zip(Rop12['LocationID'],Rop12['MaterialID']):\n  actual_inv = h_inv_fi[(h_inv_fi['SnapshotDate'] >= Start_date) & (h_inv_fi['SnapshotDate'] <= Start_date + timedelta(180)) & (h_inv_fi['MaterialID'] ==Matl) & (h_inv_fi['LocationID'] == Plant)]\n  actual_inv.drop(['InventoryUnitOfMeasure'], axis = 1, inplace = True)\n  actual_inv = pd.pivot_table(actual_inv,values='InventoryStockUnRestricted_daily',index=['LocationID','MaterialID', 'Week'],aggfunc=['max', 'min', 'mean']).reset_index()\n  actual_inv.columns =[s1 + str(s2) for (s1,s2) in actual_inv.columns.tolist()]\n\n  calc_inv = forecasting[(forecasting['MaterialID'] ==Matl) & (forecasting['LocationID'] == Plant)][['SnapshotDate', 'MaterialID', 'LocationID', 'Exp_inv']].copy()\n  calc_inv['Week']=calc_inv['SnapshotDate'].dt.week\n  calc_inv = pd.pivot_table(calc_inv,values='Exp_inv',index=['LocationID','MaterialID', 'Week'],aggfunc=['max', 'min', 'mean']).reset_index()\n  calc_inv.columns =[s1 + str(s2) for (s1,s2) in calc_inv.columns.tolist()]\n\n  act_vs_fore=pd.merge(actual_inv,calc_inv,on=['LocationID','MaterialID','Week'],how='right')\n  act_vs_fore_invt=act_vs_fore_invt.append(act_vs_fore,ignore_index=True)\nprint(act_vs_fore_invt.shape)\nact_vs_fore_invt.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"03953fbe-8678-4c1e-bb7a-f892037b3370"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["act_vs_fore_invt.display()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d3517b5f-df0c-42d8-a78c-37a0b9b646a5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["act_ind = spark.createDataFrame(act_vs_fore_invt)\nact_ind.write.saveAsTable(act_vs_fore_int,mode = 'overwrite')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"404a02fd-d1fb-474b-8cdf-6695412abaec"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#3. non prod days vs SPS\n\nSPS_w_non_p_days=pd.DataFrame()\nStart_date = '{}'.format(Start_dates)\nStart_date = datetime.datetime.strptime(Start_date, '%Y-%m-%d')\nfor Plant,Matl in zip(Rop12['LocationID'],Rop12['MaterialID']):\n  actual = Mb51matls[(Mb51matls['Material'] == Matl) & (Mb51matls['Plant'] == Plant) & (Mb51matls['Date'] >= Start_date) & (Mb51matls['Date'] <= Start_date + timedelta(90))]\n  actual['noprod'] = np.where(actual['Qty_in_BUoM']==0, 1, 0)\n  actual = pd.pivot_table(actual,values='noprod',index=['Plant','Material','week'],aggfunc='sum').reset_index()\n  Matl_SPS_2=Matl_SPS2d[(Matl_SPS2d['MaterialID'] == Matl) & (Matl_SPS2d['LocationID'] == Plant)].copy()\n  actual = pd.merge(Matl_SPS_2, actual, left_on = ['LocationID','MaterialID','Week'], right_on = ['Plant','Material','week'],how='inner')\n  actual.drop(columns=['week','Plant','Material'],axis=1,inplace=True)\n  SPS_w_non_p_days=SPS_w_non_p_days.append(actual,ignore_index=True)\nprint(SPS_w_non_p_days.shape)\nSPS_w_non_p_days.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e5d9c272-cd68-4a68-936f-f1f2eb1daf60"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["SPS_w_non_p_days.display()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5ef932b0-d45c-4fe4-8109-f551b9d44425"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["SPS_w_non_p_days_1 = spark.createDataFrame(SPS_w_non_p_days)\nSPS_w_non_p_days_1.write.saveAsTable(SPS_w_non_p_days_v1,mode = 'overwrite')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4c0a565e-1b8f-44aa-bcfb-3bdfa3ce6813"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["*************************END****************************************"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0f7d9e67-c24b-43f7-851c-b7483984c014"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"3.c SPS","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":1541108005201398}},"nbformat":4,"nbformat_minor":0}

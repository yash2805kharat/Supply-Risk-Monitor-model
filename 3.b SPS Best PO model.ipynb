{"cells":[{"cell_type":"code","source":["%run \"./2.c lead_time_predict\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Lead time predict notebook import","showTitle":true,"inputWidgets":{},"nuid":"08e4c0ea-43b1-45ef-ba15-9f10f38cfed4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["import pandas as pd\nimport numpy as np\nfrom scipy.stats import norm\n\nimport os\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nimport pickle\nfrom datetime import datetime as dt\nfrom datetime import timedelta\nimport xgboost\nfrom pandas.tseries.offsets import BDay\nimport math\nimport calendar\nimport datetime\nfrom datetime import date, timedelta\n\n%matplotlib inline"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Importing Library","showTitle":true,"inputWidgets":{},"nuid":"5155e56a-f1cb-42fc-8c47-9e9d129b4a15"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["pd.set_option('display.max_rows', 1000)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dee60193-6eba-499e-b772-60ad93c5444e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["h_inv_data='Historical_inventory_rawData_169_03_01'\n#reading historical inventory data\nh_inv = spark.table(h_inv_data)\nh_inv=h_inv.toPandas()\n\n\nMb51_data='consumptionmb51_roh_zpck_28_12'\n# MB51 import data\nMb51 = spark.table(Mb51_data)\nMb51 = Mb51.toPandas()\n\nves_data='model_data_vf_19_01'\n#ves data import\nves = spark.table(ves_data)\nves = ves.toPandas()\nves = ves[ves['PO_Create_Date']!='1888-01-01']\nves = ves[ves['Delivered_Quantity']!=0]\n\nves_w_po='enter file path to VES_data_final_06_12.csv'\n#reading ves old data to get the planned lead time\nves_old=pd.read_csv(ves_w_po)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Files & Tables imported","showTitle":true,"inputWidgets":{},"nuid":"96dad90b-4e5b-4633-b8af-9bd37861a490"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["model_forecasting='model_based_testing_90_days_op'\nmodel_numpos='model_based_numpos_90_days_op'\nprediction_forecasting='prediction_based_testing_90_days_op'\nprediction_numpos='prediction_based_numpos_90_days_op'\nmodels_saved='prediction_models_to_use'"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Output table","showTitle":true,"inputWidgets":{},"nuid":"56c3d3fd-24a7-4466-b56c-46843f6fa1d8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["model_run_date='2022-03-25'\nStart_dates = '2021-12-01'"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Forecast input date","showTitle":true,"inputWidgets":{},"nuid":"cba78ab8-a2e0-412a-85c8-f844fb8534fa"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["*To find the best prediction model between model_based_prediction and prediction_model(inventory based prediction) for a plant, material combination calculating the SPS (Stockout Possibility Score) consumption, inventory, material received, order placement will be simulated for the materials over the next 13 Weeks.\n*For this the following would be required: \n  1. Daily inventory in Hand\n  2. Historical MB51 consumption\n  3. Identifying the method of reorder namely inventory based reorder point or frequency based reorder point or both\n  4. getting expected lead time to estimate material received date\n  5. getting expected order placement to place orders"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"99274d90-d3cd-4887-a8a9-eccf9de4f6c9"}}},{"cell_type":"code","source":["#getting required fields from inventory\nh_inv_f=h_inv[['SnapshotDate','MaterialID','LocationID','BatchID','InventoryStockUnRestricted','InventoryUnitOfMeasure']]\nh_inv_f['SnapshotDate']=pd.to_datetime(h_inv['SnapshotDate'],format=\"%Y-%m-%d\")\n\n# Creating Week attribute\nh_inv_f['Week']=h_inv_f['SnapshotDate'].dt.week\nh_inv_f['SnapshotDate']=pd.to_datetime(h_inv['SnapshotDate'],format=\"%Y-%m-%d\").dt.date"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Calculating Inventory in Hand","showTitle":true,"inputWidgets":{},"nuid":"049c7663-e2d6-4d31-a4c3-ef86fa3f3161"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#To check if material has more than one UoM\ndat_check=h_inv_f[['MaterialID','InventoryUnitOfMeasure']]\ndat_check.drop_duplicates(inplace=True)\n\ndat_check1=pd.pivot_table(dat_check,values='InventoryUnitOfMeasure',index=['MaterialID'],aggfunc='count')\nprint(len(dat_check1['InventoryUnitOfMeasure'].unique()))\ndat_check1['InventoryUnitOfMeasure'].value_counts()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5b2e60e5-5235-4347-80bc-d0efceabc307"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#identifying total inventory stock unrestricted across batches for a given plant,material and day\nh_inv_f['InventoryStockUnRestricted_daily']=h_inv_f.groupby(by=['LocationID','MaterialID','SnapshotDate'])['InventoryStockUnRestricted'].transform(np.sum)\n\n#dropping batchID to get the plant, material and day wise inventory stock unrestricted\nh_inv_f.drop(columns=['BatchID','InventoryStockUnRestricted'],axis=1,inplace=True)\nh_inv_f.drop_duplicates(inplace=True)\n\n#sorting value with respect location ,material, snapshotdate and batch\nh_inv_fi=h_inv_f.sort_values(by=['LocationID','MaterialID','SnapshotDate']).reset_index()\nh_inv_fi.drop(columns='index',axis=1,inplace=True)\nh_inv_fi['SnapshotDate']=pd.to_datetime(h_inv_fi['SnapshotDate'],format=\"%Y-%m-%d\")\nprint(h_inv_fi.shape)\nh_inv_fi.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"61b2dc79-b86e-44c8-b843-38929ed1b4e5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#Code to fill MB51 missing dates\nMb51['Posting_Date'] = pd.to_datetime(Mb51['Posting_Date'])\nMb51matls = Mb51[['Plant', 'Material']].drop_duplicates()\n\n#Populating missing dates\nMb51alldates = pd.DataFrame()\nfor plant, matl in zip(Mb51matls['Plant'], Mb51matls['Material']):\n  Start = min(Mb51[(Mb51['Plant'] == plant) & (Mb51['Material'] == matl)]['Posting_Date'])\n  End = max(Mb51[(Mb51['Plant'] == plant) & (Mb51['Material'] == matl)]['Posting_Date'])\n\n  dRan1 = pd.date_range(start =Start, end =End, freq ='D')\n  dRan1 = pd.DataFrame({'Plant':plant, 'Material': matl, 'Date':dRan1})\n  \n  Mb51alldates = Mb51alldates.append(dRan1, ignore_index= True)\n  \n#merging all dates with MB51\nMb51matls = pd.merge(Mb51alldates, Mb51, left_on = ['Plant', 'Material', 'Date'], right_on = ['Plant', 'Material', 'Posting_Date'], how = 'left')\nMb51matls.drop(['Posting_Date'], inplace = True, axis = 1)\n\n#replacing null values with 0\nMb51matls['Qty_in_BUoM'] = Mb51matls['Qty_in_BUoM'].fillna(0)\n\n#creating week attribute\nMb51matls['week'] = Mb51matls['Date'].dt.week"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Getting Consumption from MB51","showTitle":true,"inputWidgets":{},"nuid":"2d93f4e2-6f62-48ed-96a8-410df634bee5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#Creating inventory consumption data table from MB51  \ninv_con1 = pd.pivot_table(Mb51matls,values='Qty_in_BUoM',index=['Plant','Material','week'],aggfunc=['mean', 'std']).reset_index()\ninv_con1.columns =[s1 + str(s2) for (s1,s2) in inv_con1.columns.tolist()]\ninv_con = inv_con1.rename(columns = {'Plant':'LocationID', 'Material':'MaterialID', 'week': 'Week', 'meanQty_in_BUoM':'daily_mean_consumption', 'stdQty_in_BUoM': 'std_dev_consumption'})"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"57bd20f8-2c33-41ea-b353-21c5f4b6d90a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#1. populating data for reorder point calculations\n\n#dropping null values and infinite values in column POqty_to_AvgDelQty\nves = ves.dropna(subset=['POqty_to_AvgDelQty'])\nves = ves[ves['POqty_to_AvgDelQty']!=np.inf]\n\n#selecting attributes needed from ves data\nves_date=ves[['Plant_ID','Material_No.','PO_Create_Date','Purchase_Order_Scheduled_Qty']]\n\n#Finding the total purchase order quantity for a given plant,material and po create date\nves_date['Total_ordered_QTY'] = ves_date.groupby(by=['Plant_ID','Material_No.','PO_Create_Date'])['Purchase_Order_Scheduled_Qty'].transform(np.sum)\nves_date.drop(columns=['Purchase_Order_Scheduled_Qty'],inplace=True)\nves_date.drop_duplicates(inplace=True)\nves_date.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Reorder Point calculation","showTitle":true,"inputWidgets":{},"nuid":"4c41968c-f9d3-42d8-99d4-d0f9028e52ee"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#2. Getting inventory in hand at the time of order placement\n\n# merging historical inventory with ves_date to get po create and po qty. \nRop1=pd.merge(h_inv_fi,ves_date,how='left',left_on=['LocationID','MaterialID','SnapshotDate'],right_on=['Plant_ID','Material_No.','PO_Create_Date']).reset_index()\nRop1.drop(columns=['index','Plant_ID','Material_No.'],axis=1,inplace=True)\n\n#filtering only the reorder dates from the combined data\nRop1=Rop1[Rop1['Total_ordered_QTY'].notna()]\n\n#sorting reorder point by plant, material and po create date and getting a reference index\nRop1.sort_values(by=['LocationID','MaterialID','PO_Create_Date'],inplace=True)\nRop1.reset_index(inplace=True)\nRop1.reset_index(inplace=True)\nRop1.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dcb11ef9-6fc0-419c-9b92-cd5218198b63"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#3. calculating the days between 2 consecutive orders\ndef checkPrevious(x):\n  try:\n    if((x['LocationID'] == Rop1.loc[x.level_0-1,'LocationID']) and (x['MaterialID'] == Rop1.loc[x.level_0-1, 'MaterialID'])):\n      return (x.PO_Create_Date - Rop1.loc[x.level_0 -1, 'PO_Create_Date']).days\n    else:\n      return 0\n  except:\n    print(\"Exception\")\n    return 0\n\n#getting day gap attibute between 2 purchase orders for the plant, material combinations\nRop1['days']= Rop1.apply(checkPrevious, 1)\nRop1.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"90f73a66-9aed-4ae4-9bda-6d544bf872c5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["* Material orders follow either an inventory based or frequency based reorder Method or a hybrid of both. \n* To classify the materials on the reorder method: \n  1. The % of orders historically placed +/-20% around the historic mean/median inventory at hand at time of order placement and (inventory based method)\n  2. The % of orders placed around +/-20% of the average time between 2 consecutive orders is found (frequency based method)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f374ab02-69c3-48b9-9e14-10643b9a57cc"}}},{"cell_type":"code","source":["#creating a table with unique set of plant and material combinations from the reorder point data\nreorder_method_check=Rop1[['LocationID','MaterialID']]\nreorder_method_check.drop_duplicates(inplace=True)\nreorder_method_check.shape[0]\n\n#mean,median,mode calculation and weightage of it on plant,mat combination to identify the order placement method\nfreqop=[]\ninvtop=[]\ninvtop_2=[]\nmodes=[]\nmedians=[]\nmeans=[]\nfor l_id,m_id in zip(reorder_method_check['LocationID'],reorder_method_check['MaterialID']):\n  a=Rop1[(Rop1['LocationID']==l_id) & (Rop1['MaterialID']==m_id)].copy()\n  c=a['days'].mean()\n  d=a['InventoryStockUnRestricted_daily'].median(axis=0)\n  e=a['InventoryStockUnRestricted_daily'].mean()\n  freqop.append(np.round(((a[(a['days']>=c*.8) & (a['days']<=c*1.2)].shape[0]/a.shape[0])*100),0))\n  invtop.append(np.round(((a[(a['InventoryStockUnRestricted_daily']>=d*.8) & (a['InventoryStockUnRestricted_daily']<=d*1.2)].shape[0]/a.shape[0])*100),0))\n  invtop_2.append(np.round(((a[(a['InventoryStockUnRestricted_daily']>=e*.8) & (a['InventoryStockUnRestricted_daily']<=e*1.2)].shape[0]/a.shape[0])*100),0))\n  modes.append(c)\n  medians.append(d)\n  means.append(e)\n  \n#method weightage along with values\nreorder_method_check['Frequency_Based_OP']=freqop\nreorder_method_check['Inventory_Based_OP_median']=invtop\nreorder_method_check['Inventory_Based_OP_mean']=invtop_2\nreorder_method_check['freq_val']=modes\nreorder_method_check['median_val']=medians\nreorder_method_check['mean_val']=means"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8c93acfc-6fd3-4c0e-8575-78d4dc47e778"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["reorder_method_check[(reorder_method_check['LocationID']==5955) & (reorder_method_check['MaterialID']==22002545)]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8264c3f4-ef73-4a9f-9227-5633f8d885f2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#flagging method of reorder point based on weightage of method (threshold 50%)\naty=[]\nfor fpq, ibm, ibe in zip(reorder_method_check['Frequency_Based_OP'],reorder_method_check['Inventory_Based_OP_median'],reorder_method_check['Inventory_Based_OP_mean']):\n  if (fpq<50) and (ibm<50) and (ibe<50): #if all values are less than threshold its hybrid\n    aty.append('hybrid')\n  else:\n    if (fpq>ibm) and (ibm>=ibe): # order percentage of freq>median>=mean trigger method as frequency\n      aty.append('frequency')\n    elif (fpq>ibe) and (ibm<=ibe): #order percentage of freq>mean>=median trigger method as frequency\n      aty.append('frequency')\n    elif (ibm>ibe) and (ibe>=fpq): #order percentage of median>mean>=frequency trigger method as median\n      aty.append('median')\n    elif (ibm>fpq) and (ibe<=fpq): #order percentage of median>frequency>=mean trigger method as median\n      aty.append('median')\n    elif (ibe>ibm) and (ibm>=fpq): #order percentage of mean>median>=frequency trigger method as mean\n      aty.append('mean')\n    elif (ibe>fpq) and (ibm<=fpq): #order percentage of mean>frequency>=median trigger method as mean\n      aty.append('mean')\n    elif (ibm==ibe) and (ibm>fpq): #order percentage of mean=median>frequency trigger method as median\n      aty.append('median')\n    elif (ibm==ibe) and (ibm==fpq): #order percentage of freq=mean=median trigger method as frequency\n      aty.append('frequency')\n    elif (fpq==ibm) and (ibm>ibe): #order percentage of freq=median>mean trigger method as frequency\n      aty.append('frequency')\n    elif (fpq==ibe) and (ibm<ibe): #order percentage of freq=mean>median trigger method as frequency\n      aty.append('frequency')\n\n#creating attribute for method flag\nreorder_method_check['flag']=aty\nreorder_method_check.reset_index(inplace=True)\nreorder_method_check.drop(['index'],axis=1,inplace=True)\n\n#tagging combinations of plant, material which has median_val 0 and flag median as not defined\nreorder_method_check.loc[(reorder_method_check['median_val']==0) & (reorder_method_check['flag']=='median'),'flag']='not_defined'\n\n#tagging combinations of plant, material with only one order which has freq_val 0 and flag frequency as not defined\nreorder_method_check.loc[(reorder_method_check['freq_val']==0) & (reorder_method_check['flag']=='frequency'),'flag']='not_defined'\nreorder_method_check['flag'].value_counts()\n\n#defining column data types \nreorder_method_check['mean_val']=round(reorder_method_check['mean_val'],0)\nreorder_method_check['mean_val']=reorder_method_check['mean_val'].astype(np.int64)\nreorder_method_check['freq_val']=round(reorder_method_check['freq_val'],0)\nreorder_method_check['freq_val']=reorder_method_check['freq_val'].astype(np.int64)\n\n#checking no of materials\nlen(reorder_method_check[(reorder_method_check['flag']!='not_defined')]['MaterialID'].unique())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"373849ff-6ce6-4b93-8c17-cd9efb483ade"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["reorder_method_check['flag'].value_counts()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d24eed06-1c4b-4a41-bbb2-3f7990c8288f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["reorder_method_check[reorder_method_check['flag']=='not_defined']"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d80528ff-3684-4063-8c69-e1e493270402"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#Finding the historic average fullfillment % of delivery quantity w.r.t to Purchase order qty.\nDelivery_qty = pd.pivot_table(ves,values=['Purchase_Order_Scheduled_Qty','Delivered_Quantity'],index=['Plant_ID','Material_No.', 'updated_VS_ID'],aggfunc='sum').reset_index()\nDelivery_qty['Fulfillment_rate'] = Delivery_qty['Delivered_Quantity']/Delivery_qty['Purchase_Order_Scheduled_Qty']\nDelivery_qty.loc[Delivery_qty['Fulfillment_rate']>1, 'Fulfillment_rate'] =1"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Vendor Attributes: Share of orders, Delivery Fulfillment Rate, Expected Order Quantity","showTitle":true,"inputWidgets":{},"nuid":"82199310-a4aa-4b78-9783-4e842347707b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#Finding the vendor share for a plant, material combination for purchase order\nOrder_share = Delivery_qty.copy()\nOrder_share.drop(['Delivered_Quantity', 'Fulfillment_rate'], inplace = True, axis =1)\n\nTotal_order = Order_share.groupby(['Material_No.', 'Plant_ID'])['Purchase_Order_Scheduled_Qty'].sum().reset_index()\nOrder_share = pd.merge(Order_share, Total_order, how = 'left', on = ['Material_No.', 'Plant_ID'])\nOrder_share['Vendor_share'] = Order_share['Purchase_Order_Scheduled_Qty_x']/Order_share['Purchase_Order_Scheduled_Qty_y']\nOrder_share.drop(['Purchase_Order_Scheduled_Qty_x', 'Purchase_Order_Scheduled_Qty_y'], inplace = True, axis = 1)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4c11c010-66af-43c4-b3a8-59f904b3cd07"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#Calculating order quantity for each vendor for a given plant , material combination and estimating how much the vendor will deliver\n\n#getting total reorder quantity for plant, material combo\nRoQ_Vendor=pd.pivot_table(Rop1.round({'Total_ordered_QTY':0}),values='Total_ordered_QTY',index=['LocationID','MaterialID'],aggfunc='mean').reset_index()\nRoQ_Vendor['Total_ordered_QTY']=RoQ_Vendor['Total_ordered_QTY'].astype(np.int64)\n\n#merging reorder quantity with order share to get vendor wise reorder quantity\nRoQ_Vendor = pd.merge(RoQ_Vendor, Order_share, how = 'left', right_on = ['Plant_ID', 'Material_No.'], left_on = ['LocationID', 'MaterialID'])\nRoQ_Vendor['Vendor_ROQ'] = RoQ_Vendor['Vendor_share']*RoQ_Vendor['Total_ordered_QTY']\nRoQ_Vendor['Vendor_ROQ'] = RoQ_Vendor['Vendor_ROQ'].round(0)\nRoQ_Vendor.drop(['Material_No.', 'Plant_ID', 'Vendor_share'], axis =1, inplace= True)\n\nRoQ_Vendor.rename(columns={'Total_ordered_QTY':'Avg_ordered_QTY'},inplace=True)\nRoQ_Vendor.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2a37311a-681f-4305-8325-1a6d41ae2de7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# 1. calculating average leadtime for plant, material combinations\n#cleaning ves data for getting lead time\nldt = ves.copy()\nldt = ldt.dropna(subset=['POqty_to_AvgDelQty'])\nldt = ldt[ldt['POqty_to_AvgDelQty']!=np.inf]\n\n#creating lead time attribute\nldt=ldt[['Plant_ID','Material_No.','First_GR_Date','PO_Create_Date']]\nldt['First_GR_Date']=pd.to_datetime(ldt['First_GR_Date'],utc=True)\nldt['First_GR_Date']=ldt['First_GR_Date'].dt.date\nldt['First_GR_Date']=pd.to_datetime(ldt['First_GR_Date'])\nldt['lead_time']=(ldt['First_GR_Date']-ldt['PO_Create_Date']).dt.days"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Getting Lead times","showTitle":true,"inputWidgets":{},"nuid":"a70c17bc-59c4-4aed-be94-9eaf78c704cc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# 2. Getting the Planned lead time\n\npldt=ves_old[['Plant','Material No.','Sum of Planned Days']].copy()\nprint('number of planned lead time records less than one',pldt[pldt['Sum of Planned Days']<1].shape[0])\n\n#identifying average planned lead time for a given plant and material\npldt_pivot=pd.pivot_table(pldt,values='Sum of Planned Days',index=['Plant','Material No.'],aggfunc='mean').reset_index()\npldt_pivot['Sum of Planned Days']=round(pldt_pivot['Sum of Planned Days'],0)\nprint('number of unique materials',len(pldt_pivot['Material No.'].unique()))\n\n#renaming the columns\npldt_pivot.rename(columns={'Plant':'LocationID','Material No.':'MaterialID','Sum of Planned Days':'Planned_avg_lead_time'},inplace=True)\npldt_pivot.head(3)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b24dd5ea-2873-43cb-9a06-00e4ed22d0eb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#lead time data cut w.r.t plant,material\nldt_cut=pd.pivot_table(ldt,values='lead_time',index=['Plant_ID','Material_No.'],aggfunc='mean').reset_index()\n\n#merging RoQ_Vendor with lead time\nvendor_plant_data=pd.merge(RoQ_Vendor,ldt_cut,left_on=['LocationID','MaterialID'],right_on=['Plant_ID','Material_No.'],how='inner')\nvendor_plant_data.drop(columns=['Plant_ID','Material_No.'],inplace=True)\nvendor_plant_data['lead_time']=round(vendor_plant_data['lead_time'],0)\nvendor_plant_data.rename(columns={'lead_time':'Avg_lead_time'},inplace=True)\nvendor_plant_data['Avg_lead_time']=vendor_plant_data['Avg_lead_time'].astype(np.int64)\n\n#merging vendor_plant_data with delivery qty\nvendor_plant_data = pd.merge(vendor_plant_data, Delivery_qty, how = 'left', left_on = ['LocationID', 'MaterialID', 'updated_VS_ID'], right_on = ['Plant_ID', 'Material_No.', 'updated_VS_ID'])\nvendor_plant_data.drop(['Plant_ID', 'Material_No.', 'Delivered_Quantity', 'Purchase_Order_Scheduled_Qty'], axis =1, inplace = True)\n\n#merging vendor_plant_data with planned lead time\nvendor_plant_data = pd.merge(vendor_plant_data, pldt_pivot, how = 'inner', on = ['LocationID', 'MaterialID'])\n\n#merging vendor_plant_data with check to get the flag and mthod values\nvendor_plant_data=pd.merge(vendor_plant_data,reorder_method_check, on =['LocationID','MaterialID'],how='left')\nvendor_plant_data.drop(columns=['Frequency_Based_OP','Inventory_Based_OP_median','Inventory_Based_OP_mean'],axis=1,inplace=True)\nvendor_plant_data=vendor_plant_data[vendor_plant_data['flag']!='not_defined']"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Compiling the Vendor - Plant data: Lead times, RoQ, Fulfillment, Reorder method","showTitle":true,"inputWidgets":{},"nuid":"e307eded-b294-4ecc-b252-f67f75b6b3e2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Checking common data availability across inventory and plant-vendor data\n\n# creating table with unique plant, material combination from vendor_plant_data\nRop12=vendor_plant_data[['LocationID','MaterialID']]\nRop12.drop_duplicates(inplace=True)\n\n#getting plant and material only for those which has historical inventory data on 2021-09-01\n\ninv_check=h_inv_fi[(h_inv_fi['SnapshotDate'] == Start_dates)][['LocationID','MaterialID']]\ninv_check.drop_duplicates(inplace=True)\n\n#filtering the plant and materials data which has historical inventory data on 2021-09-01\nprint(Rop12.shape,vendor_plant_data.shape)\nvendor_plant_data=pd.merge(vendor_plant_data,inv_check,on=['LocationID','MaterialID'],how='inner')\nRop12=pd.merge(Rop12,inv_check,on=['LocationID','MaterialID'],how='inner')\nprint(Rop12.shape,vendor_plant_data.shape)\nprint('Unique material count: ',len(Rop12['MaterialID'].unique()))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cc170057-49f6-426c-a7ca-cb78550c86bc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# def order_placed is used by model_based_prediction to determine when to place the order\ndef order_placed (SnapshotDate,Plants,Matls,Exp_invt,counter):\n  \n  #getting planned lead time\n  lead_time=pldt_pivot[(pldt_pivot['LocationID']==Plants) & (pldt_pivot['MaterialID']==Matls)]['Planned_avg_lead_time'].values[0]\n  \n  op=pd.DataFrame(data=[[SnapshotDate,Plants,Matls,Exp_invt,lead_time,counter]],columns=['SnapshotDate','LocationID','MaterialID','InventoryStockUnRestricted_daily','lead_time','counter'])\n  op['SnapshotDate']=pd.to_datetime(op['SnapshotDate']).dt.date\n  op['SnapshotDate']=pd.to_datetime(op['SnapshotDate'])\n  \n  # getting planned_gr date with extended_gr date of 2,4 and 6 weeks\n  try:\n    op['Planned_GR_date'] = pd.to_datetime(op['SnapshotDate']).dt.date + pd.to_timedelta(op['lead_time'], unit='D')\n  except:\n    ags=[]\n    for i,j in zip(op['SnapshotDate'],op['lead_time']):\n      ags.append(i+timedelta(int(j)))\n    op['Planned_GR_date']=ags\n\n  op['Planned_GR_date']=pd.to_datetime(op['Planned_GR_date']).dt.date\n  op['Planned_GR_date']=pd.to_datetime(op['Planned_GR_date'])\n  op['Extended_GR_date_2']=pd.to_datetime(op['Planned_GR_date'])+timedelta(14)\n  op['Extended_GR_date_2']=pd.to_datetime(op['Extended_GR_date_2']).dt.date\n  op['Extended_GR_date_2']=pd.to_datetime(op['Extended_GR_date_2'])\n  op['Extended_GR_date_4']=pd.to_datetime(op['Planned_GR_date'])+timedelta(28)\n  op['Extended_GR_date_4']=pd.to_datetime(op['Extended_GR_date_4']).dt.date\n  op['Extended_GR_date_4']=pd.to_datetime(op['Extended_GR_date_4'])\n  op['Extended_GR_date_6']=pd.to_datetime(op['Planned_GR_date'])+timedelta(42)\n  op['Extended_GR_date_6']=pd.to_datetime(op['Extended_GR_date_6']).dt.date\n  op['Extended_GR_date_6']=pd.to_datetime(op['Extended_GR_date_6'])\n  \n  Mb51mat=Mb51matls[(Mb51matls['Plant']==Plants) & (Mb51matls['Material']==Matls)]\n  avg_consump_w_0=pd.pivot_table(Mb51mat,values='Qty_in_BUoM',index=['Plant','Material'],aggfunc='mean').reset_index()\n  avg_con_w_0=abs(avg_consump_w_0[(avg_consump_w_0['Plant']==Plants) & (avg_consump_w_0['Material']==Matls)]['Qty_in_BUoM'].values[0])\n  \n  #creating a dataframe with all dates starting from snapshot date to extended_gr_date_6 and populating it with daily mean consumption\n  inv_con1=inv_con[(inv_con['LocationID']==Plants) & (inv_con['MaterialID']==Matls)]\n  alldates=pd.date_range(start=op['SnapshotDate'].values[0], end=op['Extended_GR_date_6'].values[0])\n  tempdf1=pd.DataFrame(alldates,columns=['dates'])\n  tempdf1['LocationID']=Plants\n  tempdf1['MaterialID']=Matls\n  tempdf1['Week']=tempdf1['dates'].dt.week\n  inv_consumption=pd.merge(tempdf1,inv_con1,on=['LocationID','MaterialID','Week'],how='left')       \n\n  consump_2=inv_consumption[(inv_consumption['LocationID']==Plants) & (inv_consumption['MaterialID']==Matls) & (inv_consumption['dates']>=op['Planned_GR_date'].values[0]) & (inv_consumption['dates']<op['Extended_GR_date_2'].values[0])]['daily_mean_consumption'].sum()\n\n  consump_4=inv_consumption[(inv_consumption['LocationID']==Plants) & (inv_consumption['MaterialID']==Matls) & (inv_consumption['dates']>=op['Planned_GR_date'].values[0]) & (inv_consumption['dates']<op['Extended_GR_date_4'].values[0])]['daily_mean_consumption'].sum()\n\n  consump_6=inv_consumption[(inv_consumption['LocationID']==Plants) & (inv_consumption['MaterialID']==Matls) & (inv_consumption['dates']>=op['Planned_GR_date'].values[0]) & (inv_consumption['dates']<op['Extended_GR_date_6'].values[0])]['daily_mean_consumption'].sum()\n  \n  # getting consumption ratio for 2,4 and 6 weeks along with inventory ratio\n  op['Expected_consumption_btw_gr_dates_2']=abs(consump_2)\n  op['Expected_consumption_btw_gr_dates_4']=abs(consump_4)\n  op['Expected_consumption_btw_gr_dates_6']=abs(consump_6)\n  op['inventory_ratio_with_0']=abs(op['InventoryStockUnRestricted_daily'].values[0]/avg_con_w_0)\n  op['Expected_consumption_ratio_2_with_0']=abs(consump_2/avg_con_w_0)\n  op['Expected_consumption_ratio_4_with_0']=abs(consump_4/avg_con_w_0)\n  op['Expected_consumption_ratio_6_with_0']=abs(consump_6/avg_con_w_0)\n\n  features=['counter','inventory_ratio_with_0','Expected_consumption_ratio_2_with_0', 'Expected_consumption_ratio_4_with_0', 'Expected_consumption_ratio_6_with_0']\n  \n  #Extracting the model object from the directory where the models were saved\n  op1=op[features].copy()\n  #print(op1)\n  file_nameds = '/dbfs/FileStore/models/classifiers/'+f\"{model_run_date}\"+'/'+str(Plants)+'/'+str(Matls)+'/'+ '_class_if.pkl'\n  loaded_model_classif = pickle.load(open(file_nameds, \"rb\"))\n  reorder_points = loaded_model_classif.predict(op1)[0]\n  #print(reorder_point)\n  return reorder_points"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4c99bb7e-092d-4a43-8f84-b015a4934ee4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["**Inorder to find which model between model_based_prediction (ML models) & trend_based (Inventory or frequency based) is suitable for forecasting the plant material combination.\n**We are going to follow below steps.\n\n  1. Simulate forecasting based on model_based_prediction for next 13 weeks.\n  2. Simulate forecasting based on trend_based for next 13 weeks.\n  3. Choosing best model based on whether the number of orders placed is the closest to actual.\n  4. In the trend_based checking the method flag type for inventory based mean or median whether it needs to be replaced by hybrid to improve order placement"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d5b93b54-9c3b-4fa5-8ada-7bdb6e14653d"}}},{"cell_type":"code","source":["###Setting up base for the 13 week forecast. \n# The inventory consumption/inflow and PO flag -> 'forecasted'\n# Identifying open Purchase orders and their expected delivery -> 'pending'\n# Vendors -> List of vendors for the material plant combination and their attributes\n\n\nforecasted=pd.DataFrame()\npending=pd.DataFrame()\nvendors=pd.DataFrame()\neli5_reasons=pd.DataFrame()\n\nStart_date = Start_dates\nStart_date = datetime.datetime.strptime(Start_date, '%Y-%m-%d')\n\n##### Getting the Reorder trigger attributes\n\nfor Plant,Matl in zip(Rop12['LocationID'],Rop12['MaterialID']):\n  try:\n  ############################## Dataframe for logging POs and expected dates of receipts#########################################\n    vendors1 = vendor_plant_data[(vendor_plant_data['LocationID']==Plant) & (vendor_plant_data['MaterialID']==Matl)]\n    vendors_v1 = vendors1[['LocationID', 'MaterialID', 'updated_VS_ID', 'Fulfillment_rate', 'Vendor_ROQ','Avg_lead_time','Planned_avg_lead_time']]\n\n    # Checking if there are open purchase orders in the VES and logging the same in the 'pending' dataframe\n    pending_v1 = ves[(ves['Plant_ID']==Plant) & (ves['Material_No.']==Matl) & (ves['PO_Create_Date'] <= Start_date) & (ves['Delivery_date'] >= Start_date)][['Plant_ID', 'Material_No.', 'PO_Create_Date', 'Purchase_Order_Scheduled_Qty', 'updated_VS_ID']]\n\n    if (pending_v1.shape[0] >0): #if there are open pending orders\n      pending_v1 = ves[(ves['Plant_ID']==Plant) & (ves['Material_No.']==Matl) & (ves['PO_Create_Date'] <= Start_date) & (ves['Delivery_date'] >= Start_date)][['Plant_ID', 'Material_No.', 'PO_Create_Date', 'Purchase_Order_Scheduled_Qty', 'updated_VS_ID']]\n      pending_v1 = pd.merge(pending_v1, vendors_v1, on = ['updated_VS_ID'], how = 'left')\n      pending_v1['Vendor_ROQ'] = pending_v1['Purchase_Order_Scheduled_Qty']\n      pds=[]\n      for pl_id,v_id,mt_id,po_c_d,p_qty in zip(pending_v1['LocationID'],pending_v1['updated_VS_ID'],pending_v1['MaterialID'],pending_v1['PO_Create_Date'].dt.date.astype(str),pending_v1['Vendor_ROQ']):\n\n        lead_time_pred,tempeli5 = pred_output(historical_data, pl_id, v_id, mt_id, po_c_d, p_qty) #predicting lead time for open orders\n        tempeli5['LocationID']=pl_id\n        tempeli5['updated_VS_ID']=v_id\n        tempeli5['MaterialID']=mt_id\n        tempeli5['PO_Create_Date']=po_c_d\n        eli5_reasons=eli5_reasons.append(tempeli5,ignore_index= True)\n        pds.append(lead_time_pred)\n      pending_v1['lead_time']=pds    \n\n      pending_v1 = pending_v1[['LocationID', 'MaterialID', 'updated_VS_ID', 'Fulfillment_rate', 'Vendor_ROQ', 'PO_Create_Date',  'lead_time', 'Avg_lead_time', 'Planned_avg_lead_time']]\n\n      #Getting expected delivery date and logging in pending\n      try:\n        pending_v1['Exp_GR_Date'] = pending_v1['PO_Create_Date'].dt.date + pd.to_timedelta(pending_v1['lead_time'], unit='D') \n      except:\n        ags=[]\n        for i,j in zip(pending_v1['PO_Create_Date'],pending_v1['lead_time']):\n          ags.append(i+timedelta(int(j)))\n        pending_v1['Exp_GR_Date']=ags\n        pending_v1['Exp_GR_Date']=pending_v1['Exp_GR_Date'].dt.date\n      pending_v1['Delivery_qty'] = pending_v1['Vendor_ROQ']*pending_v1['Fulfillment_rate']\n\n      date_since_order = np.timedelta64( Start_date - max(ves[(ves['Plant_ID']==Plant) & (ves['Material_No.']==Matl) & (ves['PO_Create_Date'] < Start_date)]['PO_Create_Date']), 'D')\n      date_since_order = date_since_order.astype(int)\n\n    else: #if no pending orders, create df with dummy values\n      pending_v1 = pd.DataFrame({'LocationID': [Plant], 'MaterialID': [Matl], 'updated_VS_ID': [0], 'Fulfillment_rate': [0.0], 'Vendor_ROQ': [0.0], 'PO_Create_Date': ['2000-01-01'],'lead_time': [0],'Avg_lead_time':[0],'Planned_avg_lead_time':[0]})\n      pending_v1['PO_Create_Date'] =   pd.to_datetime(pending_v1['PO_Create_Date'], format=\"%Y-%m-%d\") \n      pending_v1['Exp_GR_Date'] = pending_v1['PO_Create_Date'].dt.date + pd.to_timedelta(pending_v1['lead_time'].values[0], unit='D')\n      pending_v1['Delivery_qty'] = pending_v1['Vendor_ROQ']*pending_v1['Fulfillment_rate']\n\n      date_since_order = np.timedelta64( Start_date - max(ves[(ves['Plant_ID']==Plant) & (ves['Material_No.']==Matl) & (ves['PO_Create_Date'] < Start_date)]['PO_Create_Date']), 'D')\n      date_since_order = date_since_order.astype(int)\n\n    ############################## Dataframe for consumption, receipts and PO triggers#########################################\n    #Creating only the first row of the forecasted dataframe with the following elements:\n    # 1. Snapshot Date\n    # 2. Material ID\n    # 3. Location ID\n    # 4. Uinit of Measure\n    # 5. Week\n    # 6. Inventory stock in hand (from the inventory history)\n    # 7. Average Consumption\n    # 8. Std Deviation of consumption\n    # 9. Material received\n    # 10. Expected inventory at the end of the day = inventory in hand - consumption + \n    # 11. Counter: Count of days since last order \n    # 12. Reorder flag\n\n    forecasted_v1 = h_inv_fi[(h_inv_fi['SnapshotDate'] == Start_date) & (h_inv_fi['MaterialID'] ==Matl) & (h_inv_fi['LocationID'] == Plant)]\n    forecasted_v1=pd.merge(forecasted_v1,inv_con,on=['LocationID','MaterialID','Week'],how='left')\n    forecasted_v1['Matl_Recp'] = pending_v1.loc[pending_v1['Exp_GR_Date'] == pd.to_datetime(Start_date) , 'Delivery_qty'].sum()\n    forecasted_v1.loc[forecasted_v1['daily_mean_consumption'].isnull()==True,'daily_mean_consumption']=0\n    forecasted_v1['Exp_inv'] = max((forecasted_v1['InventoryStockUnRestricted_daily'].astype(np.int64) + forecasted_v1['daily_mean_consumption'].astype(np.int64) + forecasted_v1['Matl_Recp'].astype(np.int64)).values[0],0)\n    forecasted_v1['counter'] = date_since_order\n\n    # check if order needs to be placed on start date. If yes, log PO Create date, Vendor, lead time, expected delivery date, PO Quantity, Expected delivery in Pending based on the predited order placement\n    # Inventory based reorder check\n\n    if max(pending_v1['PO_Create_Date'])==Start_date:\n      forecasted_v1['Reorder']=1\n\n    #order placement prediction\n    else:\n      reorder_call = order_placed(forecasted_v1['SnapshotDate'].values[0],forecasted_v1['LocationID'].values[0],forecasted_v1['MaterialID'].values[0],forecasted_v1['Exp_inv'].values[0],forecasted_v1['counter'].values[0])        \n\n      forecasted_v1['Reorder'] = reorder_call\n\n\n    if (forecasted_v1['Reorder'].values[0] == 1):\n      po_place = vendors_v1.copy()\n      po_place['PO_Create_Date'] = Start_date\n      po_place['PO_Create_Date'] = pd.to_datetime(po_place['PO_Create_Date'], format=\"%Y-%m-%d\")\n\n      pds=[]\n      for pl_id,v_id,mt_id,po_c_d,p_qty in zip(po_place['LocationID'],po_place['updated_VS_ID'],po_place['MaterialID'],po_place['PO_Create_Date'].dt.date.astype(str),po_place['Vendor_ROQ']):\n        lead_time_pred,tempeli5 = pred_output(historical_data, pl_id, v_id, mt_id, po_c_d, p_qty)\n        tempeli5['LocationID']=pl_id\n        tempeli5['updated_VS_ID']=v_id\n        tempeli5['MaterialID']=mt_id\n        tempeli5['PO_Create_Date']=po_c_d\n        eli5_reasons=eli5_reasons.append(tempeli5,ignore_index= True)\n        pds.append(lead_time_pred)\n      po_place['lead_time']=pds\n\n      try:\n        po_place['Exp_GR_Date'] = po_place['PO_Create_Date'].dt.date + pd.to_timedelta(po_place['lead_time'], unit='D')\n      except:\n        ags=[]\n        for i,j in zip(po_place['PO_Create_Date'],po_place['lead_time']):\n          ags.append(i+timedelta(int(j)))\n        po_place['Exp_GR_Date']=ags\n        po_place['Exp_GR_Date']=po_place['Exp_GR_Date'].dt.date\n      po_place['Delivery_qty'] = po_place['Vendor_ROQ']*po_place['Fulfillment_rate']\n      pending_v1 = pending_v1.append(po_place, ignore_index= True)\n    forecasted=forecasted.append(forecasted_v1,ignore_index= True)\n    pending=pending.append(pending_v1,ignore_index= True)\n    vendors=vendors.append(vendors_v1,ignore_index= True)\n  except:\n    print(Plant,Matl,'- unable to build model')\n  ####End of loop\n\nforecasted['InventoryStockUnRestricted_daily']=forecasted['InventoryStockUnRestricted_daily'].astype(np.int64)\nforecasted['daily_mean_consumption']=forecasted['daily_mean_consumption'].astype(np.int64)\nforecasted['Exp_inv']=forecasted['Exp_inv'].astype(np.int64)\npending['Delivery_qty']=pending['Delivery_qty'].astype(np.int64)\npending['Exp_GR_Date']=pd.to_datetime(pending['Exp_GR_Date'])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Forecasting consumption and PO creation for Model_based_prediction","showTitle":true,"inputWidgets":{},"nuid":"ccc2f079-1538-4766-afef-dab95090ed1e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["print(pending.shape)\npending.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f0cb38b1-e297-4927-8c0d-3056ebd132b6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["print(forecasted.shape)\nforecasted.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a226b994-a036-4e44-a154-2209201d19c9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["print(eli5_reasons.shape)\neli5_reasons.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1db80488-4ccd-49a2-bddf-9f4667520d64"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["############Forecasting consumption, order placement, material receipts and expected inventory for next 90 days\n\nforecasting=pd.DataFrame()\npendings=pd.DataFrame()\nleadtime_reasons=pd.DataFrame()\n\nStart_date = Start_dates\nStart_date = datetime.datetime.strptime(Start_date, '%Y-%m-%d')\n\nfor Plant,Matl in zip(Rop12['LocationID'],Rop12['MaterialID']):\n  try:\n    forecasted1=forecasted[(forecasted['LocationID']==Plant) & (forecasted['MaterialID']==Matl)].copy()\n    pending1=pending[(pending['LocationID']==Plant)&(pending['MaterialID']==Matl)].copy()\n    vendors1=vendors[(vendors['LocationID']==Plant)&(vendors['MaterialID']==Matl)].copy()\n    leadtime_reasons1=eli5_reasons[(eli5_reasons['LocationID']==Plant)&(eli5_reasons['MaterialID']==Matl)].copy()\n\n    for i in range(1,90):\n      #Last updated date\n      td=timedelta(i)\n      todate = Start_date+td\n      tempdf = forecasted1.tail(1).copy() # taking the latest entry of the forecasted\n      tempdf['SnapshotDate'] = todate\n      tempdf['Week'] = int(todate.isocalendar()[1])\n      if tempdf['Reorder'].values[0] ==1:\n        tempdf['counter']=1\n        tempdf['Reorder'] = 0\n      else:        \n        tempdf['counter'] = tempdf['counter'].values[0] + 1\n        tempdf['Reorder'] = 0\n\n      # Update Consumption stats\n      try:\n        tempdf['daily_mean_consumption'] = inv_con.loc[(inv_con['MaterialID'] == Matl) & (inv_con['LocationID'] == Plant) & (inv_con['Week'] == int(todate.isocalendar()[1])),'daily_mean_consumption'].values[0]\n        tempdf['std_dev_consumption'] = inv_con.loc[(inv_con['MaterialID'] == Matl) & (inv_con['LocationID'] == Plant) & (inv_con['Week'] == int(todate.isocalendar()[1])), 'std_dev_consumption'].values[0]\n      except:\n        tempdf['daily_mean_consumption'] = 0\n        tempdf['std_dev_consumption'] = 0\n\n      # Update Material Receipt\n      tempdf['Matl_Recp'] = pending1.loc[pending1['Exp_GR_Date'] == pd.to_datetime(todate), 'Delivery_qty'].sum()\n\n      # Update the Expected inventory\n      inv_calc = max((tempdf['Exp_inv'] + tempdf['Matl_Recp'] + tempdf['daily_mean_consumption']).values[0], 0) #Non negative inventory\n      tempdf['Exp_inv']= int(inv_calc)\n\n      #   Order Placement prediction\n      if (forecasted1['Reorder'].tail(3).sum()==0):\n        reorder = order_placed(tempdf['SnapshotDate'].values[0],tempdf['LocationID'].values[0],tempdf['MaterialID'].values[0],tempdf['Exp_inv'].values[0],tempdf['counter'].values[0])        \n        tempdf['Reorder'] = reorder\n      else:\n        tempdf['Reorder']=0\n    # Order logging in 'Pending' by suppliers, PO Create date, Expected delivery, PO Qty and expected delivery qty:\n      if(tempdf['Reorder'].values[0] ==1):\n        po_place = vendors1.copy()\n        po_place['PO_Create_Date'] = todate\n        po_place['PO_Create_Date'] = pd.to_datetime(po_place['PO_Create_Date'], format=\"%Y-%m-%d\")\n        pds=[]\n        for pl_id,v_id,mt_id,po_c_d,p_qty in zip(po_place['LocationID'], po_place['updated_VS_ID'], po_place['MaterialID'], po_place['PO_Create_Date'].dt.date.astype(str), po_place['Vendor_ROQ']):\n          lead_time_pred,tempeli5 = pred_output(historical_data, pl_id, v_id, mt_id, po_c_d, p_qty)\n          tempeli5['LocationID']=pl_id\n          tempeli5['updated_VS_ID']=v_id\n          tempeli5['MaterialID']=mt_id\n          tempeli5['PO_Create_Date']=po_c_d\n          leadtime_reasons1=leadtime_reasons1.append(tempeli5,ignore_index= True)\n          pds.append(lead_time_pred)\n        po_place['lead_time']=pds\n        try:\n          po_place['Exp_GR_Date'] = po_place['PO_Create_Date'].dt.date + pd.to_timedelta(po_place['lead_time'], unit='D')\n        except:\n          ags=[]\n          for i,j in zip(po_place['PO_Create_Date'],po_place['lead_time']):\n            ags.append(i+timedelta(int(j)))\n          po_place['Exp_GR_Date']=ags\n          po_place['Exp_GR_Date']=po_place['Exp_GR_Date'].dt.date\n        po_place['Delivery_qty'] = po_place['Vendor_ROQ']*po_place['Fulfillment_rate']\n\n        pending1 = pending1.append(po_place, ignore_index= True)\n      forecasted1=forecasted1.append(tempdf,ignore_index=True)\n    forecasting=forecasting.append(forecasted1,ignore_index=True)\n    leadtime_reasons=leadtime_reasons.append(leadtime_reasons1,ignore_index=True)\n    pendings=pendings.append(pending1,ignore_index=True)\n  except:\n    print(Plant,Matl,'- unable to build model')\n  ####End of loop\n    \npendings['Exp_GR_Date']=pd.to_datetime(pendings['Exp_GR_Date'])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0b2fd7eb-d168-40d3-9566-49266220b1c8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["print(leadtime_reasons.shape)\nleadtime_reasons.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"115c0b03-0aba-4383-be7e-ecb6da150a8f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["print(forecasting.shape)\nforecasting.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6c4d1cf2-35ea-4ccb-b80f-1ae56bd1e06e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["print(pendings.shape)\npendings.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1b2f2419-5e8b-41cf-92fb-2571d32fc7b4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["fore = spark.createDataFrame(forecasting)\nfore.write.saveAsTable(model_forecasting,mode = 'overwrite')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b5c0b840-cb45-4678-9d15-a909c3bb485a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["Rop350=forecasting[['LocationID','MaterialID']].copy()\nRop350.drop_duplicates(inplace=True)\nRop350.shape"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"538c65fb-f61c-4aa6-8f7a-6ce84eb0d5f8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#1. Creating output for actual Vs estimated number of Purchase orders for a given plant, material combination\n\nnum_pos=pd.DataFrame()\nplants=[]\nmatrls=[]\nacts=[]\nestm=[]\nStart_date = '{}'.format(Start_dates)\nStart_date = datetime.datetime.strptime(Start_date, '%Y-%m-%d')\nfor Plant,Matl in zip(Rop350['LocationID'],Rop350['MaterialID']):\n  ves_date['PO_Create_Date'] = pd.to_datetime(ves_date['PO_Create_Date'])\n  PO_original = ves_date[(ves_date['PO_Create_Date'] >= Start_date) & (ves_date['PO_Create_Date'] <= Start_date + timedelta(90)) & (ves_date['Material_No.'] ==Matl) & (ves_date['Plant_ID'] == Plant)]\n  plants.append(Plant)\n  matrls.append(Matl)\n  acts.append(PO_original.shape[0])\n  estm.append(forecasting[(forecasting['LocationID']==Plant) & (forecasting['MaterialID']==Matl) & (forecasting['SnapshotDate']>=Start_date) & (forecasting['SnapshotDate']<=Start_date + timedelta(90))]['Reorder'].sum())\nnum_pos['LocationID']=plants\nnum_pos['MaterialID']=matrls\nnum_pos['Actual_POs_in_this_period']=acts\nnum_pos['Estimated_POs_in_this_period']=estm\nnum_pos['model']='model_based_prediction'\nprint(num_pos.shape)\nnum_pos.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c3fd001e-f821-42ca-9f57-9ae0d8684b39"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["mopos = spark.createDataFrame(num_pos)\nmopos.write.saveAsTable(model_numpos,mode = 'overwrite')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0914b89c-1159-45c6-8bdd-cf4cf9ba1171"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["###Setting up base for the 13 week forecast. \n# The inventory consumption/inflow and PO flag -> 'forecasted'\n# Identifying open Purchase orders and their expected delivery -> 'pending'\n# Vendors -> List of vendors for the material plant combination and their attributes\n\nforecasted=pd.DataFrame()\npending=pd.DataFrame()\nvendors=pd.DataFrame()\neli5_reasons=pd.DataFrame()\n\nStart_date = Start_dates\nStart_date = datetime.datetime.strptime(Start_date, '%Y-%m-%d')\n\n##### Getting the Reorder trigger attributes\nfor Plant,Matl in zip(Rop12['LocationID'],Rop12['MaterialID']):\n#   try:\n  ROP_freq = vendor_plant_data.loc[(vendor_plant_data['LocationID'] == Plant) & (vendor_plant_data['MaterialID'] == Matl), 'freq_val'].values[0]\n  ROP_median = vendor_plant_data.loc[(vendor_plant_data['LocationID'] == Plant) & (vendor_plant_data['MaterialID'] == Matl), 'median_val'].values[0]\n  ROP_mean = vendor_plant_data.loc[(vendor_plant_data['LocationID'] == Plant) & (vendor_plant_data['MaterialID'] == Matl), 'mean_val'].values[0]\n  ROP_method = vendor_plant_data.loc[(vendor_plant_data['LocationID'] == Plant) & (vendor_plant_data['MaterialID'] == Matl), 'flag'].values[0]\n\n  if (ROP_method == 'mean'):\n    ROP = ROP_mean\n  else:\n    ROP = ROP_median\n\n  ############################## Dataframe for logging POs and expected dates of receipts#########################################\n  vendors1 = vendor_plant_data[(vendor_plant_data['LocationID']==Plant) & (vendor_plant_data['MaterialID']==Matl)]\n  vendors_v1 = vendors1[['LocationID', 'MaterialID', 'updated_VS_ID', 'Fulfillment_rate', 'Vendor_ROQ','Avg_lead_time','Planned_avg_lead_time']]\n\n  # Checking if there are open purchase orders in the VES and logging the same in the 'pending' dataframe\n  pending_v1 = ves[(ves['Plant_ID']==Plant) & (ves['Material_No.']==Matl) & (ves['PO_Create_Date'] <= Start_date) & (ves['Delivery_date'] >= Start_date)][['Plant_ID', 'Material_No.', 'PO_Create_Date', 'Purchase_Order_Scheduled_Qty', 'updated_VS_ID']]\n\n  if (pending_v1.shape[0] >0): #if there are open pending orders\n    pending_v1 = ves[(ves['Plant_ID']==Plant) & (ves['Material_No.']==Matl) & (ves['PO_Create_Date'] <= Start_date) & (ves['Delivery_date'] >= Start_date)][['Plant_ID', 'Material_No.', 'PO_Create_Date', 'Purchase_Order_Scheduled_Qty', 'updated_VS_ID']]\n    pending_v1 = pd.merge(pending_v1, vendors_v1, on = ['updated_VS_ID'], how = 'left')\n    pending_v1['Vendor_ROQ'] = pending_v1['Purchase_Order_Scheduled_Qty']\n    pds=[]\n    for pl_id,v_id,mt_id,po_c_d,p_qty in zip(pending_v1['LocationID'],pending_v1['updated_VS_ID'],pending_v1['MaterialID'],pending_v1['PO_Create_Date'].dt.date.astype(str),pending_v1['Vendor_ROQ']):\n\n      #print(pl_id, v_id, mt_id, po_c_d, p_qty)\n      lead_time_pred,tempeli5 = pred_output(historical_data, pl_id, v_id, mt_id, po_c_d, p_qty) #predicting lead time for open orders\n      tempeli5['LocationID']=pl_id\n      tempeli5['updated_VS_ID']=v_id\n      tempeli5['MaterialID']=mt_id\n      tempeli5['PO_Create_Date']=po_c_d\n      eli5_reasons=eli5_reasons.append(tempeli5,ignore_index= True)\n      pds.append(lead_time_pred)\n    pending_v1['lead_time']=pds    \n\n    pending_v1 = pending_v1[['LocationID', 'MaterialID', 'updated_VS_ID', 'Fulfillment_rate', 'Vendor_ROQ', 'PO_Create_Date',  'lead_time', 'Avg_lead_time', 'Planned_avg_lead_time']]\n\n    #Getting expected delivery date and logging in pending\n    try:\n      pending_v1['Exp_GR_Date'] = pending_v1['PO_Create_Date'].dt.date + pd.to_timedelta(pending_v1['lead_time'], unit='D') \n    except:\n      ags=[]\n      for i,j in zip(pending_v1['PO_Create_Date'],pending_v1['lead_time']):\n        ags.append(i+timedelta(int(j)))\n      pending_v1['Exp_GR_Date']=ags\n      pending_v1['Exp_GR_Date']=pending_v1['Exp_GR_Date'].dt.date\n    pending_v1['Delivery_qty'] = pending_v1['Vendor_ROQ']*pending_v1['Fulfillment_rate']\n    date_since_order = np.timedelta64( Start_date - max(pending_v1['PO_Create_Date']), 'D')\n    date_since_order = date_since_order.astype(int)\n\n  else: #if no pending orders, create df with dummy values\n    pending_v1 = pd.DataFrame({'LocationID': [Plant], 'MaterialID': [Matl], 'updated_VS_ID': [0], 'Fulfillment_rate': [0.0], 'Vendor_ROQ': [0.0], 'PO_Create_Date': ['2000-01-01'],'lead_time': [0],'Avg_lead_time':[0],'Planned_avg_lead_time':[0]})\n    pending_v1['PO_Create_Date'] =   pd.to_datetime(pending_v1['PO_Create_Date'], format=\"%Y-%m-%d\") \n    pending_v1['Exp_GR_Date'] = pending_v1['PO_Create_Date'].dt.date + pd.to_timedelta(pending_v1['lead_time'].values[0], unit='D')\n    pending_v1['Delivery_qty'] = pending_v1['Vendor_ROQ']*pending_v1['Fulfillment_rate']\n    date_since_order = 0\n\n  ############################## Dataframe for consumption, receipts and PO triggers#########################################\n  #Creating only the first row of the forecasted dataframe with the following elements:\n  # 1. Snapshot Date\n  # 2. Material ID\n  # 3. Location ID\n  # 4. Uinit of Measure\n  # 5. Week\n  # 6. Inventory stock in hand (from the inventory history)\n  # 7. Average Consumption\n  # 8. Std Deviation of consumption\n  # 9. Material received\n  # 10. Expected inventory at the end of the day = inventory in hand - consumption + \n  # 11. Counter: Count of days since last order \n  # 12. Reorder flag\n\n  forecasted_v1 = h_inv_fi[(h_inv_fi['SnapshotDate'] == Start_date) & (h_inv_fi['MaterialID'] ==Matl) & (h_inv_fi['LocationID'] == Plant)]\n  forecasted_v1=pd.merge(forecasted_v1,inv_con,on=['LocationID','MaterialID','Week'],how='left')\n  forecasted_v1['Matl_Recp'] = pending_v1.loc[pending_v1['Exp_GR_Date'] == pd.to_datetime(Start_date) , 'Delivery_qty'].sum()\n  forecasted_v1.loc[forecasted_v1['daily_mean_consumption'].isnull()==True,'daily_mean_consumption']=0\n  forecasted_v1['Exp_inv'] = max((forecasted_v1['InventoryStockUnRestricted_daily'].astype(np.int64) + forecasted_v1['daily_mean_consumption'].astype(np.int64) + forecasted_v1['Matl_Recp'].astype(np.int64)).values[0],0)\n\n\n  forecasted_v1['counter'] = date_since_order\n  forecasted_v1['Reorder'] = 0\n\n  # check if order needs to be placed on start date. Uf yes, log PO Create date, Vendor, lead time, expected delivery date, PO Quantity, Expected delivery in Pending based on the method of reorder\n  # Inventory based reorder check\n\n  if max(pending_v1['PO_Create_Date'])==Start_date:\n    forecasted_v1['Reorder']=1\n\n  elif ((ROP_method == 'median') | (ROP_method == 'mean')):\n    if ((forecasted_v1['InventoryStockUnRestricted_daily'].values[0] >= ROP) & (forecasted_v1['Exp_inv'].values[0] < ROP)):\n      forecasted_v1['Reorder'] = 1\n\n\n  # Frequency based reorder check\n  elif (ROP_method == 'frequency'):\n    if (date_since_order >= ROP_freq):\n      forecasted_v1['Reorder'] = 1\n\n  # Hybrid Reorder check\n  elif (ROP_method == 'hybrid'): #(here ROP is median, ROP_freq is mode)\n    if (((date_since_order >= ROP_freq) & (forecasted_v1['Exp_inv'].values[0]<ROP))  | ((forecasted_v1['InventoryStockUnRestricted_daily'].values[0] >= ROP) & (forecasted_v1['Exp_inv'].values[0] < ROP))):\n      forecasted_v1['Reorder'] = 1\n\n  if (forecasted_v1['Reorder'].values[0] == 1):\n    po_place = vendors_v1.copy()\n    po_place['PO_Create_Date'] = Start_date\n    po_place['PO_Create_Date'] = pd.to_datetime(po_place['PO_Create_Date'], format=\"%Y-%m-%d\")\n\n    pds=[]\n    for pl_id,v_id,mt_id,po_c_d,p_qty in zip(po_place['LocationID'],po_place['updated_VS_ID'],po_place['MaterialID'],po_place['PO_Create_Date'].dt.date.astype(str),po_place['Vendor_ROQ']):\n      #print(pl_id, v_id, mt_id, po_c_d, p_qty)\n      lead_time_pred,tempeli5 = pred_output(historical_data, pl_id, v_id, mt_id, po_c_d, p_qty)\n      tempeli5['LocationID']=pl_id\n      tempeli5['updated_VS_ID']=v_id\n      tempeli5['MaterialID']=mt_id\n      tempeli5['PO_Create_Date']=po_c_d\n      eli5_reasons=eli5_reasons.append(tempeli5,ignore_index= True)\n      pds.append(lead_time_pred)\n    po_place['lead_time']=pds\n\n    try:\n      po_place['Exp_GR_Date'] = po_place['PO_Create_Date'].dt.date + pd.to_timedelta(po_place['lead_time'], unit='D')\n    except:\n      ags=[]\n      for i,j in zip(po_place['PO_Create_Date'],po_place['lead_time']):\n        ags.append(i+timedelta(int(j)))\n      po_place['Exp_GR_Date']=ags\n      po_place['Exp_GR_Date']=po_place['Exp_GR_Date'].dt.date\n    po_place['Delivery_qty'] = po_place['Vendor_ROQ']*po_place['Fulfillment_rate']\n    forecasted_v1['counter'] = 0\n    pending_v1 = pending_v1.append(po_place, ignore_index= True)\n  forecasted=forecasted.append(forecasted_v1,ignore_index= True)\n  pending=pending.append(pending_v1,ignore_index= True)\n  vendors=vendors.append(vendors_v1,ignore_index= True)\n#   except:\n#     print(Plant,Matl,\"- Unable to build invt based model\")\n####End of loop\n\nforecasted['InventoryStockUnRestricted_daily']=forecasted['InventoryStockUnRestricted_daily'].astype(np.int64)\nforecasted['daily_mean_consumption']=forecasted['daily_mean_consumption'].astype(np.int64)\nforecasted['Exp_inv']=forecasted['Exp_inv'].astype(np.int64)\npending['Delivery_qty']=pending['Delivery_qty'].astype(np.int64)\npending['Exp_GR_Date']=pd.to_datetime(pending['Exp_GR_Date'])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Forecasting consumption and PO creation for Trend_based models","showTitle":true,"inputWidgets":{},"nuid":"141d1ebd-68c5-4899-b891-50b06eaf42ed"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["print(eli5_reasons.shape)\neli5_reasons.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"278f804e-7766-4482-be91-356653c57c69"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["print(forecasted.shape)\nforecasted.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"120a75de-192a-4475-af9d-8d7ce62d51f0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["print(pending.shape)\npending.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a69d75e5-e8ca-4a0f-83b9-41167eda0dbc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["############Forecasting consumption, order placement, material receipts and expected inventory for next 90 days\n\nforecasting=pd.DataFrame()\npendings=pd.DataFrame()\nleadtime_reasons=pd.DataFrame()\n\nStart_date = Start_dates\nStart_date = datetime.datetime.strptime(Start_date, '%Y-%m-%d')\nfor Plant,Matl in zip(Rop12['LocationID'],Rop12['MaterialID']):\n#   try:\n\n  forecasted1=forecasted[(forecasted['LocationID']==Plant) & (forecasted['MaterialID']==Matl)].copy()\n  pending1=pending[(pending['LocationID']==Plant)&(pending['MaterialID']==Matl)].copy()\n  vendors1=vendors[(vendors['LocationID']==Plant)&(vendors['MaterialID']==Matl)].copy()\n  leadtime_reasons1=eli5_reasons[(eli5_reasons['LocationID']==Plant)&(eli5_reasons['MaterialID']==Matl)].copy()\n\n  ##### Getting the Reorder trigger attributes\n  ROP_freq = vendor_plant_data.loc[(vendor_plant_data['LocationID'] == Plant) & (vendor_plant_data['MaterialID'] == Matl), 'freq_val'].values[0]\n  ROP_median = vendor_plant_data.loc[(vendor_plant_data['LocationID'] == Plant) & (vendor_plant_data['MaterialID'] == Matl), 'median_val'].values[0]\n  ROP_mean = vendor_plant_data.loc[(vendor_plant_data['LocationID'] == Plant) & (vendor_plant_data['MaterialID'] == Matl), 'mean_val'].values[0]\n  ROP_method = vendor_plant_data.loc[(vendor_plant_data['LocationID'] == Plant) & (vendor_plant_data['MaterialID'] == Matl), 'flag'].values[0]\n\n  if (ROP_method == 'mean'):\n    ROP = ROP_mean\n  else:\n    ROP = ROP_median\n\n  for i in range(1,90):\n    #Last updated date\n    td=timedelta(i)\n    todate = Start_date+td\n    tempdf = forecasted1.tail(1).copy() # taking the latest entry of the forecasted\n    tempdf['SnapshotDate'] = todate\n    tempdf['Week'] = int(todate.isocalendar()[1])\n    tempdf['counter'] = tempdf['counter'].values[0] + 1\n    tempdf['Reorder'] = 0\n\n    # Update Consumption stats\n    try:\n      tempdf['daily_mean_consumption'] = inv_con.loc[(inv_con['MaterialID'] == Matl) & (inv_con['LocationID'] == Plant) & (inv_con['Week'] == int(todate.isocalendar()[1])),'daily_mean_consumption'].values[0]\n      tempdf['std_dev_consumption'] = inv_con.loc[(inv_con['MaterialID'] == Matl) & (inv_con['LocationID'] == Plant) & (inv_con['Week'] == int(todate.isocalendar()[1])), 'std_dev_consumption'].values[0]\n    except:\n      tempdf['daily_mean_consumption'] = 0\n      tempdf['std_dev_consumption'] = 0\n\n    # Update Material Receipt\n    tempdf['Matl_Recp'] = pending1.loc[pending1['Exp_GR_Date'] == pd.to_datetime(todate), 'Delivery_qty'].sum()\n\n\n  #   Order Placement Check - Mean/Median or hybrid or frequency and triggering order if needed\n    if((ROP_method == 'median') | (ROP_method == 'mean')):\n      if ((tempdf['Exp_inv'].values[0] >= ROP) & ((tempdf['Exp_inv'].values[0] + tempdf['Matl_Recp'].values[0] + tempdf['daily_mean_consumption'].values[0]) < ROP)):\n        tempdf['Reorder'] =1\n\n    elif(ROP_method == 'frequency'):\n      if (tempdf['counter'].values[0] >= ROP_freq):\n        tempdf['Reorder'] =1\n\n    elif(ROP_method == 'hybrid'):\n      if (((tempdf['Exp_inv'].values[0] >= ROP) & ((tempdf['Exp_inv'].values[0] + tempdf['Matl_Recp'].values[0] + tempdf['daily_mean_consumption'].values[0]) < ROP)) | ((tempdf['counter'].values[0] >= ROP_freq) & (tempdf['Exp_inv'].values[0]<ROP))):\n        tempdf['Reorder'] =1\n\n  # Order logging in 'Pending' by suppliers, PO Create date, Expected delivery, PO Qty and expected delivery qty:\n    if(tempdf['Reorder'].values[0] ==1):\n      po_place = vendors1.copy()\n      po_place['PO_Create_Date'] = todate\n      po_place['PO_Create_Date'] = pd.to_datetime(po_place['PO_Create_Date'], format=\"%Y-%m-%d\")\n      pds=[]\n      for pl_id,v_id,mt_id,po_c_d,p_qty in zip(po_place['LocationID'], po_place['updated_VS_ID'], po_place['MaterialID'], po_place['PO_Create_Date'].dt.date.astype(str), po_place['Vendor_ROQ']):\n        #print(pl_id,v_id,mt_id,po_c_d,p_qty)\n        lead_time_pred,tempeli5 = pred_output(historical_data, pl_id, v_id, mt_id, po_c_d, p_qty)\n        tempeli5['LocationID']=pl_id\n        tempeli5['updated_VS_ID']=v_id\n        tempeli5['MaterialID']=mt_id\n        tempeli5['PO_Create_Date']=po_c_d\n        leadtime_reasons1=leadtime_reasons1.append(tempeli5,ignore_index= True)\n        pds.append(lead_time_pred)\n      po_place['lead_time']=pds\n      try:\n        po_place['Exp_GR_Date'] = po_place['PO_Create_Date'].dt.date + pd.to_timedelta(po_place['lead_time'], unit='D')\n      except:\n        ags=[]\n        for i,j in zip(po_place['PO_Create_Date'],po_place['lead_time']):\n          ags.append(i+timedelta(int(j)))\n        po_place['Exp_GR_Date']=ags\n        po_place['Exp_GR_Date']=po_place['Exp_GR_Date'].dt.date\n      po_place['Delivery_qty'] = po_place['Vendor_ROQ']*po_place['Fulfillment_rate']\n\n      pending1 = pending1.append(po_place, ignore_index= True)\n      tempdf['counter'] = 0\n\n\n    # Update the Expected inventory\n    inv_calc = max((tempdf['Exp_inv'] + tempdf['Matl_Recp'] + tempdf['daily_mean_consumption']).values[0], 0) #Non negative inventory\n    tempdf['Exp_inv']= int(inv_calc)\n\n\n    forecasted1=forecasted1.append(tempdf,ignore_index=True)\n  forecasting=forecasting.append(forecasted1,ignore_index=True)\n  pendings=pendings.append(pending1,ignore_index=True)\n  leadtime_reasons=leadtime_reasons.append(leadtime_reasons1,ignore_index=True)\n#   except:\n#     print(Plant,Matl,\"- Unable to build invt based model\")\npendings['Exp_GR_Date']=pd.to_datetime(pendings['Exp_GR_Date'])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c7352c39-85b8-4f36-8bff-58899f265f3c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["print(leadtime_reasons.shape)\nleadtime_reasons.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fb6df32d-6934-4ee6-b7c9-0a5e42179556"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["print(forecasting.shape)\nforecasting.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8735d08d-f870-41b4-8744-dfe73843fff3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["print(pendings.shape)\npendings.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8029ccb9-f3b0-47f3-becd-cff951b969a8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["fore = spark.createDataFrame(forecasting)\nfore.write.saveAsTable(prediction_forecasting,mode = 'overwrite')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6f49f3cd-71fd-4c72-a12a-6cf517752d7d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["Rop450=forecasting[['LocationID','MaterialID']].copy()\nRop450.drop_duplicates(inplace=True)\nRop450.shape"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4ee57490-5c7b-4c1d-8cfe-e8d875ef233f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#1. Creating output for actual Vs estimated number of Purchase orders for a given plant, material combination\n\nnum_pos1=pd.DataFrame()\nplants=[]\nmatrls=[]\nacts=[]\nestm=[]\nStart_date = '{}'.format(Start_dates)\nStart_date = datetime.datetime.strptime(Start_date, '%Y-%m-%d')\nfor Plant,Matl in zip(Rop450['LocationID'],Rop450['MaterialID']):\n  ves_date['PO_Create_Date'] = pd.to_datetime(ves_date['PO_Create_Date'])\n  PO_original = ves_date[(ves_date['PO_Create_Date'] >= Start_date) & (ves_date['PO_Create_Date'] <= Start_date + timedelta(90)) & (ves_date['Material_No.'] ==Matl) & (ves_date['Plant_ID'] == Plant)]\n  plants.append(Plant)\n  matrls.append(Matl)\n  acts.append(PO_original.shape[0])\n  estm.append(forecasting[(forecasting['LocationID']==Plant) & (forecasting['MaterialID']==Matl) & (forecasting['SnapshotDate']>=Start_date) & (forecasting['SnapshotDate']<=Start_date + timedelta(90))]['Reorder'].sum())\nnum_pos1['LocationID']=plants\nnum_pos1['MaterialID']=matrls\nnum_pos1['Actual_POs_in_this_period']=acts\nnum_pos1['Estimated_POs_in_this_period']=estm\nnum_pos1['model']='trend_based'\nprint(num_pos1.shape)\nnum_pos1.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"347d5e64-13f4-4ef2-bf91-00a7e7919569"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["mopos = spark.createDataFrame(num_pos1)\nmopos.write.saveAsTable(prediction_numpos,mode = 'overwrite')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fa8b9804-7b49-485f-a2d9-11121d66a250"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#Choosing best model based on whether the number of orders placed is the closest to actual.\n\nnumpo=pd.concat([num_pos,num_pos1]).reset_index()\nnumpo.drop(columns=['index'],inplace=True)\nnumpo['absolute_error']=abs(numpo['Estimated_POs_in_this_period']-numpo['Actual_POs_in_this_period'])\nRop555=numpo[['LocationID','MaterialID']]\nRop555.drop_duplicates(inplace=True)\nmodel_to_use=pd.DataFrame()\nfor plant, matl in zip (Rop555['LocationID'],Rop555['MaterialID']):\n  a=numpo[(numpo['LocationID']==plant) & (numpo['MaterialID']==matl)]\n  tempdf=a.loc[a['absolute_error'].idxmin()]\n  model_to_use=model_to_use.append(tempdf)\nvar1=model_to_use[model_to_use['model']=='trend_based']\nvar2=model_to_use[model_to_use['model']=='model_based_prediction']\nvar2['flag']=''\nvar3=pd.merge(var1,reorder_method_check[['LocationID','MaterialID','flag']],on=['LocationID','MaterialID'],how='inner')\nmodels=pd.concat([var2,var3])\nprint(models.shape)\nmodels['LocationID']=models['LocationID'].astype(int)\nmodels['MaterialID']=models['MaterialID'].astype(int)\nmodels.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4cbc827f-4a1a-49e8-ac03-766fa254ce66"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["mopos1 = spark.createDataFrame(models)\nmopos1.write.saveAsTable(\"temp_models\",mode = 'overwrite')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1e110ca1-4ab0-44ef-9297-63d545ee0087"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["**In the Trend_based checking the method flag type of mean or median whether it needs to be replaced by hybrid to improve order placement. For this the following steps are followed.\n  1. Forecasting the plant material combination of Trend_based with flag mean or median for 6 months\n  2. In the month of february if more than 2 weeks has expected inventory equal to 0 replacing those plants and material combination with hybrid."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e23e7e08-4ea6-431f-aeb1-694360e71141"}}},{"cell_type":"code","source":["model_verification=models[(models['model']=='trend_based') & ((models['flag']=='median') | (models['flag']=='mean'))].copy()\nprint(model_verification.shape)\nmodel_verification.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"576d5e4c-edac-4b4c-8bec-cfaee2487852"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["###Setting up base for the 27 week forecast. \n# The inventory consumption/inflow and PO flag -> 'forecasted'\n# Identifying open Purchase orders and their expected delivery -> 'pending'\n# Vendors -> List of vendors for the material plant combination and their attributes\n\ndef set_base (Plants,Matls):\n  forecasted=pd.DataFrame()\n  pending=pd.DataFrame()\n  vendors=pd.DataFrame()\n  eli5_reasons=pd.DataFrame()\n\n  Start_date = Start_dates\n  Start_date = datetime.datetime.strptime(Start_date, '%Y-%m-%d')\n\n  ##### Getting the Reorder trigger attributes\n  for Plant,Matl in zip(Plants,Matls):\n    \n    ROP_freq = vendor_plant_data.loc[(vendor_plant_data['LocationID'] == Plant) & (vendor_plant_data['MaterialID'] == Matl), 'freq_val'].values[0]\n    ROP_median = vendor_plant_data.loc[(vendor_plant_data['LocationID'] == Plant) & (vendor_plant_data['MaterialID'] == Matl), 'median_val'].values[0]\n    ROP_mean = vendor_plant_data.loc[(vendor_plant_data['LocationID'] == Plant) & (vendor_plant_data['MaterialID'] == Matl), 'mean_val'].values[0]\n    ROP_method = vendor_plant_data.loc[(vendor_plant_data['LocationID'] == Plant) & (vendor_plant_data['MaterialID'] == Matl), 'flag'].values[0]\n\n    if (ROP_method == 'mean'):\n      ROP = ROP_mean\n    else:\n      ROP = ROP_median\n\n    ############################## Dataframe for logging POs and expected dates of receipts#########################################\n    vendors1 = vendor_plant_data[(vendor_plant_data['LocationID']==Plant) & (vendor_plant_data['MaterialID']==Matl)]\n    vendors_v1 = vendors1[['LocationID', 'MaterialID', 'updated_VS_ID', 'Fulfillment_rate', 'Vendor_ROQ','Avg_lead_time','Planned_avg_lead_time']]\n\n    # Checking if there are open purchase orders in the VES and logging the same in the 'pending' dataframe\n    pending_v1 = ves[(ves['Plant_ID']==Plant) & (ves['Material_No.']==Matl) & (ves['PO_Create_Date'] <= Start_date) & (ves['Delivery_date'] >= Start_date)][['Plant_ID', 'Material_No.', 'PO_Create_Date', 'Purchase_Order_Scheduled_Qty', 'updated_VS_ID']]\n\n    if (pending_v1.shape[0] >0): #if there are open pending orders\n      pending_v1 = ves[(ves['Plant_ID']==Plant) & (ves['Material_No.']==Matl) & (ves['PO_Create_Date'] <= Start_date) & (ves['Delivery_date'] >= Start_date)][['Plant_ID', 'Material_No.', 'PO_Create_Date', 'Purchase_Order_Scheduled_Qty', 'updated_VS_ID']]\n      pending_v1 = pd.merge(pending_v1, vendors_v1, on = ['updated_VS_ID'], how = 'left')\n      pending_v1['Vendor_ROQ'] = pending_v1['Purchase_Order_Scheduled_Qty']\n      pds=[]\n      for pl_id,v_id,mt_id,po_c_d,p_qty in zip(pending_v1['LocationID'],pending_v1['updated_VS_ID'],pending_v1['MaterialID'],pending_v1['PO_Create_Date'].dt.date.astype(str),pending_v1['Vendor_ROQ']):\n\n        lead_time_pred,tempeli5 = pred_output(historical_data, pl_id, v_id, mt_id, po_c_d, p_qty) #predicting lead time for open orders\n        tempeli5['LocationID']=pl_id\n        tempeli5['updated_VS_ID']=v_id\n        tempeli5['MaterialID']=mt_id\n        tempeli5['PO_Create_Date']=po_c_d\n        eli5_reasons=eli5_reasons.append(tempeli5,ignore_index= True)\n        pds.append(lead_time_pred)\n      pending_v1['lead_time']=pds    \n\n      pending_v1 = pending_v1[['LocationID', 'MaterialID', 'updated_VS_ID', 'Fulfillment_rate', 'Vendor_ROQ', 'PO_Create_Date',  'lead_time', 'Avg_lead_time', 'Planned_avg_lead_time']]\n\n      #Getting expected delivery date and logging in pending\n      try:\n        pending_v1['Exp_GR_Date'] = pending_v1['PO_Create_Date'].dt.date + pd.to_timedelta(pending_v1['lead_time'], unit='D') \n      except:\n        ags=[]\n        for i,j in zip(pending_v1['PO_Create_Date'],pending_v1['lead_time']):\n          ags.append(i+timedelta(int(j)))\n        pending_v1['Exp_GR_Date']=ags\n        pending_v1['Exp_GR_Date']=pending_v1['Exp_GR_Date'].dt.date\n      pending_v1['Delivery_qty'] = pending_v1['Vendor_ROQ']*pending_v1['Fulfillment_rate']\n      date_since_order = np.timedelta64( Start_date - max(pending_v1['PO_Create_Date']), 'D')\n      date_since_order = date_since_order.astype(int)\n\n    else: #if no pending orders, create df with dummy values\n      pending_v1 = pd.DataFrame({'LocationID': [Plant], 'MaterialID': [Matl], 'updated_VS_ID': [0], 'Fulfillment_rate': [0.0], 'Vendor_ROQ': [0.0], 'PO_Create_Date': ['2000-01-01'],'lead_time': [0],'Avg_lead_time':[0],'Planned_avg_lead_time':[0]})\n      pending_v1['PO_Create_Date'] =   pd.to_datetime(pending_v1['PO_Create_Date'], format=\"%Y-%m-%d\") \n      pending_v1['Exp_GR_Date'] = pending_v1['PO_Create_Date'].dt.date + pd.to_timedelta(pending_v1['lead_time'].values[0], unit='D')\n      pending_v1['Delivery_qty'] = pending_v1['Vendor_ROQ']*pending_v1['Fulfillment_rate']\n      date_since_order = 0\n\n    ############################## Dataframe for consumption, receipts and PO triggers#########################################\n    #Creating only the first row of the forecasted dataframe with the following elements:\n    # 1. Snapshot Date\n    # 2. Material ID\n    # 3. Location ID\n    # 4. Uinit of Measure\n    # 5. Week\n    # 6. Inventory stock in hand (from the inventory history)\n    # 7. Average Consumption\n    # 8. Std Deviation of consumption\n    # 9. Material received\n    # 10. Expected inventory at the end of the day = inventory in hand - consumption + \n    # 11. Counter: Count of days since last order \n    # 12. Reorder flag\n    \n    forecasted_v1 = h_inv_fi[(h_inv_fi['SnapshotDate'] == Start_date) & (h_inv_fi['MaterialID'] ==Matl) & (h_inv_fi['LocationID'] == Plant)]\n    forecasted_v1=pd.merge(forecasted_v1,inv_con,on=['LocationID','MaterialID','Week'],how='left')\n    forecasted_v1['Matl_Recp'] = pending_v1.loc[pending_v1['Exp_GR_Date'] == pd.to_datetime(Start_date) , 'Delivery_qty'].sum()\n    forecasted_v1.loc[forecasted_v1['daily_mean_consumption'].isnull()==True,'daily_mean_consumption']=0\n    forecasted_v1['Exp_inv'] = max((forecasted_v1['InventoryStockUnRestricted_daily'].astype(np.int64) + forecasted_v1['daily_mean_consumption'].astype(np.int64) + forecasted_v1['Matl_Recp'].astype(np.int64)).values[0],0)\n\n\n    forecasted_v1['counter'] = date_since_order\n    forecasted_v1['Reorder'] = 0\n    \n    # check if order needs to be placed on start date. Uf yes, log PO Create date, Vendor, lead time, expected delivery date, PO Quantity, Expected delivery in Pending based on the method of reorder\n    # Inventory based reorder check\n    \n    if max(pending_v1['PO_Create_Date'])==Start_date:\n      forecasted_v1['Reorder']=1\n    \n    if ((ROP_method == 'median') | (ROP_method == 'mean')):\n      if ((forecasted_v1['InventoryStockUnRestricted_daily'].values[0] >= ROP) & (forecasted_v1['Exp_inv'].values[0] < ROP)):\n        forecasted_v1['Reorder'] = 1\n\n\n    # Frequency based reorder check\n    elif (ROP_method == 'frequency'):\n      if (date_since_order >= ROP_freq):\n        forecasted_v1['Reorder'] = 1\n\n    # Hybrid Reorder check\n    elif (ROP_method == 'hybrid'): #(here ROP is median, ROP_freq is mode)\n      if (((date_since_order >= ROP_freq) & (forecasted_v1['Exp_inv'].values[0]<ROP))  | ((forecasted_v1['InventoryStockUnRestricted_daily'].values[0] >= ROP) & (forecasted_v1['Exp_inv'].values[0] < ROP))):\n        forecasted_v1['Reorder'] = 1\n\n    if (forecasted_v1['Reorder'].values[0] == 1):\n      po_place = vendors_v1.copy()\n      po_place['PO_Create_Date'] = Start_date\n      po_place['PO_Create_Date'] = pd.to_datetime(po_place['PO_Create_Date'], format=\"%Y-%m-%d\")\n\n      pds=[]\n      for pl_id,v_id,mt_id,po_c_d,p_qty in zip(po_place['LocationID'],po_place['updated_VS_ID'],po_place['MaterialID'],po_place['PO_Create_Date'].dt.date.astype(str),po_place['Vendor_ROQ']):\n        lead_time_pred,tempeli5 = pred_output(historical_data, pl_id, v_id, mt_id, po_c_d, p_qty)\n        tempeli5['LocationID']=pl_id\n        tempeli5['updated_VS_ID']=v_id\n        tempeli5['MaterialID']=mt_id\n        tempeli5['PO_Create_Date']=po_c_d\n        eli5_reasons=eli5_reasons.append(tempeli5,ignore_index= True)\n        pds.append(lead_time_pred)\n      po_place['lead_time']=pds\n\n      try:\n        po_place['Exp_GR_Date'] = po_place['PO_Create_Date'].dt.date + pd.to_timedelta(po_place['lead_time'], unit='D')\n      except:\n        ags=[]\n        for i,j in zip(po_place['PO_Create_Date'],po_place['lead_time']):\n          ags.append(i+timedelta(int(j)))\n        po_place['Exp_GR_Date']=ags\n        po_place['Exp_GR_Date']=po_place['Exp_GR_Date'].dt.date\n      po_place['Delivery_qty'] = po_place['Vendor_ROQ']*po_place['Fulfillment_rate']\n      forecasted_v1['counter'] = 0\n      pending_v1 = pending_v1.append(po_place, ignore_index= True)\n    forecasted=forecasted.append(forecasted_v1,ignore_index= True)\n    pending=pending.append(pending_v1,ignore_index= True)\n    vendors=vendors.append(vendors_v1,ignore_index= True)\n  ####End of loop\n\n  forecasted['InventoryStockUnRestricted_daily']=forecasted['InventoryStockUnRestricted_daily'].astype(np.int64)\n  forecasted['daily_mean_consumption']=forecasted['daily_mean_consumption'].astype(np.int64)\n  forecasted['Exp_inv']=forecasted['Exp_inv'].astype(np.int64)\n  pending['Delivery_qty']=pending['Delivery_qty'].astype(np.int64)\n  pending['Exp_GR_Date']=pd.to_datetime(pending['Exp_GR_Date'])\n  return forecasted,pending,vendors,eli5_reasons"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5bfd6685-39b0-474d-ba32-baf6a2b4f6e5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["forecasted,pending,vendors,eli5_reasons=set_base(model_verification['LocationID'],model_verification['MaterialID'])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"120772e7-1d4f-433e-99ea-b688c6e292e0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["print(eli5_reasons.shape)\neli5_reasons.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"839b9e9b-24b8-45d5-8128-84f821cd5216"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["print(forecasted.shape)\nforecasted.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d1d696af-bc60-4fda-973b-24c727f6548d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["print(pending.shape)\npending.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b39fb687-f9aa-4d17-8559-9070e93157c1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["############Forecasting consumption, order placement, material receipts and expected inventory for next 180 days\n\ndef forecast (Plants,Matls):\n  forecasting=pd.DataFrame()\n  pendings=pd.DataFrame()\n  leadtime_reasons=pd.DataFrame()\n  \n  Start_date = Start_dates\n  Start_date = datetime.datetime.strptime(Start_date, '%Y-%m-%d')\n  for Plant,Matl in zip(Plants,Matls):\n    \n    forecasted1=forecasted[(forecasted['LocationID']==Plant) & (forecasted['MaterialID']==Matl)].copy()\n    pending1=pending[(pending['LocationID']==Plant)&(pending['MaterialID']==Matl)].copy()\n    vendors1=vendors[(vendors['LocationID']==Plant)&(vendors['MaterialID']==Matl)].copy()\n    leadtime_reasons1=eli5_reasons[(eli5_reasons['LocationID']==Plant)&(eli5_reasons['MaterialID']==Matl)].copy()\n   \n    ##### Getting the Reorder trigger attributes\n    ROP_freq = vendor_plant_data.loc[(vendor_plant_data['LocationID'] == Plant) & (vendor_plant_data['MaterialID'] == Matl), 'freq_val'].values[0]\n    ROP_median = vendor_plant_data.loc[(vendor_plant_data['LocationID'] == Plant) & (vendor_plant_data['MaterialID'] == Matl), 'median_val'].values[0]\n    ROP_mean = vendor_plant_data.loc[(vendor_plant_data['LocationID'] == Plant) & (vendor_plant_data['MaterialID'] == Matl), 'mean_val'].values[0]\n    ROP_method = vendor_plant_data.loc[(vendor_plant_data['LocationID'] == Plant) & (vendor_plant_data['MaterialID'] == Matl), 'flag'].values[0]\n\n    if (ROP_method == 'mean'):\n      ROP = ROP_mean\n    else:\n      ROP = ROP_median\n\n    for i in range(1,180):\n      #Last updated date\n      td=timedelta(i)\n      todate = Start_date+td\n      tempdf = forecasted1.tail(1).copy() # taking the latest entry of the forecasted\n      tempdf['SnapshotDate'] = todate\n      tempdf['Week'] = int(todate.isocalendar()[1])\n      tempdf['counter'] = tempdf['counter'].values[0] + 1\n      tempdf['Reorder'] = 0\n\n      # Update Consumption stats\n      try:\n        tempdf['daily_mean_consumption'] = inv_con.loc[(inv_con['MaterialID'] == Matl) & (inv_con['LocationID'] == Plant) & (inv_con['Week'] == int(todate.isocalendar()[1])),'daily_mean_consumption'].values[0]\n        tempdf['std_dev_consumption'] = inv_con.loc[(inv_con['MaterialID'] == Matl) & (inv_con['LocationID'] == Plant) & (inv_con['Week'] == int(todate.isocalendar()[1])), 'std_dev_consumption'].values[0]\n      except:\n        tempdf['daily_mean_consumption'] = 0\n        tempdf['std_dev_consumption'] = 0\n\n      # Update Material Receipt\n      tempdf['Matl_Recp'] = pending1.loc[pending1['Exp_GR_Date'] == pd.to_datetime(todate), 'Delivery_qty'].sum()\n\n\n    #   Order Placement Check - Mean/Median or hybrid or frequency and triggering order if needed\n      if((ROP_method == 'median') | (ROP_method == 'mean')):\n        if ((tempdf['Exp_inv'].values[0] >= ROP) & ((tempdf['Exp_inv'].values[0] + tempdf['Matl_Recp'].values[0] + tempdf['daily_mean_consumption'].values[0]) < ROP)):\n          tempdf['Reorder'] =1\n\n      elif(ROP_method == 'frequency'):\n        if (tempdf['counter'].values[0] >= ROP_freq):\n          tempdf['Reorder'] =1\n\n      elif(ROP_method == 'hybrid'):\n        if (((tempdf['Exp_inv'].values[0] >= ROP) & ((tempdf['Exp_inv'].values[0] + tempdf['Matl_Recp'].values[0] + tempdf['daily_mean_consumption'].values[0]) < ROP)) | ((tempdf['counter'].values[0] >= ROP_freq) & (tempdf['Exp_inv'].values[0]<ROP))):\n          tempdf['Reorder'] =1\n\n    # Order logging in 'Pending' by suppliers, PO Create date, Expected delivery, PO Qty and expected delivery qty:\n      if(tempdf['Reorder'].values[0] ==1):\n        po_place = vendors1.copy()\n        po_place['PO_Create_Date'] = todate\n        po_place['PO_Create_Date'] = pd.to_datetime(po_place['PO_Create_Date'], format=\"%Y-%m-%d\")\n        pds=[]\n        for pl_id,v_id,mt_id,po_c_d,p_qty in zip(po_place['LocationID'], po_place['updated_VS_ID'], po_place['MaterialID'], po_place['PO_Create_Date'].dt.date.astype(str), po_place['Vendor_ROQ']):\n          lead_time_pred,tempeli5 = pred_output(historical_data, pl_id, v_id, mt_id, po_c_d, p_qty)\n          tempeli5['LocationID']=pl_id\n          tempeli5['updated_VS_ID']=v_id\n          tempeli5['MaterialID']=mt_id\n          tempeli5['PO_Create_Date']=po_c_d\n          leadtime_reasons1=leadtime_reasons1.append(tempeli5,ignore_index= True)\n          pds.append(lead_time_pred)\n        po_place['lead_time']=pds\n        try:\n          po_place['Exp_GR_Date'] = po_place['PO_Create_Date'].dt.date + pd.to_timedelta(po_place['lead_time'], unit='D')\n        except:\n          ags=[]\n          for i,j in zip(po_place['PO_Create_Date'],po_place['lead_time']):\n            ags.append(i+timedelta(int(j)))\n          po_place['Exp_GR_Date']=ags\n          po_place['Exp_GR_Date']=po_place['Exp_GR_Date'].dt.date\n        po_place['Delivery_qty'] = po_place['Vendor_ROQ']*po_place['Fulfillment_rate']\n\n        pending1 = pending1.append(po_place, ignore_index= True)\n        tempdf['counter'] = 0\n\n\n      # Update the Expected inventory\n      inv_calc = max((tempdf['Exp_inv'] + tempdf['Matl_Recp'] + tempdf['daily_mean_consumption']).values[0], 0) #Non negative inventory\n      tempdf['Exp_inv']= int(inv_calc)\n\n\n      forecasted1=forecasted1.append(tempdf,ignore_index=True)\n    forecasting=forecasting.append(forecasted1,ignore_index=True)\n    leadtime_reasons=leadtime_reasons.append(leadtime_reasons1,ignore_index=True)\n    pendings=pendings.append(pending1,ignore_index=True)\n  pendings['Exp_GR_Date']=pd.to_datetime(pendings['Exp_GR_Date'])\n  return forecasting,pendings,leadtime_reasons"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2808ae8d-9d10-4714-b31d-4160690993d3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["forecasting,pendings,leadtime_reasons=forecast(model_verification['LocationID'],model_verification['MaterialID'])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f4ace41c-d7de-4c0a-8912-be70e18da424"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["print(leadtime_reasons.shape)\nleadtime_reasons.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ee3c5bf0-fea2-4086-a63e-b3fe375c9c76"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["print(forecasting.shape)\nforecasting.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"85b52cb4-759d-4b74-892f-6ff59ab41cb5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["print(pendings.shape)\npendings.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3f0bc978-f4bc-44fd-a509-01f77689cb4c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#identfying plant material combination whose flag has to be replaced to hybrid\nsampledf=forecasting[(forecasting['Exp_inv']<1) & (forecasting['SnapshotDate']>=Start_dates)]\nsampledf=pd.pivot_table(sampledf,values='Exp_inv',index=['LocationID','MaterialID','Week'],aggfunc='count').reset_index()\nsampledf=sampledf[sampledf['Exp_inv']==7]\nsampledf=pd.pivot_table(sampledf,values='Exp_inv',index=['LocationID','MaterialID'],aggfunc='count').reset_index()\nsampledf=sampledf[sampledf['Exp_inv']>=2]\nprint(sampledf.shape)\nsampledf.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d46e4c9f-6bc4-46c3-a1e6-034c9a6d485f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["for plant,matl in zip(sampledf['LocationID'],sampledf['MaterialID']):\n  models.loc[(models['LocationID']==plant) & (models['MaterialID']==matl),'flag']='hybrid'"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"863c4715-53ea-446e-8ceb-878891b57330"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["models.reset_index(inplace=True)\nmodels.drop(columns=['index'],inplace=True)\nprint(models.shape)\nmodels.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c0578d86-6b0b-42d7-8d7d-d88cf9930cbb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["mopos = spark.createDataFrame(models)\nmopos.write.saveAsTable('models_tobe_saved',mode = 'overwrite')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"77e5ce8e-1c22-4ab4-a591-f32da439f21e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["models = spark.table('models_tobe_saved')\nmodels=models.toPandas()\nmodels['type']=1\nmodels_hist = spark.table(models_saved)\nmodels_hist=models_hist.toPandas()\nmodels_hist['type']=2\nmodels=pd.concat([models,models_hist])\nmodels.sort_values(by=['LocationID','MaterialID','type'],inplace=True)\nmodels.drop_duplicates(subset=['LocationID','MaterialID'],keep='first',inplace=True)\nmodels.drop(columns=['type'],inplace=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fc883afb-1e33-4a7d-aa4a-a30b76a62b4f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["mopos = spark.createDataFrame(models)\nmopos.write.saveAsTable(models_saved,mode = 'overwrite')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5a70bccd-003b-41b2-8de9-8318ba8e40b3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["*************************END****************************************"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0f7d9e67-c24b-43f7-851c-b7483984c014"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"3.b SPS Best PO model","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":1541108005201322}},"nbformat":4,"nbformat_minor":0}
